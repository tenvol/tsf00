{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL",
        "dPpJUV862FYI",
        "i2e3TlyL57Qs",
        "wCugvl0JdWYL"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tenvol/tsf00/blob/master/logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JndnmDMp66FL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "metadata": {
        "id": "hMqWDc_m6rUC",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g4T-_IsVbweU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "LEAHZv4rIYHX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Learning Objectives:**\n",
        "  * Reframe the median house value predictor (from the preceding exercises) as a binary classification model\n",
        "  * Compare the effectiveness of logisitic regression vs linear regression for a binary classification problem"
      ]
    },
    {
      "metadata": {
        "id": "CnkCZqdIIYHY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As in the prior exercises, we're working with the [California housing data set](https://developers.google.com/machine-learning/crash-course/california-housing-data-description), but this time we will turn it into a binary classification problem by predicting whether a city block is a high-cost city block. We'll also revert to the default features, for now."
      ]
    },
    {
      "metadata": {
        "id": "9pltCyy2K3dd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Frame the Problem as Binary Classification\n",
        "\n",
        "The target of our dataset is `median_house_value` which is a numeric (continuous-valued) feature. We can create a boolean label by applying a threshold to this continuous value.\n",
        "\n",
        "Given features describing a city block, we wish to predict if it is a high-cost city block. To prepare the targets for train and eval data, we define a classification threshold of the 75%-ile for median house value (a value of approximately 265000). All house values above the threshold are labeled `1`, and all others are labeled `0`."
      ]
    },
    {
      "metadata": {
        "id": "67IJwZX1Vvjt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Run the cells below to load the data and prepare the input features and targets."
      ]
    },
    {
      "metadata": {
        "id": "fOlbcJ4EIYHd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "\n",
        "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
        "\n",
        "california_housing_dataframe = california_housing_dataframe.reindex(\n",
        "    np.random.permutation(california_housing_dataframe.index))\n",
        "\n",
        "cahdf = california_housing_dataframe.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sGhje75uwPW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "547aa6bc-b592-40ad-babf-68db25582350"
      },
      "cell_type": "code",
      "source": [
        "cahdf.tail()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5892</th>\n",
              "      <td>-118.2</td>\n",
              "      <td>33.8</td>\n",
              "      <td>35.0</td>\n",
              "      <td>3405.0</td>\n",
              "      <td>779.0</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>671.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>159200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6336</th>\n",
              "      <td>-118.2</td>\n",
              "      <td>33.8</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1697.0</td>\n",
              "      <td>394.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>396.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>163100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14058</th>\n",
              "      <td>-122.0</td>\n",
              "      <td>37.4</td>\n",
              "      <td>23.0</td>\n",
              "      <td>3200.0</td>\n",
              "      <td>907.0</td>\n",
              "      <td>2029.0</td>\n",
              "      <td>866.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>450000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6027</th>\n",
              "      <td>-118.2</td>\n",
              "      <td>34.1</td>\n",
              "      <td>31.0</td>\n",
              "      <td>394.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>573.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>154200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8546</th>\n",
              "      <td>-118.5</td>\n",
              "      <td>34.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>2914.0</td>\n",
              "      <td>934.0</td>\n",
              "      <td>1334.0</td>\n",
              "      <td>870.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>350000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "5892      -118.2      33.8                35.0       3405.0           779.0   \n",
              "6336      -118.2      33.8                36.0       1697.0           394.0   \n",
              "14058     -122.0      37.4                23.0       3200.0           907.0   \n",
              "6027      -118.2      34.1                31.0        394.0           117.0   \n",
              "8546      -118.5      34.0                35.0       2914.0           934.0   \n",
              "\n",
              "       population  households  median_income  median_house_value  \n",
              "5892       1953.0       671.0            2.8            159200.0  \n",
              "6336       1274.0       396.0            3.4            163100.0  \n",
              "14058      2029.0       866.0            3.6            450000.0  \n",
              "6027        573.0       131.0            1.8            154200.0  \n",
              "8546       1334.0       870.0            3.0            350000.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "W4gruo_muemf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bd91aab5-d48f-4ee1-dddf-3f1356b61fc5"
      },
      "cell_type": "code",
      "source": [
        "california_housing_dataframe.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12776</th>\n",
              "      <td>-121.8</td>\n",
              "      <td>39.6</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2202.0</td>\n",
              "      <td>422.0</td>\n",
              "      <td>1109.0</td>\n",
              "      <td>403.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>87500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9408</th>\n",
              "      <td>-119.2</td>\n",
              "      <td>34.3</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4695.0</td>\n",
              "      <td>955.0</td>\n",
              "      <td>2065.0</td>\n",
              "      <td>982.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>223600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15920</th>\n",
              "      <td>-122.4</td>\n",
              "      <td>37.8</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1952.0</td>\n",
              "      <td>628.0</td>\n",
              "      <td>1284.0</td>\n",
              "      <td>576.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>316700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1473</th>\n",
              "      <td>-117.2</td>\n",
              "      <td>34.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4998.0</td>\n",
              "      <td>953.0</td>\n",
              "      <td>2764.0</td>\n",
              "      <td>891.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>101900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12753</th>\n",
              "      <td>-121.8</td>\n",
              "      <td>38.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>3090.0</td>\n",
              "      <td>593.0</td>\n",
              "      <td>1588.0</td>\n",
              "      <td>566.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>124700.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "12776     -121.8      39.6                25.0       2202.0           422.0   \n",
              "9408      -119.2      34.3                11.0       4695.0           955.0   \n",
              "15920     -122.4      37.8                52.0       1952.0           628.0   \n",
              "1473      -117.2      34.5                 7.0       4998.0           953.0   \n",
              "12753     -121.8      38.0                34.0       3090.0           593.0   \n",
              "\n",
              "       population  households  median_income  median_house_value  \n",
              "12776      1109.0       403.0            2.8             87500.0  \n",
              "9408       2065.0       982.0            3.2            223600.0  \n",
              "15920      1284.0       576.0            2.1            316700.0  \n",
              "1473       2764.0       891.0            3.2            101900.0  \n",
              "12753      1588.0       566.0            3.6            124700.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "StrrCs09v5dd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b9d05ad3-ec23-45b3-80e9-1e5ef402d3fb"
      },
      "cell_type": "code",
      "source": [
        "california_housing_dataframe.index"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([12776,  9408, 15920,  1473, 12753, 12705,  8420, 10092, 12628,\n",
              "             3813,\n",
              "            ...\n",
              "             4542,   169, 15811,  3816,  3974,  5892,  6336, 14058,  6027,\n",
              "             8546],\n",
              "           dtype='int64', length=17000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "lTB73MNeIYHf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note how the code below is slightly different from the previous exercises. Instead of using `median_house_value` as target, we create a new binary target, `median_house_value_is_high`."
      ]
    },
    {
      "metadata": {
        "id": "kPSqspaqIYHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_features(california_housing_dataframe):\n",
        "  \"\"\"Prepares input features from California housing data set.\n",
        "\n",
        "  Args:\n",
        "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
        "      from the California housing data set.\n",
        "  Returns:\n",
        "    A DataFrame that contains the features to be used for the model, including\n",
        "    synthetic features.\n",
        "  \"\"\"\n",
        "  selected_features = california_housing_dataframe[\n",
        "    [\"latitude\",\n",
        "     \"longitude\",\n",
        "     \"housing_median_age\",\n",
        "     \"total_rooms\",\n",
        "     \"total_bedrooms\",\n",
        "     \"population\",\n",
        "     \"households\",\n",
        "     \"median_income\"]]\n",
        "  processed_features = selected_features.copy()\n",
        "  # Create a synthetic feature.\n",
        "  processed_features[\"rooms_per_person\"] = (\n",
        "    california_housing_dataframe[\"total_rooms\"] /\n",
        "    california_housing_dataframe[\"population\"])\n",
        "  return processed_features\n",
        "\n",
        "def preprocess_targets(california_housing_dataframe):\n",
        "  \"\"\"Prepares target features (i.e., labels) from California housing data set.\n",
        "\n",
        "  Args:\n",
        "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
        "      from the California housing data set.\n",
        "  Returns:\n",
        "    A DataFrame that contains the target feature.\n",
        "  \"\"\"\n",
        "  output_targets = pd.DataFrame()\n",
        "  # Create a boolean categorical feature representing whether the\n",
        "  # median_house_value is above a set threshold.\n",
        "  output_targets[\"median_house_value_is_high\"] = (\n",
        "    california_housing_dataframe[\"median_house_value\"] > 265000).astype(float)\n",
        "  return output_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BDOXAfnpxXsP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "4424e5a6-fc0d-4578-f15e-f4184f659640"
      },
      "cell_type": "code",
      "source": [
        "(pd.DataFrame([np.random.randn(10)*10]) > 5.1).astype(float)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0   1   2   3   4   5   6   7   8   9\n",
              "0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "uLKw-m9Bxt9v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FwOYWmXqWA6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1205
        },
        "outputId": "5972b0f2-9bc1-4788-81a2-5b5cc88b3c5f"
      },
      "cell_type": "code",
      "source": [
        "# Choose the first 12000 (out of 17000) examples for training.\n",
        "training_examples = preprocess_features(california_housing_dataframe.head(12000))\n",
        "training_targets = preprocess_targets(california_housing_dataframe.head(12000))\n",
        "\n",
        "# Choose the last 5000 (out of 17000) examples for validation.\n",
        "validation_examples = preprocess_features(california_housing_dataframe.tail(5000))\n",
        "validation_targets = preprocess_targets(california_housing_dataframe.tail(5000))\n",
        "\n",
        "# Double-check that we've done the right thing.\n",
        "print(\"Training examples summary:\")\n",
        "display.display(training_examples.describe())\n",
        "print(\"Validation examples summary:\")\n",
        "display.display(validation_examples.describe())\n",
        "\n",
        "print(\"Training targets summary:\")\n",
        "display.display(training_targets.describe())\n",
        "print(\"Validation targets summary:\")\n",
        "display.display(validation_targets.describe())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training examples summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       latitude  longitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "count   12000.0    12000.0             12000.0      12000.0         12000.0   \n",
              "mean       35.6     -119.5                28.4       2647.6           540.6   \n",
              "std         2.1        2.0                12.6       2185.0           423.5   \n",
              "min        32.5     -124.3                 1.0          2.0             2.0   \n",
              "25%        33.9     -121.8                18.0       1466.0           297.0   \n",
              "50%        34.2     -118.5                28.0       2131.0           435.0   \n",
              "75%        37.7     -118.0                37.0       3162.0           648.0   \n",
              "max        42.0     -114.3                52.0      37937.0          6445.0   \n",
              "\n",
              "       population  households  median_income  rooms_per_person  \n",
              "count     12000.0     12000.0        12000.0           12000.0  \n",
              "mean       1430.5       501.9            3.9               2.0  \n",
              "std        1159.2       385.5            1.9               1.1  \n",
              "min           3.0         2.0            0.5               0.0  \n",
              "25%         793.0       282.0            2.6               1.5  \n",
              "50%        1167.0       410.0            3.5               1.9  \n",
              "75%        1726.0       603.0            4.8               2.3  \n",
              "max       35682.0      6082.0           15.0              55.2  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>rooms_per_person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>35.6</td>\n",
              "      <td>-119.5</td>\n",
              "      <td>28.4</td>\n",
              "      <td>2647.6</td>\n",
              "      <td>540.6</td>\n",
              "      <td>1430.5</td>\n",
              "      <td>501.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2185.0</td>\n",
              "      <td>423.5</td>\n",
              "      <td>1159.2</td>\n",
              "      <td>385.5</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>32.5</td>\n",
              "      <td>-124.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.9</td>\n",
              "      <td>-121.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1466.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>793.0</td>\n",
              "      <td>282.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>34.2</td>\n",
              "      <td>-118.5</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2131.0</td>\n",
              "      <td>435.0</td>\n",
              "      <td>1167.0</td>\n",
              "      <td>410.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>37.7</td>\n",
              "      <td>-118.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3162.0</td>\n",
              "      <td>648.0</td>\n",
              "      <td>1726.0</td>\n",
              "      <td>603.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>42.0</td>\n",
              "      <td>-114.3</td>\n",
              "      <td>52.0</td>\n",
              "      <td>37937.0</td>\n",
              "      <td>6445.0</td>\n",
              "      <td>35682.0</td>\n",
              "      <td>6082.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>55.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation examples summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       latitude  longitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "count    5000.0     5000.0              5000.0       5000.0          5000.0   \n",
              "mean       35.7     -119.6                28.9       2634.3           536.5   \n",
              "std         2.1        2.0                12.6       2168.0           416.7   \n",
              "min        32.5     -124.3                 1.0          8.0             1.0   \n",
              "25%        33.9     -121.8                19.0       1452.0           295.0   \n",
              "50%        34.3     -118.5                29.0       2118.5           431.0   \n",
              "75%        37.7     -118.0                37.0       3118.2           650.2   \n",
              "max        42.0     -114.6                52.0      30401.0          4957.0   \n",
              "\n",
              "       population  households  median_income  rooms_per_person  \n",
              "count      5000.0      5000.0         5000.0            5000.0  \n",
              "mean       1427.5       499.5            3.9               2.0  \n",
              "std        1120.2       382.1            1.9               1.3  \n",
              "min           9.0         1.0            0.5               0.1  \n",
              "25%         782.0       282.0            2.6               1.5  \n",
              "50%        1167.0       407.0            3.5               1.9  \n",
              "75%        1710.0       607.0            4.8               2.3  \n",
              "max       13251.0      4616.0           15.0              52.0  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>rooms_per_person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>35.7</td>\n",
              "      <td>-119.6</td>\n",
              "      <td>28.9</td>\n",
              "      <td>2634.3</td>\n",
              "      <td>536.5</td>\n",
              "      <td>1427.5</td>\n",
              "      <td>499.5</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2168.0</td>\n",
              "      <td>416.7</td>\n",
              "      <td>1120.2</td>\n",
              "      <td>382.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>32.5</td>\n",
              "      <td>-124.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.9</td>\n",
              "      <td>-121.8</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1452.0</td>\n",
              "      <td>295.0</td>\n",
              "      <td>782.0</td>\n",
              "      <td>282.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>34.3</td>\n",
              "      <td>-118.5</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2118.5</td>\n",
              "      <td>431.0</td>\n",
              "      <td>1167.0</td>\n",
              "      <td>407.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>37.7</td>\n",
              "      <td>-118.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3118.2</td>\n",
              "      <td>650.2</td>\n",
              "      <td>1710.0</td>\n",
              "      <td>607.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>42.0</td>\n",
              "      <td>-114.6</td>\n",
              "      <td>52.0</td>\n",
              "      <td>30401.0</td>\n",
              "      <td>4957.0</td>\n",
              "      <td>13251.0</td>\n",
              "      <td>4616.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training targets summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       median_house_value_is_high\n",
              "count                     12000.0\n",
              "mean                          0.2\n",
              "std                           0.4\n",
              "min                           0.0\n",
              "25%                           0.0\n",
              "50%                           0.0\n",
              "75%                           0.0\n",
              "max                           1.0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>median_house_value_is_high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation targets summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       median_house_value_is_high\n",
              "count                      5000.0\n",
              "mean                          0.3\n",
              "std                           0.4\n",
              "min                           0.0\n",
              "25%                           0.0\n",
              "50%                           0.0\n",
              "75%                           1.0\n",
              "max                           1.0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>median_house_value_is_high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "uon1LB3A31VN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How Would Linear Regression Fare?\n",
        "To see why logistic regression is effective, let us first train a naive model that uses linear regression. This model will use labels with values in the set `{0, 1}` and will try to predict a continuous value that is as close as possible to `0` or `1`. Furthermore, we wish to interpret the output as a probability, so it would be ideal if the output will be within the range `(0, 1)`. We would then apply a threshold of `0.5` to determine the label.\n",
        "\n",
        "Run the cells below to train the linear regression model using [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor)."
      ]
    },
    {
      "metadata": {
        "id": "smmUYRDtWOV_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns(input_features):\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Args:\n",
        "    input_features: The names of the numerical input features to use.\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\"\n",
        "  return set([tf.feature_column.numeric_column(my_feature)\n",
        "              for my_feature in input_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QvKEpvp077Ie",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5OwSrr1yIKD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
        "    \"\"\"Trains a linear regression model.\n",
        "  \n",
        "    Args:\n",
        "      features: pandas DataFrame of features\n",
        "      targets: pandas DataFrame of targets\n",
        "      batch_size: Size of batches to be passed to the model\n",
        "      shuffle: True or False. Whether to shuffle the data.\n",
        "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
        "    Returns:\n",
        "      Tuple of (features, labels) for next data batch\n",
        "    \"\"\"\n",
        "    \n",
        "    # Convert pandas data into a dict of np arrays.\n",
        "    features = {key:np.array(value) for key,value in dict(features).items()}                                            \n",
        " \n",
        "    # Construct a dataset, and configure batching/repeating.\n",
        "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    # Shuffle the data, if specified.\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "    \n",
        "    # Return the next batch of data.\n",
        "    features, labels = ds.make_one_shot_iterator().get_next()\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SE2-hq8PIYHz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_linear_regressor_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear regression model.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  as well as a plot of the training and validation loss over time.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    training_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for training.\n",
        "    training_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for training.\n",
        "    validation_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for validation.\n",
        "    validation_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for validation.\n",
        "      \n",
        "  Returns:\n",
        "    A `LinearRegressor` object trained on the training data.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "\n",
        "  # Create a linear regressor object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  linear_regressor = tf.estimator.LinearRegressor(\n",
        "      feature_columns=construct_feature_columns(training_examples),\n",
        "      optimizer=my_optimizer\n",
        "  )\n",
        "    \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                          training_targets[\"median_house_value_is_high\"], \n",
        "                                          batch_size=batch_size)\n",
        "  predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                                  training_targets[\"median_house_value_is_high\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                    validation_targets[\"median_house_value_is_high\"], \n",
        "                                                    num_epochs=1, \n",
        "                                                    shuffle=False)\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"RMSE (on training data):\")\n",
        "  training_rmse = []\n",
        "  validation_rmse = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    linear_regressor.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    \n",
        "    # Take a break and compute predictions.\n",
        "    training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\n",
        "    training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
        "    \n",
        "    validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n",
        "    validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
        "    \n",
        "    # Compute training and validation loss.\n",
        "    training_root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(training_predictions, training_targets))\n",
        "    validation_root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(validation_predictions, validation_targets))\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, training_root_mean_squared_error))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_rmse.append(training_root_mean_squared_error)\n",
        "    validation_rmse.append(validation_root_mean_squared_error)\n",
        "  print(\"Model training finished.\")\n",
        "  \n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(training_rmse, label=\"training\")\n",
        "  plt.plot(validation_rmse, label=\"validation\")\n",
        "  plt.legend()\n",
        "\n",
        "  return linear_regressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dID4CR37_dyO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a1bc854-af97-4027-8991-04603660d103"
      },
      "cell_type": "code",
      "source": [
        "np.array([1,3,2])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "TDBD8xeeIYH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "1bec1f6c-1ea3-4f30-be0a-7a8bb5e1ba9e"
      },
      "cell_type": "code",
      "source": [
        "linear_regressor = train_linear_regressor_model(\n",
        "    learning_rate=0.000001,\n",
        "    steps=200,\n",
        "    batch_size=20,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "RMSE (on training data):\n",
            "  period 00 : 0.45\n",
            "  period 01 : 0.45\n",
            "  period 02 : 0.45\n",
            "  period 03 : 0.44\n",
            "  period 04 : 0.44\n",
            "  period 05 : 0.44\n",
            "  period 06 : 0.44\n",
            "  period 07 : 0.44\n",
            "  period 08 : 0.44\n",
            "  period 09 : 0.44\n",
            "Model training finished.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGACAYAAACgBBhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa538d64250>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "JjBZ_q7aD9gh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 1: Can We Calculate LogLoss for These Predictions?\n",
        "\n",
        "**Examine the predictions and decide whether or not we can use them to calculate LogLoss.**\n",
        "\n",
        "`LinearRegressor` uses the L2 loss, which doesn't do a great job at penalizing misclassifications when the output is interpreted as a probability.  For example, there should be a huge difference whether a negative example is classified as positive with a probability of 0.9 vs 0.9999, but L2 loss doesn't strongly differentiate these cases.\n",
        "\n",
        "In contrast, `LogLoss` penalizes these \"confidence errors\" much more heavily.  Remember, `LogLoss` is defined as:\n",
        "\n",
        "$$Log Loss = \\sum_{(x,y)\\in D} -y \\cdot log(y_{pred}) - (1 - y) \\cdot log(1 - y_{pred})$$\n",
        "\n",
        "\n",
        "But first, we'll need to obtain the prediction values. We could use `LinearRegressor.predict` to obtain these.\n",
        "\n",
        "Given the predictions and the targets, can we calculate `LogLoss`?"
      ]
    },
    {
      "metadata": {
        "id": "xPzqHKLfFFaz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "91A94fumG6rb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dPpJUV862FYI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below to display the solution."
      ]
    },
    {
      "metadata": {
        "id": "kXFQ5uig2RoP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "8f92214e-f5a5-4847-870a-b4736e429d54"
      },
      "cell_type": "code",
      "source": [
        "predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                  validation_targets[\"median_house_value_is_high\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "\n",
        "validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n",
        "validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
        "\n",
        "_ = plt.hist(validation_predictions)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFKCAYAAADScRzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHbZJREFUeJzt3X9MXfXh//HXhcvdlXkRLru3W2Pn\nlqWuTBktwbFCWoUWtSTLUEtXSGu2orMpOqtMZdVpE5NBq5jaSFatw5I2KvPOLHyMgcYVExuubHoT\nQo1J1T8W1tZyr6JUfsgtud8/+vXaasu5Yi/nzeX5+EvOOZfzfr9y4ivnfS6njlgsFhMAADBSmt0D\nAAAAF0ZRAwBgMIoaAACDUdQAABiMogYAwGAUNQAABnPaPYDzCYdP2T2EpMvJydTw8JjdwzAeOVkj\nI2tklBhyspasjHw+zwX3cUdtE6cz3e4hzAnkZI2MrJFRYsjJmh0ZUdQAABiMogYAwGAUNQAABkuo\nqCcmJrR69Wq9/PLLOnHihDZu3Kja2lrdfffdmpyclCR1dnbqlltuUXV1tV566SVJUjQaVUNDg2pq\narRhwwYNDg4mbyYAAKSghIr6r3/9qy677DJJ0u7du1VbW6vnn39eV1xxhQKBgMbGxtTa2qp9+/Zp\n//79am9v1yeffKJXXnlFWVlZeuGFF7R582a1tLQkdTIAAKQay6L+4IMP9P777+u6666TJPX19WnV\nqlWSpLKyMgWDQfX39ys/P18ej0dut1uFhYUKhUIKBoOqqKiQJJWUlCgUCiVvJgAApCDLot6xY4ca\nGxvjP4+Pj8vlckmScnNzFQ6HFYlE5PV648d4vd6vbU9LS5PD4YgvlQMAAGvTvvDkn//8p5YuXapF\nixadd/+F/inrb7r9q3JyMufF3/NN9wfu+BI5WSMja2SUGHKyNtsZTVvUr7/+ugYHB/X666/rww8/\nlMvlUmZmpiYmJuR2u3Xy5En5/X75/X5FIpH454aGhrR06VL5/X6Fw2EtWbJE0WhUsVgsfjc+nfnw\nZhyfzzMv3sD2bZGTNTKyRkaJISdrycpoxm8m27Vrl/7xj3/o73//u6qrq7VlyxaVlJSou7tbknTw\n4EGtWLFCBQUFGhgY0MjIiEZHRxUKhVRUVKTS0lJ1dXVJknp6elRcXHwRpwUAQOr7xu/6vuuuu/TA\nAw+oo6NDCxcuVFVVlTIyMtTQ0KC6ujo5HA7V19fL4/GosrJSvb29qqmpkcvlUnNzczLmAABAynLE\nEn1wPIvmw9ILS0yJISdrZGSNjBJDTtbsWPo28l/Pmo82NR+yewjTamsst3sIADAv8QpRAAAMRlED\nAGAwihoAAINR1AAAGIyiBgDAYBQ1AAAGo6gBADAYRQ0AgMEoagAADEZRAwBgMIoaAACDUdQAABiM\nogYAwGAUNQAABqOoAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAAg1HUAAAYjKIGAMBgFDUAAAajqAEA\nMBhFDQCAwShqAAAMRlEDAGAwihoAAIM5rQ4YHx9XY2OjPvroI33++efasmWLuru79c477yg7O1uS\nVFdXp+uuu06dnZ1qb29XWlqa1q1bp+rqakWjUTU2Nur48eNKT09XU1OTFi1alPSJAQCQCiyLuqen\nR1dffbVuv/12HTt2TJs2bdKyZct07733qqysLH7c2NiYWltbFQgElJGRobVr16qiokI9PT3KyspS\nS0uLDh8+rJaWFu3atSupkwIAIFVYFnVlZWX8v0+cOKEFCxac97j+/n7l5+fL4/FIkgoLCxUKhRQM\nBlVVVSVJKikp0bZt2y7GuAEAmBcsi/oL69ev14cffqg9e/Zo3759OnDggJ577jnl5ubqz3/+syKR\niLxeb/x4r9ercDh8zva0tDQ5HA5NTk7K5XJd8Fw5OZlyOtO/xbTmBp/PY/cQEmbnWOdSTnYhI2tk\nlBhysjbbGSVc1C+++KLeffdd3Xfffdq2bZuys7OVl5enZ555Rk899ZSWLVt2zvGxWOy8v+dC2882\nPDyW6LDmLJ/Po3D4lN3DSJhdY51rOdmBjKyRUWLIyVqyMpqu/C2/9X3kyBGdOHFCkpSXl6epqSld\neeWVysvLkySVl5fr6NGj8vv9ikQi8c8NDQ3J7/fL7/crHA5LkqLRqGKx2LR30wAA4EuWRf3WW2+p\nra1NkhSJRDQ2NqaHH35Yg4ODkqS+vj4tXrxYBQUFGhgY0MjIiEZHRxUKhVRUVKTS0lJ1dXVJOvPF\ntOLi4iROBwCA1GK59L1+/Xo9+OCDqq2t1cTEhB5++GFlZmZq69atuuSSS5SZmammpia53W41NDSo\nrq5ODodD9fX18ng8qqysVG9vr2pqauRyudTc3Dwb8wIAICU4Yok8NJ5l8+EZyVefc2xqPmTjaKy1\nNZbbcl6emVkjI2tklBhysmbkM2oAAGAfihoAAINR1AAAGIyiBgDAYBQ1AAAGo6gBADAYRQ0AgMEo\nagAADEZRAwBgMIoaAACDUdQAABiMogYAwGAUNQAABqOoAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAA\ng1HUAAAYjKIGAMBgFDUAAAajqAEAMBhFDQCAwShqAAAMRlEDAGAwihoAAINR1AAAGMxpdcD4+Lga\nGxv10Ucf6fPPP9eWLVu0ZMkS3X///ZqampLP59Njjz0ml8ulzs5Otbe3Ky0tTevWrVN1dbWi0aga\nGxt1/Phxpaenq6mpSYsWLZqNuQEAMOdZ3lH39PTo6quv1oEDB7Rr1y41Nzdr9+7dqq2t1fPPP68r\nrrhCgUBAY2Njam1t1b59+7R//361t7frk08+0SuvvKKsrCy98MIL2rx5s1paWmZjXgAApATLoq6s\nrNTtt98uSTpx4oQWLFigvr4+rVq1SpJUVlamYDCo/v5+5efny+PxyO12q7CwUKFQSMFgUBUVFZKk\nkpIShUKhJE4HAIDUYrn0/YX169frww8/1J49e/S73/1OLpdLkpSbm6twOKxIJCKv1xs/3uv1fm17\nWlqaHA6HJicn458/n5ycTDmd6TOd05zh83nsHkLC7BzrXMrJLmRkjYwSQ07WZjujhIv6xRdf1Lvv\nvqv77rtPsVgsvv3s/z7bN91+tuHhsUSHNWf5fB6Fw6fsHkbC7BrrXMvJDmRkjYwSQ07WkpXRdOVv\nufR95MgRnThxQpKUl5enqakpffe739XExIQk6eTJk/L7/fL7/YpEIvHPDQ0NxbeHw2FJUjQaVSwW\nm/ZuGgAAfMmyqN966y21tbVJkiKRiMbGxlRSUqLu7m5J0sGDB7VixQoVFBRoYGBAIyMjGh0dVSgU\nUlFRkUpLS9XV1SXpzBfTiouLkzgdAABSi+XS9/r16/Xggw+qtrZWExMTevjhh3X11VfrgQceUEdH\nhxYuXKiqqiplZGSooaFBdXV1cjgcqq+vl8fjUWVlpXp7e1VTUyOXy6Xm5ubZmBcAACnBEUvkofEs\nmw/PSL76nGNT8yEbR2OtrbHclvPyzMwaGVkjo8SQkzUjn1EDAAD7UNQAABiMogYAwGAUNQAABqOo\nAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAAg1HUAAAYjKIGAMBgFDUAAAajqAEAMBhFDQCAwShqAAAM\nRlEDAGAwihoAAINR1AAAGIyiBgDAYBQ1AAAGo6gBADAYRQ0AgMEoagAADEZRAwBgMIoaAACDUdQA\nABiMogYAwGDORA7auXOn3n77bZ0+fVp33HGHDh06pHfeeUfZ2dmSpLq6Ol133XXq7OxUe3u70tLS\ntG7dOlVXVysajaqxsVHHjx9Xenq6mpqatGjRoqROCgCAVGFZ1G+++abee+89dXR0aHh4WDfddJN+\n+ctf6t5771VZWVn8uLGxMbW2tioQCCgjI0Nr165VRUWFenp6lJWVpZaWFh0+fFgtLS3atWtXUicF\nAECqsFz6vuaaa/Tkk09KkrKysjQ+Pq6pqamvHdff36/8/Hx5PB653W4VFhYqFAopGAyqoqJCklRS\nUqJQKHSRpwAAQOqyLOr09HRlZmZKkgKBgFauXKn09HQdOHBAt956q+655x59/PHHikQi8nq98c95\nvV6Fw+FztqelpcnhcGhycjJJ0wEAILUk9Ixakl577TUFAgG1tbXpyJEjys7OVl5enp555hk99dRT\nWrZs2TnHx2Kx8/6eC20/W05OppzO9ESHNmf5fB67h5AwO8c6l3KyCxlZI6PEkJO12c4ooaJ+4403\ntGfPHj377LPyeDxavnx5fF95ebm2b9+uG264QZFIJL59aGhIS5culd/vVzgc1pIlSxSNRhWLxeRy\nuaY93/Dw2AynM3f4fB6Fw6fsHkbC7BrrXMvJDmRkjYwSQ07WkpXRdOVvufR96tQp7dy5U08//XT8\nW9533XWXBgcHJUl9fX1avHixCgoKNDAwoJGREY2OjioUCqmoqEilpaXq6uqSJPX09Ki4uPhizAkA\ngHnB8o761Vdf1fDwsLZu3RrfdvPNN2vr1q265JJLlJmZqaamJrndbjU0NKiurk4Oh0P19fXyeDyq\nrKxUb2+vampq5HK51NzcnNQJAQCQShyxRB4az7L5sPTy1eWTTc2HbByNtbbGclvOy1KcNTKyRkaJ\nISdrRi59AwAA+1DUAAAYjKIGAMBgFDUAAAajqAEAMBhFDQCAwShqAAAMRlEDAGAwihoAAINR1AAA\nGIyiBgDAYBQ1AAAGo6gBADAYRQ0AgMEoagAADEZRAwBgMIoaAACDUdQAABiMogYAwGAUNQAABqOo\nAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAAg1HUAAAYjKIGAMBgzkQO2rlzp95++22dPn1ad9xxh/Lz\n83X//fdrampKPp9Pjz32mFwulzo7O9Xe3q60tDStW7dO1dXVikajamxs1PHjx5Wenq6mpiYtWrQo\n2fMCACAlWBb1m2++qffee08dHR0aHh7WTTfdpOXLl6u2tlZr1qzRE088oUAgoKqqKrW2tioQCCgj\nI0Nr165VRUWFenp6lJWVpZaWFh0+fFgtLS3atWvXbMwNAIA5z3Lp+5prrtGTTz4pScrKytL4+Lj6\n+vq0atUqSVJZWZmCwaD6+/uVn58vj8cjt9utwsJChUIhBYNBVVRUSJJKSkoUCoWSOB0AAFKLZVGn\np6crMzNTkhQIBLRy5UqNj4/L5XJJknJzcxUOhxWJROT1euOf83q9X9uelpYmh8OhycnJZMwFAICU\nk9Azakl67bXXFAgE1NbWpuuvvz6+PRaLnff4b7r9bDk5mXI60xMd2pzl83nsHkLC7BzrXMrJLmRk\njYwSQ07WZjujhIr6jTfe0J49e/Tss8/K4/EoMzNTExMTcrvdOnnypPx+v/x+vyKRSPwzQ0NDWrp0\nqfx+v8LhsJYsWaJoNKpYLBa/G7+Q4eGxbzerOcDn8ygcPmX3MBJm11jnWk52ICNrZJQYcrKWrIym\nK3/Lpe9Tp05p586devrpp5WdnS3pzLPm7u5uSdLBgwe1YsUKFRQUaGBgQCMjIxodHVUoFFJRUZFK\nS0vV1dUlSerp6VFxcfHFmBMAAPOC5R31q6++quHhYW3dujW+rbm5WQ899JA6Ojq0cOFCVVVVKSMj\nQw0NDaqrq5PD4VB9fb08Ho8qKyvV29urmpoauVwuNTc3J3VCAACkEkcskYfGs2w+LL18dflkU/Mh\nG0djra2x3JbzshRnjYyskVFiyMmakUvfAADAPhQ1AAAGo6gBADAYRQ0AgMEoagAADEZRAwBgMIoa\nAACDUdQAABiMogYAwGAUNQAABqOoAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAAg1HUAAAYjKIGAMBg\nFDUAAAajqAEAMBhFDQCAwShqAAAMRlEDAGAwihoAAINR1AAAGIyiBgDAYBQ1AAAGo6gBADBYQkV9\n9OhRrV69WgcOHJAkNTY26le/+pU2btyojRs36vXXX5ckdXZ26pZbblF1dbVeeuklSVI0GlVDQ4Nq\namq0YcMGDQ4OJmcmAACkIKfVAWNjY3r00Ue1fPnyc7bfe++9KisrO+e41tZWBQIBZWRkaO3ataqo\nqFBPT4+ysrLU0tKiw4cPq6WlRbt27br4MwEAIAVZ3lG7XC7t3btXfr9/2uP6+/uVn58vj8cjt9ut\nwsJChUIhBYNBVVRUSJJKSkoUCoUuzsgBAJgHLIva6XTK7XZ/bfuBAwd066236p577tHHH3+sSCQi\nr9cb3+/1ehUOh8/ZnpaWJofDocnJyYs4BQAAUpfl0vf5/PrXv1Z2drby8vL0zDPP6KmnntKyZcvO\nOSYWi533sxfafracnEw5nekzGdqc4vN57B5Cwuwc61zKyS5kZI2MEkNO1mY7oxkV9dnPq8vLy7V9\n+3bdcMMNikQi8e1DQ0NaunSp/H6/wuGwlixZomg0qlgsJpfLNe3vHx4em8mw5hSfz6Nw+JTdw0iY\nXWOdaznZgYyskVFiyMlasjKarvxn9OdZd911V/zb2319fVq8eLEKCgo0MDCgkZERjY6OKhQKqaio\nSKWlperq6pIk9fT0qLi4eCanBABgXrK8oz5y5Ih27NihY8eOyel0qru7Wxs2bNDWrVt1ySWXKDMz\nU01NTXK73WpoaFBdXZ0cDofq6+vl8XhUWVmp3t5e1dTUyOVyqbm5eTbmBQBASnDEEnloPMvmw9LL\nV5dPNjUfsnE01toay205L0tx1sjIGhklhpyszZmlbwAAMDsoagAADEZRAwBgMIoaAACDUdQAABiM\nogYAwGAUNQAABqOoAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAAg1HUAAAYjKIGAMBgFDUAAAajqAEA\nMBhFDQCAwShqAAAMRlEDAGAwihoAAINR1AAAGIyiBgDAYBQ1AAAGo6gBADAYRQ0AgMEoagAADEZR\nAwBgMIoaAACDJVTUR48e1erVq3XgwAFJ0okTJ7Rx40bV1tbq7rvv1uTkpCSps7NTt9xyi6qrq/XS\nSy9JkqLRqBoaGlRTU6MNGzZocHAwSVMBACD1WBb12NiYHn30US1fvjy+bffu3aqtrdXzzz+vK664\nQoFAQGNjY2ptbdW+ffu0f/9+tbe365NPPtErr7yirKwsvfDCC9q8ebNaWlqSOiEAAFKJZVG7XC7t\n3btXfr8/vq2vr0+rVq2SJJWVlSkYDKq/v1/5+fnyeDxyu90qLCxUKBRSMBhURUWFJKmkpEShUChJ\nUwEAIPU4LQ9wOuV0nnvY+Pi4XC6XJCk3N1fhcFiRSERerzd+jNfr/dr2tLQ0ORwOTU5Oxj9/Pjk5\nmXI602c0obnE5/PYPYSE2TnWuZSTXcjIGhklhpyszXZGlkVtJRaLXZTtZxseHvtWY5oLfD6PwuFT\ndg8jYXaNda7lZAcyskZGiSEna8nKaLryn9G3vjMzMzUxMSFJOnnypPx+v/x+vyKRSPyYoaGh+PZw\nOCzpzBfLYrHYtHfTAADgSzMq6pKSEnV3d0uSDh48qBUrVqigoEADAwMaGRnR6OioQqGQioqKVFpa\nqq6uLklST0+PiouLL97oAQBIcZZL30eOHNGOHTt07NgxOZ1OdXd36/HHH1djY6M6Ojq0cOFCVVVV\nKSMjQw0NDaqrq5PD4VB9fb08Ho8qKyvV29urmpoauVwuNTc3z8a8AABICY5YIg+NZ9l8eEby1ecc\nm5oP2Tgaa22N5bacl2dm1sjIGhklhpyszZln1AAAYHZQ1AAAGIyiBgDAYBQ1AAAGo6gBADAYRQ0A\ngMEoagAADEZRAwBgMIoaAACDUdQAABiMogYAwGAUNQAABqOoAQAwGEUNAIDBKGoAAAxGUQMAYDCK\nGgAAg1HUAAAYjKIGAMBgFDUAAAZz2j0AzA2bmg/ZPQRLbY3ldg8BAC467qgBADAYRQ0AgMEoagAA\nDEZRAwBgMIoaAACDUdQAABhsRn+e1dfXp7vvvluLFy+WJF155ZW67bbbdP/992tqako+n0+PPfaY\nXC6XOjs71d7errS0NK1bt07V1dUXdQIAAKSyGf8d9S9+8Qvt3r07/vOf/vQn1dbWas2aNXriiScU\nCARUVVWl1tZWBQIBZWRkaO3ataqoqFB2dvZFGTwAAKnuoi199/X1adWqVZKksrIyBYNB9ff3Kz8/\nXx6PR263W4WFhQqFQhfrlAAApLwZ31G///772rx5sz799FPdeeedGh8fl8vlkiTl5uYqHA4rEonI\n6/XGP+P1ehUOh7/9qAEAmCdmVNQ/+tGPdOedd2rNmjUaHBzUrbfeqqmpqfj+WCx23s9daPtX5eRk\nyulMn8nQ5hSfz2P3EFLKfM5zPs89UWSUGHKyNtsZzaioFyxYoMrKSknSD3/4Q33ve9/TwMCAJiYm\n5Ha7dfLkSfn9fvn9fkUikfjnhoaGtHTpUsvfPzw8NpNhzSk+n0fh8Cm7h5FS5mueXEvWyCgx5GQt\nWRlNV/4zekbd2dmpv/3tb5KkcDisjz76SDfffLO6u7slSQcPHtSKFStUUFCggYEBjYyMaHR0VKFQ\nSEVFRTM5JQAA89KM7qjLy8v1xz/+Uf/6178UjUa1fft25eXl6YEHHlBHR4cWLlyoqqoqZWRkqKGh\nQXV1dXI4HKqvr5fHw7IKAACJmlFRX3rppdqzZ8/Xtj/33HNf23bjjTfqxhtvnMlpAACY93gzGQAA\nBqOoAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAAg1HUAAAYjKIGAMBgFDUAAAajqAEAMBhFDQCAwShq\nAAAMNqN/lGOu2dR8yO4hAAAwI9xRAwBgMIoaAACDUdQAABiMogYAwGAUNQAABqOoAQAwGEUNAIDB\nKGoAAAxGUQMAYDCKGgAAg82LV4hifjD9VbFtjeV2DwHAHMQdNQAABqOoAQAwGEUNAIDBZuUZ9V/+\n8hf19/fL4XBo27Zt+vnPfz4bpwUAYM5LelH/+9//1n//+191dHTogw8+0LZt29TR0ZHs0wLGMf3L\nbhJfeANMlPSl72AwqNWrV0uSfvKTn+jTTz/VZ599luzTAgCQEpJ+Rx2JRHTVVVfFf/Z6vQqHw7r0\n0kuTfWoA39BcuOs3HasSuNhm/e+oY7GY5TE+n+einvP/Wn59UX8fAKSqi/3/31Q02xklfenb7/cr\nEonEfx4aGpLP50v2aQEASAlJL+rS0lJ1d3dLkt555x35/X6WvQEASFDSl74LCwt11VVXaf369XI4\nHHrkkUeSfUoAAFKGI5bIQ2MAAGAL3kwGAIDBKGoAAAzGP3M5C6Z7hWpvb6+eeOIJpaena+XKlaqv\nr7dxpPaZLqPy8nJ9//vfV3p6uiTp8ccf14IFC+waqq2OHj2qLVu26Le//a02bNhwzj6upTOmy4hr\n6YydO3fq7bff1unTp3XHHXfo+uuvj+/jOvrSdDnN6rUUQ1L19fXFfv/738disVjs/fffj61bt+6c\n/WvWrIkdP348NjU1FaupqYm99957dgzTVlYZlZWVxT777DM7hmaU0dHR2IYNG2IPPfRQbP/+/V/b\nz7VknRHXUiwWDAZjt912WywWi8U+/vjj2LXXXnvOfq6jM6xyms1riaXvJJvuFaqDg4O67LLL9IMf\n/EBpaWm69tprFQwG7RyuLXjNbGJcLpf27t0rv9//tX1cS2dMlxHOuOaaa/Tkk09KkrKysjQ+Pq6p\nqSlJXEdnmy6n2UZRJ1kkElFOTk785y9eoSpJ4XBYXq/3vPvmk+ky+sIjjzyimpoaPf744wm93S4V\nOZ1Oud3u8+7jWjpjuoy+MN+vpfT0dGVmZkqSAoGAVq5cGV++5Tr60nQ5fWG2riWeUc+y+fg/hm/q\nqxn94Q9/0IoVK3TZZZepvr5e3d3duvHGG20aHeYyrqUvvfbaawoEAmpra7N7KEa7UE6zeS1xR51k\n071C9av7Tp48OS+X7KxeM1tVVaXc3Fw5nU6tXLlSR48etWOYRuNaSgzX0hlvvPGG9uzZo71798rj\n+fK91VxH57pQTtLsXksUdZJN9wrVyy+/XJ999pn+97//6fTp0+rp6VFpaamdw7XFdBmdOnVKdXV1\nmpyclCT95z//0eLFi20bq6m4lqxxLZ1x6tQp7dy5U08//bSys7PP2cd19KXpcprta4ml7yQ73ytU\nX375ZXk8HlVUVGj79u1qaGiQJFVWVurHP/6xzSOefVYZrVy5Ur/5zW/0ne98Rz/72c/m7VLlkSNH\ntGPHDh07dkxOp1Pd3d0qLy/X5ZdfzrX0/1llxLUkvfrqqxoeHtbWrVvj24qLi/XTn/6U6+gsVjnN\n5rXEK0QBADAYS98AABiMogYAwGAUNQAABqOoAQAwGEUNAIDBKGoAAAxGUQMAYDCKGgAAg/0/KlcB\nOPugENoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa53a413550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rYpy336F9wBg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2: Train a Logistic Regression Model and Calculate LogLoss on the Validation Set\n",
        "\n",
        "To use logistic regression, simply use [LinearClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) instead of `LinearRegressor`. Complete the code below.\n",
        "\n",
        "**NOTE**: When running `train()` and `predict()` on a `LinearClassifier` model, you can access the real-valued predicted probabilities via the `\"probabilities\"` key in the returned dict—e.g., `predictions[\"probabilities\"]`. Sklearn's [log_loss](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html) function is handy for calculating LogLoss using these probabilities.\n"
      ]
    },
    {
      "metadata": {
        "id": "JElcb--E9wBm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_linear_classifier_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear classification model.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  as well as a plot of the training and validation loss over time.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    training_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for training.\n",
        "    training_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for training.\n",
        "    validation_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for validation.\n",
        "    validation_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for validation.\n",
        "      \n",
        "  Returns:\n",
        "    A `LinearClassifier` object trained on the training data.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "  \n",
        "  # Create a linear classifier object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  linear_classifier = # YOUR CODE HERE: Construct the linear classifier.\n",
        "  \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                          training_targets[\"median_house_value_is_high\"], \n",
        "                                          batch_size=batch_size)\n",
        "  predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                                  training_targets[\"median_house_value_is_high\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                    validation_targets[\"median_house_value_is_high\"], \n",
        "                                                    num_epochs=1, \n",
        "                                                    shuffle=False)\n",
        "  \n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"LogLoss (on training data):\")\n",
        "  training_log_losses = []\n",
        "  validation_log_losses = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    linear_classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    # Take a break and compute predictions.    \n",
        "    training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn)\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n",
        "    \n",
        "    validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n",
        "    \n",
        "    training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, training_log_loss))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_log_losses.append(training_log_loss)\n",
        "    validation_log_losses.append(validation_log_loss)\n",
        "  print(\"Model training finished.\")\n",
        "  \n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(training_log_losses, label=\"training\")\n",
        "  plt.plot(validation_log_losses, label=\"validation\")\n",
        "  plt.legend()\n",
        "\n",
        "  return linear_classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VM0wmnFUIYH9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_classifier = train_linear_classifier_model(\n",
        "    learning_rate=0.000005,\n",
        "    steps=500,\n",
        "    batch_size=20,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i2e3TlyL57Qs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below to see the solution.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "5YxXd2hn6MuF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_linear_classifier_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear classification model.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  as well as a plot of the training and validation loss over time.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    training_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for training.\n",
        "    training_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for training.\n",
        "    validation_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for validation.\n",
        "    validation_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for validation.\n",
        "      \n",
        "  Returns:\n",
        "    A `LinearClassifier` object trained on the training data.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "  \n",
        "  # Create a linear classifier object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)  \n",
        "  linear_classifier = tf.estimator.LinearClassifier(\n",
        "      feature_columns=construct_feature_columns(training_examples),\n",
        "      optimizer=my_optimizer\n",
        "  )\n",
        "  \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                          training_targets[\"median_house_value_is_high\"], \n",
        "                                          batch_size=batch_size)\n",
        "  predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                                  training_targets[\"median_house_value_is_high\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                    validation_targets[\"median_house_value_is_high\"], \n",
        "                                                    num_epochs=1, \n",
        "                                                    shuffle=False)\n",
        "  \n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"LogLoss (on training data):\")\n",
        "  training_log_losses = []\n",
        "  validation_log_losses = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    linear_classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    # Take a break and compute predictions.    \n",
        "    training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn)\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n",
        "    \n",
        "    validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n",
        "    \n",
        "    training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, training_log_loss))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_log_losses.append(training_log_loss)\n",
        "    validation_log_losses.append(validation_log_loss)\n",
        "  print(\"Model training finished.\")\n",
        "  \n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(training_log_losses, label=\"training\")\n",
        "  plt.plot(validation_log_losses, label=\"validation\")\n",
        "  plt.legend()\n",
        "\n",
        "  return linear_classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UPM_T1FXsTaL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_classifier = train_linear_classifier_model(\n",
        "    learning_rate=0.000005,\n",
        "    steps=500,\n",
        "    batch_size=20,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i-Xo83_aR6s_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 3: Calculate Accuracy and plot a ROC Curve for the Validation Set\n",
        "\n",
        "A few of the metrics useful for classification are the model [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification), the [ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) and the area under the ROC curve (AUC). We'll examine these metrics.\n",
        "\n",
        "`LinearClassifier.evaluate` calculates useful metrics like accuracy and AUC."
      ]
    },
    {
      "metadata": {
        "id": "DKSQ87VVIYIA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
        "\n",
        "print(\"AUC on the validation set: %0.2f\" % evaluation_metrics['auc'])\n",
        "print(\"Accuracy on the validation set: %0.2f\" % evaluation_metrics['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "47xGS2uNIYIE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You may use class probabilities, such as those calculated by `LinearClassifier.predict`,\n",
        "and Sklearn's [roc_curve](http://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics) to\n",
        "obtain the true positive and false positive rates needed to plot a ROC curve."
      ]
    },
    {
      "metadata": {
        "id": "xaU7ttj8IYIF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
        "# Get just the probabilities for the positive class.\n",
        "validation_probabilities = np.array([item['probabilities'][1] for item in validation_probabilities])\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(\n",
        "    validation_targets, validation_probabilities)\n",
        "plt.plot(false_positive_rate, true_positive_rate, label=\"our model\")\n",
        "plt.plot([0, 1], [0, 1], label=\"random classifier\")\n",
        "_ = plt.legend(loc=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PIdhwfgzIYII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**See if you can tune the learning settings of the model trained at Task 2 to improve AUC.**\n",
        "\n",
        "Often times, certain metrics improve at the detriment of others, and you'll need to find the settings that achieve a good compromise.\n",
        "\n",
        "**Verify if all metrics improve at the same time.**"
      ]
    },
    {
      "metadata": {
        "id": "XKIqjsqcCaxO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TUNE THE SETTINGS BELOW TO IMPROVE AUC\n",
        "linear_classifier = train_linear_classifier_model(\n",
        "    learning_rate=0.000005,\n",
        "    steps=500,\n",
        "    batch_size=20,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)\n",
        "\n",
        "evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
        "\n",
        "print(\"AUC on the validation set: %0.2f\" % evaluation_metrics['auc'])\n",
        "print(\"Accuracy on the validation set: %0.2f\" % evaluation_metrics['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCugvl0JdWYL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below for a possible solution."
      ]
    },
    {
      "metadata": {
        "id": "VHosS1g2aetf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "One possible solution that works is to just train for longer, as long as we don't overfit. \n",
        "\n",
        "We can do this by increasing the number the steps, the batch size, or both.\n",
        "\n",
        "All metrics improve at the same time, so our loss metric is a good proxy\n",
        "for both AUC and accuracy.\n",
        "\n",
        "Notice how it takes many, many more iterations just to squeeze a few more \n",
        "units of AUC. This commonly happens. But often even this small gain is worth \n",
        "the costs."
      ]
    },
    {
      "metadata": {
        "id": "dWgTEYMddaA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_classifier = train_linear_classifier_model(\n",
        "    learning_rate=0.000003,\n",
        "    steps=20000,\n",
        "    batch_size=500,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)\n",
        "\n",
        "evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
        "\n",
        "print(\"AUC on the validation set: %0.2f\" % evaluation_metrics['auc'])\n",
        "print(\"Accuracy on the validation set: %0.2f\" % evaluation_metrics['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}