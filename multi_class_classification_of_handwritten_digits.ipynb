{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi-class_classification_of_handwritten_digits.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL",
        "266KQvZoMxMv",
        "6sfw3LH0Oycm"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tenvol/tsf00/blob/master/multi_class_classification_of_handwritten_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JndnmDMp66FL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "metadata": {
        "id": "hMqWDc_m6rUC",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mPa95uXvcpcn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classifying Handwritten Digits with Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "Fdpn8b90u8Tp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![img](https://www.tensorflow.org/versions/r0.11/images/MNIST.png)"
      ]
    },
    {
      "metadata": {
        "id": "c7HLCm66Cs2p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Learning Objectives:**\n",
        "  * Train both a linear model and a neural network to classify handwritten digits from the classic [MNIST](http://yann.lecun.com/exdb/mnist/) data set\n",
        "  * Compare the performance of the linear and neural network classification models\n",
        "  * Visualize the weights of a neural-network hidden layer"
      ]
    },
    {
      "metadata": {
        "id": "HSEh-gNdu8T0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our goal is to map each input image to the correct numeric digit. We will create a NN with a few hidden layers and a Softmax layer at the top to select the winning class."
      ]
    },
    {
      "metadata": {
        "id": "2NMdE1b-7UIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "First, let's download the data set, import TensorFlow and other utilities, and load the data into a *pandas* `DataFrame`. Note that this data is a sample of the original MNIST training data; we've taken 20000 rows at random."
      ]
    },
    {
      "metadata": {
        "id": "4LJ4SD8BWHeh",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "6556e37c-e50a-4709-9bbe-41c665054517"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import glob\n",
        "import math\n",
        "import os\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "\n",
        "mnist_dataframe = pd.read_csv(\n",
        "  \"https://download.mlcc.google.com/mledu-datasets/mnist_train_small.csv\",\n",
        "  sep=\",\",\n",
        "  header=None)\n",
        "\n",
        "# Use just the first 10,000 records for training/validation.\n",
        "mnist_dataframe = mnist_dataframe.head(10000)\n",
        "\n",
        "mnist_dataframe = mnist_dataframe.reindex(np.random.permutation(mnist_dataframe.index))\n",
        "mnist_dataframe.head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7691</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5001</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7344</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1    2    3    4    5    6    7    8    9   ...   775  776  777  \\\n",
              "7691    8    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "993     1    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "681     1    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "5001    1    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "7344    1    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "\n",
              "      778  779  780  781  782  783  784  \n",
              "7691    0    0    0    0    0    0    0  \n",
              "993     0    0    0    0    0    0    0  \n",
              "681     0    0    0    0    0    0    0  \n",
              "5001    0    0    0    0    0    0    0  \n",
              "7344    0    0    0    0    0    0    0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "gC_j3j7V9wwl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mndf = mnist_dataframe.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LJWAETrU91rV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cceff1a-065f-4eba-d910-aa4302df9eaf"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "_6fNG_XG93zE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "9a0398b1-5c38-4a6b-8838-8f72e909c3a8"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.head(3)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7691</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1    2    3    4    5    6    7    8    9   ...   775  776  777  \\\n",
              "7691    8    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "993     1    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "681     1    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "\n",
              "      778  779  780  781  782  783  784  \n",
              "7691    0    0    0    0    0    0    0  \n",
              "993     0    0    0    0    0    0    0  \n",
              "681     0    0    0    0    0    0    0  \n",
              "\n",
              "[3 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "BU-6_KTb96hK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d7b18fe8-df12-4d96-eaa9-99b110758ee2"
      },
      "cell_type": "code",
      "source": [
        "mndf.groupby(0).apply(lambda x: x[0].count())"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0     979\n",
              "1    1107\n",
              "2    1001\n",
              "3     981\n",
              "4     943\n",
              "5     894\n",
              "6    1021\n",
              "7    1085\n",
              "8     973\n",
              "9    1016\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "L00-M8Vh-r2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "cf6bd5eb-51a2-4eae-93cd-bd84c8deb15f"
      },
      "cell_type": "code",
      "source": [
        "mndf.groupby(0).apply(lambda x: x[9].count())"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0     979\n",
              "1    1107\n",
              "2    1001\n",
              "3     981\n",
              "4     943\n",
              "5     894\n",
              "6    1021\n",
              "7    1085\n",
              "8     973\n",
              "9    1016\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "-3tdNrN4-yha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f77cb593-404e-487a-9476-cb6f307fec44"
      },
      "cell_type": "code",
      "source": [
        "mndf.groupby(0).agg('count')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>...</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>...</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>...</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>...</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>...</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>...</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>...</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>...</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>...</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>...</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    1     2     3     4     5     6     7     8     9     10   ...    775  \\\n",
              "0                                                              ...          \n",
              "0   979   979   979   979   979   979   979   979   979   979  ...    979   \n",
              "1  1107  1107  1107  1107  1107  1107  1107  1107  1107  1107  ...   1107   \n",
              "2  1001  1001  1001  1001  1001  1001  1001  1001  1001  1001  ...   1001   \n",
              "3   981   981   981   981   981   981   981   981   981   981  ...    981   \n",
              "4   943   943   943   943   943   943   943   943   943   943  ...    943   \n",
              "5   894   894   894   894   894   894   894   894   894   894  ...    894   \n",
              "6  1021  1021  1021  1021  1021  1021  1021  1021  1021  1021  ...   1021   \n",
              "7  1085  1085  1085  1085  1085  1085  1085  1085  1085  1085  ...   1085   \n",
              "8   973   973   973   973   973   973   973   973   973   973  ...    973   \n",
              "9  1016  1016  1016  1016  1016  1016  1016  1016  1016  1016  ...   1016   \n",
              "\n",
              "    776   777   778   779   780   781   782   783   784  \n",
              "0                                                        \n",
              "0   979   979   979   979   979   979   979   979   979  \n",
              "1  1107  1107  1107  1107  1107  1107  1107  1107  1107  \n",
              "2  1001  1001  1001  1001  1001  1001  1001  1001  1001  \n",
              "3   981   981   981   981   981   981   981   981   981  \n",
              "4   943   943   943   943   943   943   943   943   943  \n",
              "5   894   894   894   894   894   894   894   894   894  \n",
              "6  1021  1021  1021  1021  1021  1021  1021  1021  1021  \n",
              "7  1085  1085  1085  1085  1085  1085  1085  1085  1085  \n",
              "8   973   973   973   973   973   973   973   973   973  \n",
              "9  1016  1016  1016  1016  1016  1016  1016  1016  1016  \n",
              "\n",
              "[10 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "P1-awioT-7ZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "922f411d-c71a-4c15-b618-f46fe51a2cb6"
      },
      "cell_type": "code",
      "source": [
        "mndf.groupby(0).agg({9: 'count', 700: 'count'})"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>9</th>\n",
              "      <th>700</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    9     700\n",
              "0            \n",
              "0   979   979\n",
              "1  1107  1107\n",
              "2  1001  1001\n",
              "3   981   981\n",
              "4   943   943\n",
              "5   894   894\n",
              "6  1021  1021\n",
              "7  1085  1085\n",
              "8   973   973\n",
              "9  1016  1016"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "ZVHS5zU--e-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "86def4c1-87ef-4d97-e100-0356c9b4105c"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.groupby(0)[0].hist(bins=10)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "3    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "4    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "5    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "6    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "7    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "8    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "9    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFKCAYAAAA0WNeQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb028b4fed0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "m9_QtHI4AHrc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "bb02a982-a5fb-425e-b448-5b130e3b41ac"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.groupby(0).agg({784: 'count'})"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    784\n",
              "0      \n",
              "0   979\n",
              "1  1107\n",
              "2  1001\n",
              "3   981\n",
              "4   943\n",
              "5   894\n",
              "6  1021\n",
              "7  1085\n",
              "8   973\n",
              "9  1016"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "Us9DPw6gBReZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a7bdabd-863a-494d-ed94-915108939577"
      },
      "cell_type": "code",
      "source": [
        "type(mnist_dataframe.groupby(0).agg('count'))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "pVopUSR2EL50",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "163d0174-1ada-4353-b809-a85aa2b05bf8"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.groupby(0).agg('count')[96]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0     979\n",
              "1    1107\n",
              "2    1001\n",
              "3     981\n",
              "4     943\n",
              "5     894\n",
              "6    1021\n",
              "7    1085\n",
              "8     973\n",
              "9    1016\n",
              "Name: 96, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "85BIEKNgIvIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "d21d9918-fc5d-4348-98a2-e6da906007f8"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.groupby(0)[9].hist(bins=10)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "3    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "4    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "5    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "6    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "7    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "8    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "9    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "Name: 9, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFKCAYAAADScRzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb02affeb10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Pi4ggs46BZCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "dccfa8ef-cb0a-4bdb-ee59-c26ac1512b33"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.groupby(0)[9].agg('count').plot(kind='bar')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb02b3a43d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFUCAYAAADrrX8/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb02b4866d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MdTlM4chLo8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "59a14c27-fb79-4729-da0e-3503c66f7ffd"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.groupby(0)[9].agg('count')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0     979\n",
              "1    1107\n",
              "2    1001\n",
              "3     981\n",
              "4     943\n",
              "5     894\n",
              "6    1021\n",
              "7    1085\n",
              "8     973\n",
              "9    1016\n",
              "Name: 9, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "iR4gF8S1LsXA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kg0-25p2mOi0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each row represents one labeled example. Column 0 represents the label that a human rater has assigned for one handwritten digit. For example, if Column 0 contains '6', then a human rater interpreted the handwritten character as the digit '6'.  The ten digits 0-9 are each represented, with a unique class label for each possible digit. Thus, this is a multi-class classification problem with 10 classes."
      ]
    },
    {
      "metadata": {
        "id": "PQ7vuOwRCsZ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![img](https://www.tensorflow.org/versions/r0.11/images/MNIST-Matrix.png)"
      ]
    },
    {
      "metadata": {
        "id": "dghlqJPIu8UM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Columns 1 through 784 contain the feature values, one per pixel for the 28×28=784 pixel values. The pixel values are on a gray scale in which 0 represents white, 255 represents black, and values between 0 and 255 represent shades of gray. Most of the pixel values are 0; you may want to take a minute to confirm that they aren't all 0.  For example, adjust the following text block to print out the values in column 72."
      ]
    },
    {
      "metadata": {
        "id": "2ZkrL5MCqiJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "2e672855-1d6b-43d0-9808-c18d190072a3"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.loc[:, 72:72]"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>72</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7691</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5001</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7344</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9450</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2843</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9072</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3467</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7604</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      72\n",
              "7691   0\n",
              "993    0\n",
              "681    0\n",
              "5001   0\n",
              "7344   0\n",
              "...   ..\n",
              "9450   0\n",
              "2843   0\n",
              "9072   0\n",
              "3467   0\n",
              "7604   0\n",
              "\n",
              "[10000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "id": "ep4Smv_o-JIz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vLNg2VxqhUZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let's parse out the labels and features and look at a few examples. Note the use of `loc` which allows us to pull out columns based on original location, since we don't have a header row in this data set."
      ]
    },
    {
      "metadata": {
        "id": "JfFWWvMWDFrR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parse_labels_and_features(dataset):\n",
        "  \"\"\"Extracts labels and features.\n",
        "  \n",
        "  This is a good place to scale or transform the features if needed.\n",
        "  \n",
        "  Args:\n",
        "    dataset: A Pandas `Dataframe`, containing the label on the first column and\n",
        "      monochrome pixel values on the remaining columns, in row major order.\n",
        "  Returns:\n",
        "    A `tuple` `(labels, features)`:\n",
        "      labels: A Pandas `Series`.\n",
        "      features: A Pandas `DataFrame`.\n",
        "  \"\"\"\n",
        "  labels = dataset[0]\n",
        "\n",
        "  # DataFrame.loc index ranges are inclusive at both ends.\n",
        "  features = dataset.loc[:,1:784]\n",
        "  # Scale the data to [0, 1] by dividing out the max value, 255.\n",
        "  features = features / 255\n",
        "\n",
        "  return labels, features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GcoWUz6cPejV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFY_-7vZu8UU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "f2c1f437-4d36-4a3c-f99f-cc6771d530fc"
      },
      "cell_type": "code",
      "source": [
        "training_targets, training_examples = parse_labels_and_features(mnist_dataframe[:7500])\n",
        "training_examples.describe()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         1      2      3      4      5      6      7      8      9      10   \\\n",
              "count 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0   \n",
              "mean     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "       ...      775    776    777    778    779    780    781    782    783  \\\n",
              "count  ...   7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0   \n",
              "mean   ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max    ...      1.0    1.0    0.8    0.2    1.0    0.2    0.0    0.0    0.0   \n",
              "\n",
              "         784  \n",
              "count 7500.0  \n",
              "mean     0.0  \n",
              "std      0.0  \n",
              "min      0.0  \n",
              "25%      0.0  \n",
              "50%      0.0  \n",
              "75%      0.0  \n",
              "max      0.0  \n",
              "\n",
              "[8 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "mNcT3Al1PnQ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4-Vgg-1zu8Ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "f35593b1-6e4c-4b02-d588-9ff7ac90da96"
      },
      "cell_type": "code",
      "source": [
        "validation_targets, validation_examples = parse_labels_and_features(mnist_dataframe[7500:10000])\n",
        "validation_examples.describe()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         1      2      3      4      5      6      7      8      9      10   \\\n",
              "count 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0   \n",
              "mean     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "       ...      775    776    777    778    779    780    781    782    783  \\\n",
              "count  ...   2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0   \n",
              "mean   ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max    ...      1.0    0.7    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "         784  \n",
              "count 2500.0  \n",
              "mean     0.0  \n",
              "std      0.0  \n",
              "min      0.0  \n",
              "25%      0.0  \n",
              "50%      0.0  \n",
              "75%      0.0  \n",
              "max      0.0  \n",
              "\n",
              "[8 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "wrnAI1v6u8Uh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Show a random example and its corresponding label."
      ]
    },
    {
      "metadata": {
        "id": "s-euVJVtu8Ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "5cd551ef-f070-47b4-ae28-e623a252b996"
      },
      "cell_type": "code",
      "source": [
        "rand_example = np.random.choice(training_examples.index)\n",
        "_, ax = plt.subplots()\n",
        "ax.matshow(training_examples.loc[rand_example].values.reshape(28, 28))\n",
        "ax.set_title(\"Label: %i\" % training_targets.loc[rand_example])\n",
        "ax.grid(False)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFXCAYAAAAro2x+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMCCWAGBALAHA4P8AGeVEMwd7fkQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb028698850>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "GxY_G9SrQNZ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "13e267c4-84de-4ed8-8a27-fddc8028cafc"
      },
      "cell_type": "code",
      "source": [
        "rand_example = np.random.choice(training_examples.index)\n",
        "_, ax = plt.subplots()\n",
        "ax.matshow(training_examples.loc[rand_example].values.reshape(28, 28))\n",
        "ax.set_title(\"Label: %i\" % training_targets.loc[rand_example])\n",
        "ax.grid(False)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFXCAYAAAAro2x+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFDhJREFUeJzt3W9MlfX/x/HX8dBZnsQoFJY3NP2K\nRWY3WprHPyjgtKNzinVDSKnllv3RiWaO+YdatkDSWqSmkrYV/WE7ba2tEjTLnAElazW4A2UZOSVS\nCk0sVH432s5+Jsb7OnK4+PN83NLDxw+fy6ueu46Hz3V52tvb2wUA+E8D3F4AAPQGxBIADIglABgQ\nSwAwIJYAYEAsAcCAWKLb3HbbbTp58qSjP5OWlqYjR444+jO5ubnavn17p+M++OADzZkzR9OnT9fT\nTz+tv//+29H3Qf9CLNEv1dXVKT8/X6+//ro+++wzXbp0ScXFxW4vCz0YsYTrWltblZOTo1mzZikt\nLU2bNm267OuVlZWaP3++pk2bppdffjn8+v79+zV37lylp6frkUce0enTp6+Ye8uWLXr33XeveL2y\nslITJ07ULbfcIo/Ho4ceekjl5eVdf3DoM2LcXgDw7rvv6s8//9TevXvV0tKimTNnKj09Xffcc48k\nqba2Vu+//75+//13BYNBBYNB3XDDDVqzZo3ee+89jRkzRjt37tSzzz6roqKiy+Z+6qmnOvyeHo9H\nly5dCv/e7/fr559/jt5BotfjyhKue+SRR7R9+3Z5PB7deOONSkpK0i+//BL++ty5c+X1ehUfH6/x\n48frm2++0RdffKEJEyZozJgxkqSFCxfqwIEDunjxoul7BgIBHT58WHV1dbpw4YLefvtt/fXXX1E5\nPvQNXFnCdT/99JMKCgp09OhRDRgwQCdPntSCBQvCX7/55pvDv46NjVVLS4va29t15MgR3XfffeGv\nDRo0SL///rvpe44ePVobNmzQqlWr5PP5dP/99ys2NrbrDgp9DrGE65577jmNHTtW27Ztk9fr1cKF\nCy/7+h9//HHZr2+88Ub5fD5NmjTpirfdTmRkZCgjI0OS9PXXX4evUoGO8DYcrjt16pSSk5Pl9Xp1\n+PBhHTt2TOfOnQt//aOPPtKlS5d06tQpVVdX65577tGUKVN05MgRNTQ0SJK+++47Pf/88+bveezY\nMc2bN08tLS1qa2vTjh07LruaBf6NK0t0q8WLF8vr9YZ///zzz+vxxx9Xfn6+tm/frvT0dC1btkxF\nRUVKTk6WJI0bN04PPPCATp8+rYceekijR4+WJG3cuFFPPvmk2tradMMNN2jt2rVXfL8tW7Zo2LBh\nyszMvOz1ESNGKD09XfPmzZPH49GcOXPCV5lARzzczxIAOsfbcAAwIJYAYEAsAcDAlQ94XnjhBX37\n7bfyeDxau3at7rrrLjeW0aWqqqq0YsUKJSUlSZLGjBmjDRs2uLyqyNXV1emJJ57Qww8/rEWLFunE\niRNas2aNLl68qKFDh+rFF1+Uz+dze5mO/PuYcnNzVVtbq7i4OEnSkiVLNH36dHcX6VBhYaGqq6t1\n4cIFLV26VOPGjev150m68rgOHDjg+rnq9lh+9dVXOnbsmEpLS/XDDz9o7dq1Ki0t7e5lRMWECROu\n6ef+eopz585p48aNCgQC4deKioqUlZWlYDCol156SaFQSFlZWS6u0pmOjkmSVq1apdTUVJdWdW0q\nKytVX1+v0tJSNTc3KyMjQ4FAoFefJ6nj45o4caLr56rb34ZXVFRoxowZkqT//e9/+uOPP3T27Nnu\nXgb+g8/nU3FxsRISEsKvVVVVKT09XZKUmpqqiooKt5YXkY6OqbcbP368XnnlFUnS4MGD1dra2uvP\nk9TxcVm3sUZTt8fyt99+00033RT+/c0336ympqbuXkZUfP/993rssceUmZmpw4cPu72ciMXExOj6\n66+/7LXW1tbw27n4+Phed846OiZJKikpUXZ2tlauXNnhXYt6Mq/XK7/fL0kKhUJKSUnp9edJ6vi4\nvF6v6+fK9R9K7ys/5nnrrbdq2bJlCgaDamhoUHZ2tsrLy3vlvxd1pq+cs3nz5ikuLk7JycnatWuX\ntm7dqry8PLeX5dj+/fsVCoW0Z88ezZw5M/x6bz9P//+4ampqXD9X3X5lmZCQoN9++y38+19//VVD\nhw7t7mV0ucTERM2ePVsej0fDhw/XkCFD1NjY6Payuozf79f58+clSY2NjX3i7WwgEAjvEkpLS1Nd\nXZ3LK3Lu0KFD2rFjh4qLixUbG9tnztO/j6snnKtuj+XkyZNVVlYm6Z/7FCYkJGjQoEHdvYwu9+GH\nH2r37t2SpKamJp06dUqJiYkur6rrTJo0KXzeysvLNXXqVJdXdO2WL18e3lteVVUV/kmG3uLMmTMq\nLCzUzp07w58S94Xz1NFx9YRz5cp2x82bN+vIkSPyeDx65plndPvtt3f3Errc2bNntXr16vCNGZYt\nW6Zp06a5vayI1NTUaNOmTTp+/LhiYmKUmJiozZs3Kzc3V3/99ZeGDRum/Px8XXfddW4v1ayjY1q0\naJF27dqlgQMHyu/3Kz8/X/Hx8W4v1ay0tFSvvvqqRo4cGX6toKBA69ev77XnSer4uBYsWKCSkhJX\nzxV7wwHAgB08AGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGAQ8V2H+uLdzgHgaiKK\nZV++2zkAdCSit+Hc7RxAfxNRLPvy3c4BoCNd8gEPNy4C0NdFFMu+erdzALiaiGLZV+92DgBXE9Gn\n4XfffbfGjh2rhQsXhu92DgB9GXdKBwADdvAAgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHA\ngFgCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsA\nMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADYgkABsQS\nAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAYxETyh6qqqrRixQolJSVJksaM\nGaMNGzZ06cIAoCeJKJaSNGHCBBUVFXXlWgCgx+JtOAAYRBzL77//Xo899pgyMzN1+PDhrlwTAPQ4\nnvb29nanf6ixsVHV1dUKBoNqaGhQdna2ysvL5fP5orFGAHBdRFeWiYmJmj17tjwej4YPH64hQ4ao\nsbGxq9cGAD1GRLH88MMPtXv3bklSU1OTTp06pcTExC5dGAD0JBG9DT979qxWr16tlpYWtbW1admy\nZZo2bVo01gcAPUJEsQSA/oYfHQIAA2IJAAbEEgAMiCUAGBBLADAglgBgQCwBwIBYAoABsQQAA2IJ\nAAbEEgAMIn6sBPq3lpYW89ja2lrz2IMHD5rGrVu3zjznpUuXzGMHDLBdP8ycOdM8Z15ennmsk7t3\njRo1yjwW144rSwAwIJYAYEAsAcCAWAKAAbEEAANiCQAGxBIADIglABgQSwAw4OmO/cDRo0fNY7ds\n2WIa9+OPP5rn3Ldvn3msdbeNdaeNkzmdzBuNOSXp0UcfNY/dtm2beSyuHVeWAGBALAHAgFgCgAGx\nBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgO2OPcyXX35pGjd16lTznNHYmufkPxuPx2MeO2LE\nCNO4YDBonjMaa3WyhbS8vNw81slaCwoKTOPWrFljnhNXx5UlABgQSwAwIJYAYEAsAcCAWAKAAbEE\nAANiCQAGxBIADIglABgQSwAwYLtjDzN79mzTuGg8MVGyb3ecNWuWec4NGzaYxyYkJJjGjRw50jxn\nNFRUVJjHpqSkmMdG41y1tbWZ58TVmf626+rqNGPGDJWUlEiSTpw4ocWLFysrK0srVqzQ33//HdVF\nAoDbOo3luXPntHHjRgUCgfBrRUVFysrK0jvvvKMRI0YoFApFdZEA4LZOY+nz+VRcXHzZ26Oqqiql\np6dLklJTUx29JQGA3iim0wExMYqJuXxYa2urfD6fJCk+Pl5NTU3RWR0A9BDX/Gk4nw8B6A8iiqXf\n79f58+clSY2NjeZPMAGgt4oolpMmTVJZWZmkf+4C7eSu3QDQG3X6b5Y1NTXatGmTjh8/rpiYGJWV\nlWnz5s3Kzc1VaWmphg0bpvnz53fHWgHANZ3G8s4779Rbb711xetvvPFGVBYEAD1Rp7FEx6wPi5Kk\ndevWmcdad3BYd29ICm8msMjMzDSP7YusDyKbPHmyec5oPLBNkj799FPzWFw79oYDgAGxBAADYgkA\nBsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADtjtGyMkWRidbE4PBoGmck4eA3XvvveaxfZF1\nC6MkzZw50zTOyRbGaJx/yf2HtvU3XFkCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgFgC\ngAGxBACDfrHdsaWlxTx24cKFpnHWpzA69eCDD5rG9dUtjNZzZT1PkrR3717zWOs2xvb2dvOcTv5b\ncTIvuhdXlgBgQCwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBg0C928NTW1prH7tu3zzTO\nyUOonIzNzMw0j+2LrDtzrOdJis7DxZzsynFy/p2sFd2LK0sAMCCWAGBALAHAgFgCgAGxBAADYgkA\nBsQSAAyIJQAYEEsAMCCWAGDQL7Y7JiYmmscOHz7cNO7HH380z+lka1wwGDSNy8vLM88ZDQcPHjSP\nXbdunXms9YFds2fPNs9pPaeSfbvha6+9Zp6TB5b1DVxZAoCBKZZ1dXWaMWOGSkpKJEm5ubmaO3eu\nFi9erMWLF+vzzz+P5hoBwHWdvg0/d+6cNm7cqEAgcNnrq1atUmpqatQWBgA9SadXlj6fT8XFxUpI\nSOiO9QBAj9RpLGNiYnT99ddf8XpJSYmys7O1cuVKnT59OiqLA4CeIqIPeObNm6fVq1frzTffVHJy\nsrZu3drV6wKAHiWiWAYCASUnJ0uS0tLSVFdX16WLAoCeJqJYLl++XA0NDZKkqqoqJSUldemiAKCn\n6fTT8JqaGm3atEnHjx9XTEyMysrKtGjRIuXk5GjgwIHy+/3Kz8/vjrUCgGs6jeWdd96pt95664rX\nZ82aFZUFAUBP5Glnf9VlrNsYR48ebZ7TydP9rFvjojGnk3mj9XTDQ4cOmcbdcccd5jkHDx5sHmvl\n9XrNY50c/6OPPmoeu23bNvNYXDu2OwKAAbEEAANiCQAGxBIADIglABgQSwAwIJYAYEAsAcCAWAKA\nAbEEAIN+8XRHJ0aOHGkaV19fb55zy5Yt5rHW3afWpxA6mVOSnn76adM4699TX+Xk75SnO/YNXFkC\ngAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAE7eCI0atQo81geLNX3ONlB5eSBZU7m\nRffiyhIADIglABgQSwAwIJYAYEAsAcCAWAKAAbEEAANiCQAGxBIADIglABiw3RGIQLQeWHb06FHz\n2JaWFtO4wYMHm+fE1XFlCQAGxBIADIglABgQSwAwIJYAYEAsAcCAWAKAAbEEAANiCQAGxBIADDzt\nTvZtAZAkeb1e81gnT3d0sjXyyy+/NI279957zXPi6kx7wwsLC1VdXa0LFy5o6dKlGjdunNasWaOL\nFy9q6NChevHFF+Xz+aK9VgBwTaexrKysVH19vUpLS9Xc3KyMjAwFAgFlZWUpGAzqpZdeUigUUlZW\nVnesFwBc0en7g/Hjx+uVV16R9M/dS1pbW1VVVaX09HRJUmpqqioqKqK7SgBwWaex9Hq98vv9kqRQ\nKKSUlBS1traG33bHx8erqakpuqsEAJeZ/+V5//79CoVCysvLu+x1Ph8C0B+YYnno0CHt2LFDxcXF\nio2Nld/v1/nz5yVJjY2NSkhIiOoiAcBtncbyzJkzKiws1M6dOxUXFydJmjRpksrKyiRJ5eXlmjp1\nanRXCQAu6/TT8I8//ljNzc3KyckJv1ZQUKD169ertLRUw4YN0/z586O6SABwGz+UDkSAH0rvf3hg\nGRCBaD2wzMm8XOd0L/aGA4ABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgQCwBwIBYAoABsQQAA7Y7\nAhEoKCgwj123bp15rJOtkR6PxzwW144rSwAwIJYAYEAsAcCAWAKAAbEEAANiCQAGxBIADIglABgQ\nSwAwIJYAYMB2RyACU6dONY+N1tMdDx48aBrHo3C7BleWAGBALAHAgFgCgAGxBAADYgkABsQSAAyI\nJQAYEEsAMCCWAGDgaXeyZQCAJKmiosI8NiUlxTzWyW6fAQNs1zptbW3mOXF1XFkCgAGxBAADYgkA\nBsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADHlgGRFm0Hlhmnffo0aPmOUeNGmUe29+YYllY\nWKjq6mpduHBBS5cu1YEDB1RbW6u4uDhJ0pIlSzR9+vRorhMAXNVpLCsrK1VfX6/S0lI1NzcrIyND\nEydO1KpVq5SamtodawQA13Uay/Hjx+uuu+6SJA0ePFitra26ePFi1BcGAD1Jpx/weL1e+f1+SVIo\nFFJKSoq8Xq9KSkqUnZ2tlStX6vTp01FfKAC4yfwBz/79+xUKhbRnzx7V1NQoLi5OycnJ2rVrl7Zu\n3aq8vLxorhMAXGX60aFDhw5px44dKi4uVmxsrAKBgJKTkyVJaWlpqquri+oiAcBtncbyzJkzKiws\n1M6dO8Offi9fvlwNDQ2SpKqqKiUlJUV3lQDgsk7fhn/88cdqbm5WTk5O+LUFCxYoJydHAwcOlN/v\nV35+flQXCQBu4xk8QAScPINnypQp5rFO/nf0eDymcfX19eY5+aH0q2O7IwAYsN0RiMDYsWPNY4PB\noHnsJ598Yh5rfbqj9QoU/40rSwAwIJYAYEAsAcCAWAKAAbEEAANiCQAGxBIADIglABgQSwAwYG84\nABhwZQkABsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBA\nLAHAgFgCgAGxBAADYgkABv8HjazFqhcly+AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb0286da710>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_48rauOvQnQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3bc1edba-769b-417f-b102-ca687c5495c4"
      },
      "cell_type": "code",
      "source": [
        "training_examples.loc[rand_example]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     0.0\n",
              "2     0.0\n",
              "3     0.0\n",
              "4     0.0\n",
              "5     0.0\n",
              "       ..\n",
              "780   0.0\n",
              "781   0.0\n",
              "782   0.0\n",
              "783   0.0\n",
              "784   0.0\n",
              "Name: 7113, Length: 784, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "metadata": {
        "id": "YeBMIlw5REUx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2873
        },
        "outputId": "bd34152b-4d8a-4d8f-c9fa-c41e5ae29454"
      },
      "cell_type": "code",
      "source": [
        "training_examples.loc[rand_example].values.reshape(28,28)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.11372549, 0.33333333, 0.55294118, 0.99215686,\n",
              "        1.        , 0.99215686, 0.77647059, 0.33333333, 0.22352941,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.22352941,\n",
              "        0.65882353, 0.77254902, 0.98431373, 0.99215686, 0.98431373,\n",
              "        0.99215686, 0.98431373, 0.99215686, 0.98431373, 0.65882353,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.3372549 , 0.99215686, 1.        ,\n",
              "        0.99215686, 0.99607843, 0.99215686, 0.88627451, 0.65882353,\n",
              "        0.6627451 , 0.65882353, 0.77647059, 0.99215686, 0.99607843,\n",
              "        0.54509804, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.77254902, 0.98431373, 0.99215686,\n",
              "        0.98431373, 0.76862745, 0.3254902 , 0.21960784, 0.        ,\n",
              "        0.        , 0.        , 0.33333333, 0.98431373, 0.99215686,\n",
              "        0.98431373, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.55294118, 0.99215686, 1.        , 0.99215686, 0.44705882,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.22352941, 0.99607843, 0.99215686, 0.88627451,\n",
              "        0.21960784, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.99215686, 0.98431373, 0.76862745, 0.3254902 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.22352941, 0.87843137, 0.99215686, 0.98431373, 0.65882353,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.11372549, 0.77254902,\n",
              "        1.        , 0.99215686, 0.44705882, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.11372549, 0.77254902,\n",
              "        0.99607843, 0.99215686, 0.99607843, 0.99215686, 0.6627451 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.33333333, 0.98431373,\n",
              "        0.99215686, 0.98431373, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.77254902, 0.98431373,\n",
              "        0.99215686, 0.98431373, 0.99215686, 0.98431373, 0.65882353,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.22352941, 0.88235294,\n",
              "        0.99607843, 0.99215686, 0.77647059, 0.33333333, 0.33333333,\n",
              "        0.33333333, 0.55294118, 0.99215686, 0.99607843, 0.76862745,\n",
              "        0.6627451 , 0.65882353, 0.99607843, 0.99215686, 0.6627451 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.21960784,\n",
              "        0.99215686, 0.98431373, 0.99215686, 0.98431373, 0.99215686,\n",
              "        0.98431373, 0.99215686, 0.98431373, 0.32941176, 0.10980392,\n",
              "        0.        , 0.        , 0.99215686, 0.98431373, 0.65882353,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.22352941, 0.65882353, 0.6627451 , 0.65882353, 0.6627451 ,\n",
              "        0.21960784, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.99607843, 0.99215686, 0.6627451 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.99215686, 0.98431373, 0.65882353,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.99607843, 0.99215686, 0.77647059,\n",
              "        0.10980392, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.99215686, 0.98431373, 0.99215686,\n",
              "        0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.99607843, 0.99215686, 0.99607843,\n",
              "        0.32941176, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.54509804, 0.98431373, 0.99215686,\n",
              "        0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.33333333, 0.99215686, 0.99607843,\n",
              "        0.54509804, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.33333333, 0.98431373, 0.99215686,\n",
              "        0.98431373, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.33333333, 0.99215686, 0.99607843,\n",
              "        0.99215686, 0.22352941, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.10980392, 0.76862745, 0.99215686,\n",
              "        0.98431373, 0.21960784, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "6wJAZA5YQ5T0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2686
        },
        "outputId": "864f621b-d3d0-4ab5-f89b-daa12f4bc382"
      },
      "cell_type": "code",
      "source": [
        "training_examples.loc[rand_example].values"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.11372549, 0.33333333, 0.55294118,\n",
              "       0.99215686, 1.        , 0.99215686, 0.77647059, 0.33333333,\n",
              "       0.22352941, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.22352941, 0.65882353,\n",
              "       0.77254902, 0.98431373, 0.99215686, 0.98431373, 0.99215686,\n",
              "       0.98431373, 0.99215686, 0.98431373, 0.65882353, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.3372549 ,\n",
              "       0.99215686, 1.        , 0.99215686, 0.99607843, 0.99215686,\n",
              "       0.88627451, 0.65882353, 0.6627451 , 0.65882353, 0.77647059,\n",
              "       0.99215686, 0.99607843, 0.54509804, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.77254902, 0.98431373, 0.99215686,\n",
              "       0.98431373, 0.76862745, 0.3254902 , 0.21960784, 0.        ,\n",
              "       0.        , 0.        , 0.33333333, 0.98431373, 0.99215686,\n",
              "       0.98431373, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.55294118, 0.99215686,\n",
              "       1.        , 0.99215686, 0.44705882, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.22352941,\n",
              "       0.99607843, 0.99215686, 0.88627451, 0.21960784, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.99215686, 0.98431373, 0.76862745, 0.3254902 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.22352941, 0.87843137, 0.99215686, 0.98431373,\n",
              "       0.65882353, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.11372549, 0.77254902, 1.        ,\n",
              "       0.99215686, 0.44705882, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.11372549, 0.77254902, 0.99607843,\n",
              "       0.99215686, 0.99607843, 0.99215686, 0.6627451 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.33333333, 0.98431373, 0.99215686, 0.98431373, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.77254902, 0.98431373, 0.99215686, 0.98431373, 0.99215686,\n",
              "       0.98431373, 0.65882353, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.22352941, 0.88235294,\n",
              "       0.99607843, 0.99215686, 0.77647059, 0.33333333, 0.33333333,\n",
              "       0.33333333, 0.55294118, 0.99215686, 0.99607843, 0.76862745,\n",
              "       0.6627451 , 0.65882353, 0.99607843, 0.99215686, 0.6627451 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.21960784, 0.99215686, 0.98431373,\n",
              "       0.99215686, 0.98431373, 0.99215686, 0.98431373, 0.99215686,\n",
              "       0.98431373, 0.32941176, 0.10980392, 0.        , 0.        ,\n",
              "       0.99215686, 0.98431373, 0.65882353, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.22352941, 0.65882353, 0.6627451 , 0.65882353,\n",
              "       0.6627451 , 0.21960784, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.99607843, 0.99215686,\n",
              "       0.6627451 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.99215686, 0.98431373, 0.65882353, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.99607843,\n",
              "       0.99215686, 0.77647059, 0.10980392, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.99215686, 0.98431373, 0.99215686,\n",
              "       0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.99607843, 0.99215686, 0.99607843, 0.32941176, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.54509804, 0.98431373,\n",
              "       0.99215686, 0.3254902 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.33333333, 0.99215686, 0.99607843, 0.54509804,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
              "       0.98431373, 0.99215686, 0.98431373, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.33333333, 0.99215686, 0.99607843,\n",
              "       0.99215686, 0.22352941, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.10980392, 0.76862745, 0.99215686, 0.98431373, 0.21960784,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "metadata": {
        "id": "8v2b5wtCQ7Ql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ScmYX7xdZMXE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 1: Build a Linear Model for MNIST\n",
        "\n",
        "First, let's create a baseline model to compare against. The `LinearClassifier` provides a set of *k* one-vs-all classifiers, one for each of the *k* classes.\n",
        "\n",
        "You'll notice that in addition to reporting accuracy, and plotting Log Loss over time, we also display a [**confusion matrix**](https://en.wikipedia.org/wiki/Confusion_matrix).  The confusion matrix shows which classes were misclassified as other classes. Which digits get confused for each other?\n",
        "\n",
        "Also note that we track the model's error using the `log_loss` function. This should not be confused with the loss function internal to `LinearClassifier` that is used for training."
      ]
    },
    {
      "metadata": {
        "id": "cpoVC4TSdw5Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns():\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\" \n",
        "  \n",
        "  # There are 784 pixels in each image.\n",
        "  return set([tf.feature_column.numeric_column('pixels', shape=784)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k4TUt2L9Uvz3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMmL89yGeTfz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we'll make separate input functions for training and for prediction. We'll nest them in `create_training_input_fn()` and `create_predict_input_fn()`, respectively, so we can invoke these functions to return the corresponding `_input_fn`s to pass to our `.train()` and `.predict()` calls."
      ]
    },
    {
      "metadata": {
        "id": "OeS47Bmn5Ms2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_training_input_fn(features, labels, batch_size, num_epochs=None, shuffle=True):\n",
        "  \"\"\"A custom input_fn for sending MNIST data to the estimator for training.\n",
        "\n",
        "  Args:\n",
        "    features: The training features.\n",
        "    labels: The training labels.\n",
        "    batch_size: Batch size to use during training.\n",
        "\n",
        "  Returns:\n",
        "    A function that returns batches of training features and labels during\n",
        "    training.\n",
        "  \"\"\"\n",
        "  def _input_fn(num_epochs=None, shuffle=True):\n",
        "    # Input pipelines are reset with each call to .train(). To ensure model\n",
        "    # gets a good sampling of data, even when number of steps is small, we \n",
        "    # shuffle all the data before creating the Dataset object\n",
        "    idx = np.random.permutation(features.index)\n",
        "    raw_features = {\"pixels\":features.reindex(idx)}\n",
        "    raw_targets = np.array(labels[idx])\n",
        "   \n",
        "    ds = Dataset.from_tensor_slices((raw_features,raw_targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "    \n",
        "    # Return the next batch of data.\n",
        "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
        "    return feature_batch, label_batch\n",
        "\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OYlULlueainZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8zoGWAoohrwS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_predict_input_fn(features, labels, batch_size):\n",
        "  \"\"\"A custom input_fn for sending mnist data to the estimator for predictions.\n",
        "\n",
        "  Args:\n",
        "    features: The features to base predictions on.\n",
        "    labels: The labels of the prediction examples.\n",
        "\n",
        "  Returns:\n",
        "    A function that returns features and labels for predictions.\n",
        "  \"\"\"\n",
        "  def _input_fn():\n",
        "    raw_features = {\"pixels\": features.values}\n",
        "    raw_targets = np.array(labels)\n",
        "    \n",
        "    ds = Dataset.from_tensor_slices((raw_features, raw_targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size)\n",
        "    \n",
        "        \n",
        "    # Return the next batch of data.\n",
        "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
        "    return feature_batch, label_batch\n",
        "\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7qCsnIhLajwy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6DjSLZMu8Um",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_linear_classification_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear classification model for the MNIST digits dataset.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  a plot of the training and validation loss over time, and a confusion\n",
        "  matrix.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: An `int`, the learning rate to use.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    training_examples: A `DataFrame` containing the training features.\n",
        "    training_targets: A `DataFrame` containing the training labels.\n",
        "    validation_examples: A `DataFrame` containing the validation features.\n",
        "    validation_targets: A `DataFrame` containing the validation labels.\n",
        "      \n",
        "  Returns:\n",
        "    The trained `LinearClassifier` object.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "\n",
        "  steps_per_period = steps / periods  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create a LinearClassifier object.\n",
        "  my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  classifier = tf.estimator.LinearClassifier(\n",
        "      feature_columns=construct_feature_columns(),\n",
        "      n_classes=10,\n",
        "      optimizer=my_optimizer,\n",
        "      config=tf.estimator.RunConfig(keep_checkpoint_max=1)\n",
        "  )\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"LogLoss error (on validation data):\")\n",
        "  training_errors = []\n",
        "  validation_errors = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "  \n",
        "    # Take a break and compute probabilities.\n",
        "    training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
        "    \n",
        "    len(training_predictions)\n",
        "    \n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
        "    training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
        "    training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10)\n",
        "        \n",
        "    validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
        "    validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
        "    validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10)    \n",
        "    \n",
        "    # Compute training and validation errors.\n",
        "    training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_errors.append(training_log_loss)\n",
        "    validation_errors.append(validation_log_loss)\n",
        "  print(\"Model training finished.\")\n",
        "  # Remove event files to save disk space.\n",
        "  _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
        "  \n",
        "  # Calculate final predictions (not probabilities, as above).\n",
        "  final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
        "  final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
        "  \n",
        "  \n",
        "  accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
        "  print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.plot(training_errors, label=\"training\")\n",
        "  plt.plot(validation_errors, label=\"validation\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "  # Output a plot of the confusion matrix.\n",
        "  cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
        "  # Normalize the confusion matrix by row (i.e by the number of samples\n",
        "  # in each class).\n",
        "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
        "  ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
        "  ax.set_aspect(1)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.ylabel(\"True label\")\n",
        "  plt.xlabel(\"Predicted label\")\n",
        "  plt.show()\n",
        "\n",
        "  return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ItHIUyv2u8Ur",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Spend 5 minutes seeing how well you can do on accuracy with a linear model of this form. For this exercise, limit yourself to experimenting with the hyperparameters for batch size, learning rate and steps.**\n",
        "\n",
        "Stop if you get anything above about 0.9 accuracy."
      ]
    },
    {
      "metadata": {
        "id": "yaiIhIQqu8Uv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "outputId": "6d4a1869-ad02-4a67-a720-ad0a3a5ca5ee"
      },
      "cell_type": "code",
      "source": [
        "classifier = train_linear_classification_model(\n",
        "             learning_rate=0.02,\n",
        "             steps=100,\n",
        "             batch_size=10,\n",
        "             training_examples=training_examples,\n",
        "             training_targets=training_targets,\n",
        "             validation_examples=validation_examples,\n",
        "             validation_targets=validation_targets)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "LogLoss error (on validation data):\n",
            "  period 00 : 17.10\n",
            "  period 01 : 11.78\n",
            "  period 02 : 9.37\n",
            "  period 03 : 9.70\n",
            "  period 04 : 7.43\n",
            "  period 05 : 6.89\n",
            "  period 06 : 6.05\n",
            "  period 07 : 6.74\n",
            "  period 08 : 6.58\n",
            "  period 09 : 5.97\n",
            "Model training finished.\n",
            "Final accuracy (on validation data): 0.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFnCAYAAACLnxFFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xd8VfX9x/HXuffmZu/cTFZYIRBm\nQEVZCshwjypSolittpXWqnX9qnV1W62jrQOtA4tVqaBWEMWBiFUIAYFACCsQQvbe4977+yMQiJAQ\nIPfehLyfj4cPyblnfO7HI++c+TWcTqcTERER6fJMni5AREREOkahLSIi0k0otEVERLoJhbaIiEg3\nodAWERHpJhTaIiIi3YRCW6QTJCQkkJeX1ynrOnDgAEOHDu2UdXlCSkoKEyZMYObMmcyYMYPZs2fz\n2muvnfR6Nm/ezE033XTSyw0dOpQDBw6c9HIi3YHF0wWIyJnn7rvv5rLLLgOgsLCQa6+9lvj4eCZN\nmtThdYwYMYKXX37ZVSWKdEs60hZxofr6en7zm98wY8YMZs2axR//+EfsdjsAa9asYfLkycyaNYu3\n3nqLMWPGnPAIsaysjNtvv73lCPbFF19s+eyvf/0rM2bMYMaMGVx//fXk5+e3O/2w1atXc8kll7Sa\ndtlll/Hll1+ybt06rrjiCmbPns2sWbNYsWLFSffAZrMxc+ZM1q5dC8CuXbuYN28eM2bM4JJLLmHL\nli0AfPvtt8yZM4fbb7+du+66i2+//Zbp06efsI+rV69m+vTpzJo1i5deeqllu9XV1dx2223MmjWL\nqVOn8sADD9DY2HjS9Yt0JQptERd67bXXyMvL48MPP2Tp0qWkpqby3//+F7vdzn333cejjz7KihUr\nyMrKora29oTre/LJJwkODmblypUsXryYN998k9TUVHbu3MlHH33Ef//7X1auXMn06dP53//+1+b0\no40fP568vDyys7MByM7OJi8vj3PPPZc//elP3H///SxfvpznnnuOVatWnVIfmpqasFqtOBwObrvt\nNi677DJWrlzJww8/zM9+9jOampoA2LZtG3PmzOGJJ57ocB9//etf89BDD7FixQpMJlNLmC9btoyg\noCBWrFjBypUrMZvN7Nq165TqF+kqFNoiLvTFF19wzTXXYLFY8PHx4ZJLLmHt2rVkZWXR0NDA5MmT\ngebrwA6H44TrW716NXPnzgUgJCSE6dOns3btWoKCgigpKeGDDz6gvLyclJQULr/88janH81qtXL+\n+efz2WefAbBq1SqmTZuGxWIhPDycZcuWsXv3bvr163dMmHZEdnY2H330EdOnT2fPnj0UFxdz9dVX\nA5CcnExYWBgbN24EwMfHh/Hjx590HydMmADAFVdc0bLM4fV+9dVXOBwOHnnkERITE0+6fpGuRKEt\n4kIlJSUEBwe3/BwcHExxcTHl5eUEBQW1TI+MjOzw+o5eLigoiOLiYqKionj22Wf56KOPmDJlCrfc\ncgu5ubltTv++GTNmtArt2bNnA/D73/8eX19fbrzxRi688EI++uijDtX5+OOPt9yIduedd3Lfffcx\nYsQIKioqqKurY9asWcycOZOZM2dSXFxMWVlZS3/a+t5t9TEgIKDV9MNmzZrF/Pnzefrppxk/fjyP\nPPIIDQ0NHapfpKtSaIu4UEREREsgQfM16YiICAICAqipqWmZXlRUdFrrAzjnnHN48cUXWbt2LTEx\nMfzlL39pd/rRJk6cSEZGBllZWWRlZXHOOee0bO/BBx/kyy+/5De/+Q33338/1dXVJ6zz7rvv5qOP\nPmLlypW88847Lb8EREZG4u/vz0cffdTyz1dffdVy7fpkv3dwcDBVVVUt00tKSlotN2fOHN555x2W\nL19Oeno6y5YtO2HtIl2ZQlvEhaZMmcKSJUuw2+3U1NTw3nvvMXnyZPr160dTUxPffvstAG+++SaG\nYXRofW+99RbQHFCffPIJU6ZM4auvvuKRRx7B4XDg5+fHkCFDMAyjzenfZ7VamTBhAo8//jhTp07F\nbDbT2NhISkoKBQUFAAwbNgyLxYLJdOp/bcTFxREdHd1yxF5SUsKdd97Z6heYtr738frYp08fzGZz\nSx/ffffdlu/397//nSVLlgAQFRVFr169OtRjka5Mj3yJdJKUlBTMZnPLz7/97W9JSUkhOzubiy66\nCMMwmDlzJrNmzcIwDB5++GHuv/9+AgMDufHGGzGZTBiGgdPpxG63M3PmzFbrX7hwIb/85S95+OGH\nmTlzJiaTiVtuuYURI0ZQX1/Phx9+yIwZM7BarYSFhfH73/+eyMjI404/nhkzZvDzn/+cV199FQAv\nLy+uvvpq5s+fD4DJZOKBBx7A19eXTz75hM8++4w//OEPJ9UjwzB48sknefjhh3nqqacwmUzceOON\n+Pn5nbC3bfXxscce4//+7/+wWq1ceeWVLeu67LLLuP/++1m4cCGGYTBy5MiWx9BEuitD42mLeF5N\nTQ2jR48mNTWVwMBAT5cjIl2UTo+LeMhVV13F8uXLAVi+fDkDBgxQYItIu3SkLeIhqampPProo9TX\n1+Pv78/DDz/MiBEjPF2WiHRhCm0REZFuQqfHRUREugmFtoiISDfRpR/5Kiys7PR1hob6UVra/jOh\ncvrUZ/dQn91DfXYP9bmZzdb2Dak97kjbYjGfeCY5beqze6jP7qE+u4f6fGI9LrRFRES6K4W2iIhI\nN6HQFhER6SYU2iIiIt2EQltERKSbUGiLiIh0EwptERGRbkKhLSIiZ4Qvvvi0Q/M9/fQTHDyY0+bn\n9913Z2eV1OkU2iIi0u3l5h5k1aqVHZr39tvvIjY2rs3P//jHJzurrE7XpV9jKiIi0hFPPvkntm9P\nZ+LEcVx44Sxycw/y1FP/4A9/eJTCwgJqa2v50Y9u4bzzJrJgwS3ceec9fP75p1RXV7F//z5ycg7w\ni1/cxfjx53HRRVP58MNPWbDgFsaNO5u0tFTKysr405/+SkREBI8++iB5ebkMHz6Czz5bxdKly932\nPXtMaDudTlZmrmOyaQS++Hq6HBGRM9bbn+1ifUbBSS9nNhvY7ccfLXrckEiuuWBgm8ted10K7777\nNvHxA9i/P4t//OMlSktLOOusc5g162Jycg7w4IP3cd55E1stV1CQz1/+8gzffPM17733H8aPP6/V\n5/7+/jz99HM899yzfPnlZ8TG9qKhoZ4XX3yVtWvX8Pbbb5709zwdPSa0S6qr+SDnP6w5sI7fTf25\np8sREREXSUwcBkBgYBDbt6fz/vvvYhgmKirKj5l3xIhRAERGRlJVVXXM5yNHjm75vLy8nH379jJ8\n+EgAxo8/D7PZve9L7zGhHebvj6kumDLvA5TWlBPqF+zpkkREzkjXXDCw3aPitthsgZ0yuqOXlxcA\nn3zyERUVFfz97y9RUVHBzTenHDPv0aHrdB57lP/9z51OJyZT8zTDMDAM47TrPRk95kY0wzDo5zME\nDCfLd3zr6XJERKQTmUwm7HZ7q2llZWXExMRiMplYvfozGhsbT3s7cXG92LFjGwDr1n1zzDZdrceE\nNsDUAWfjdMJ3Rd95uhQREelEffvGs2NHBtXVR05xT5lyAV9/vYbbb/8pvr6+REZG8sorC09rO+ee\nO5Hq6mp++tOb+O67jQQFufesreE83vmALqIzTpMczeF0cvt//4LDv5DfnH03Uf62Tl2/HNFZp7mk\nfeqze6jP7tEd+lxRUU5aWipTpkylsLCA22//KYsX/6dTt2GzBbb5WY+5pg1gMgwGBw4jw/EFKzO/\n4frRl3i6JBER6Ub8/Pz57LNVLF68CKfTwc9/7t4XsfSo0Aa4OOlctm/6ku9KNuN0Xuz2mwhERKT7\nslgsPProHzy2/R51TRtgzOA4jIoo6oxy9lUe8HQ5IiIiHdbjQttiNjHAdygAq3brLnIREek+elxo\nA0weOApnkxfppVuwO9x7u76IiMip6pGhPSI+AspiaKCWHaW7PF2OiIhIh/TI0PaymBng13yKfHXW\neg9XIyIi7nL11ZdQU1PDokWvsnXr5laf1dTUcPXV7T9VdHj4z+XLP2D16s9dVmdbetzd44dN6D+U\nXftWs718Ow32Bqxmq6dLEhERN0lJmX/Syxwe/nPKlKnMnu2ZR4Z7bGiPHBiBc2Ms9pjdbC7axtio\nUZ4uSURETtGPfvRDfv/7J4iOjiYvL5f7778Lmy2S2tpa6urquOOOuxk6NKll/t/97mGmTJnKqFGj\n+fWv76GhoaFl8BCAjz9ewZIlb2E2m+jXbwD33vvrluE/X3llIQ6Hg5CQEK666lr+8Y+n2bLlO5qa\n7Fx11TXMnHnRcYf1jI6OPu3v2WND28dqYYBvIlns5qvsVIW2iEgneXfXf9lYsOWklzObDOyO47+k\nc3TkcK4ceHGby06adD5r137JVVddw5o1q5k06XwGDBjEpElT2LBhPf/612v87nePH7PcypUr6N9/\nAL/4xV18+unHrFq1EoDa2lqeeOJZAgMDue22H7N7966W4T9vvPHHvPzyCwBs2pTGnj27ee65f1Jb\nW8sNN8xh0qQpwLHDel5zzdyT7sn39chr2oedO2gQjuogdlXsoqqh2tPliIjIKWoO7TUAfPXVaiZM\nmMzq1Z/y05/exHPPPUt5+bHDcgJkZe0hKal5qM3Ro5NbpgcFBXH//XexYMEt7Nu3l/LysuMun5Gx\njVGjxgDg6+tLv379yc7OBloP63m8YT9PRY890obmU+Svb4jF5J9BWsF3TOp1rqdLEhHp9q4ceHG7\nR8VtOZ13j/fvP4Di4kLy8/OorKxkzZoviIiI5MEHHyMjYxt/+9tTx13O6QSTqfnNmI5DR/mNjY08\n+eSfefXVxYSHR3DPPb9sc7uGYXD0CB5NTY0t6zvRsJ+nokcfaQf4ehHvl4DTCV/nbPB0OSIichrG\nj5/Aiy/+g4kTJ1NeXkZcXC8AVq/+nKampuMu06dPXzIytgOQlpYKQE1NNWazmfDwCPLz88jI2E5T\nU9Nxh/8cMmQYGzduOLRcDTk5B+jVq4+rvmLPDm2Aswf1w1ERTnZ1NkW1xZ4uR0RETtHkyee33N09\nc+ZFvPXWv7jjjtsYNiyJ4uJiPvzw/WOWmTnzItLTt3D77T8lO3sfhmEQHBzCuHFnc/PN1/PKKwuZ\nOzeFZ555smX4z2eeeaJl+ZEjR5GQMITbbvsxd9xxGz/5yQJ8fX1d9h171NCccOzpl7Kqeu7591t4\n9d/KxfEzmBU/tdO32RN1hyH2zgTqs3uoz+6hPjdrb2jOHn+kHRLgTR/fwTgdJr7NTeu06w4iIiKd\nrceHNsC4QbHYSyMprCskuzLH0+WIiIgcl0IbGDPYhr04FoD1+Rs9XI2IiMjxuTS0MzMzmTZtGm+8\n8QbQfBv9XXfdxdVXX80NN9zQ5nNz7mYL8aWXdzzOJi/W523E4XR4uiQREZFjuCy0a2pqeOyxxxg/\nfnzLtLfffpvQ0FCWLFnC7NmzSU1NddXmT1pyQhT24mgqG6s08peIiHRJLgttq9XKwoULiYyMbJn2\n+eefc+mllwJw7bXXMnVq17lTO/noU+R5OkUuIiJdj8tC22Kx4OPj02paTk4OX375JSkpKdxxxx2U\nlR3/tXCeEBvhT6R3LM56XzYVbqHB3uDpkkRERFpx62tMnU4n8fHxLFiwgH/84x+88MIL3HvvvW3O\nHxrqh8VibvPzU9XWM3ATR/Vi6Y4Y6r33sK9hL+f2Gdvp2+5J2nvWUDqP+uwe6rN7qM/tc2toR0RE\nMG7cOAAmTJjAs88+2+78paU1nV5Dew/vD+0dwpK1sXjF7uHTnV8zyDeh07ffU+glCe6hPruH+uwe\n6nOzLvNylUmTJrFmTfMoLOnp6cTHx7tz8yfUJyqAMGsE1AaRXrxDI3+JiEiX4rLQ3rp1KykpKSxd\nupTXX3+dlJQULrvsMlavXs11113HqlWruOWWW1y1+VNiGAbJCTYaC2NwOB2kFWz2dEkiIiItXHZ6\nPCkpiUWLFh0z/ZlnnnHVJjvFmME2Pt4Ug1fvHazP38ikXuNPvJCIiIgb6I1o3zMwLpggaxBUR7Cn\nPIui2hJPlyQiIgIotI9hMhmMGRRBQ0E0AKl6ramIiHQRCu3jSE6IxF4aheE0sy5vo0b+EhGRLkGh\nfRwJfULws/hiVEaRX1NAdpVG/hIREc9TaB+HxWxi1KAIavOiAL3WVEREugaFdhuSB9twlNuw4M2G\n/E0a+UtERDxOod2GYfFheFu8MMpjKG+oJLN0t6dLEhGRHk6h3Qarl5nhA8KpymkepUynyEVExNMU\n2u1IHmzDURWKDwGHRv5q9HRJIiLSgym02zFiQDgWswmjLI46ez1birZ5uiQREenBFNrt8PW2MLRf\nGKXZEQCsz0/zcEUiItKTKbRPIHmwDWdtIEGmiOaRvxo18peIiHiGQvsERg2KwGQYOEticTgdbNTI\nXyIi4iEK7RMI9LOS0CeEgr1hGBis013kIiLiIQrtDhgz2AaNPkSY49hTnkWxRv4SEREPUGh3wJjB\nNgAcJbEArM/f5MlyRESkh1Jod0BooDcDYoPI2R2IxbCwPi9NI3+JiIjbKbQ7KDkhEmeTF9Fe8eTV\nFHCg6qCnSxIRkR5God1BYwY3P6ttL4oBYF2entkWERH3Umh3UGSoH70jA9i/ywdfi69G/hIREbdT\naJ+E5ME2mppM9PIaqJG/RETE7RTaJ2FMQvNd5I2FzafINfKXiIi4k0L7JMRF+BMV5sfunWZCvUM0\n8peIiLiVQvskGIZB8mAbDY1OelsTqLPXs7V4u6fLEhGRHkKhfZKSD50ir8+PBnQXuYiIuI9C+yT1\niw4kNNCbzJ124vxj2Fa8g+rGGk+XJSIiPYBC+yQdPkVeU99Eb2sCdqedNI38JSIibqDQPgWHT5HX\n5UdhYLBep8hFRMQNFNqnYFCvEAL9vEjPrGFgSH92a+QvERFxA4X2KTCZDEYPslFR00gfawKgkb9E\nRMT1FNqn6PAp8uq8CCwmC+vzN2rkLxERcSmF9ilK7BuKr7eFzZnlJIUPIa86nwNVuZ4uS0REzmAK\n7VNkMZsYNTCc4op6+noPAdANaSIi4lIK7dMwZnAkAOUHQ/C1+JKqkb9ERMSFFNqnIal/GFaLibTM\nEkbbhlPeUMHO0j2eLktERM5QCu3T4O1lZnj/cPJLaoj3TQRgXb5OkYuIiGsotE/T4eE6iw74No/8\nVbBVI3+JiIhLKLRP08gBEZhNBmk7ixgbNYo6e51G/hIREZdQaJ8mPx8LQ/uFsT+/ioH+QwFYn7fR\nw1WJiMiZyKWhnZmZybRp03jjjTdaTV+zZg0JCQmu3LRbHX7RyoH9JuICYkgvztDIXyIi0ulcFto1\nNTU89thjjB8/vtX0+vp6XnzxRWw2m6s27XajBkZgGJCWWci4qNEa+UtERFzCZaFttVpZuHAhkZGR\nraY///zzzJ07F6vV6qpNu12Qv5XBvULYlVPOoIChh0b+0ilyERHpXBaXrdhiwWJpvfq9e/eSkZHB\n7bffzuOPP37CdYSG+mGxmDu9NpstsNPXOTm5NzuyyygsMTE0chDpBZng14DNP7zTt9VduKLPciz1\n2T3UZ/dQn9vnstA+nj/84Q888MADHZ6/tLTzrwvbbIEUFlZ2+noHxzbvaKs3ZDN+0nDSCzJZue0r\nZvS7oNO31R24qs/SmvrsHuqze6jPzdr7xcVtd4/n5+ezZ88efvWrX3HNNddQUFDAvHnz3LV5lwsL\n8iE+JoiMfWUMDkzEYphZp5G/RESkE7ntSDsqKopVq1a1/HzBBRccc1d5d5ecYGNvbgU79laTFJHI\npsKtHKjKpXdgrKdLExGRM4DLjrS3bt1KSkoKS5cu5fXXXyclJYWysjJXba5LSB7cfEd8WmYh46LH\nALBerzUVEZFO4rIj7aSkJBYtWtTm55999pmrNu0xUWF+9LL5s3VvCTdedA6+Fl825H/H5QNmYzL0\nHhsRETk9SpJONmawjSa7g+1Z5Yy2Daesvlwjf4mISKdQaHey5ITm59I37CjkrOjRAKzP1zPbIiJy\n+hTanayXzZ/IEF827y6mT0AfQr1D2FiwhUaN/CUiIqdJod3JDMNgTIKN+kY727PKW0b+2qKRv0RE\n5DQptF3g8AAiGzILGHfoFHmqXmsqIiKnSaHtAvExQYQGerNpZxFRvlHE+kezVSN/iYjIaVJou4DJ\nMBgzyEZ1XRM7sssYF9088tdGjfwlIiKnQaHtImMOnSJP29E8XCfoLnIRETk9Cm0XGdw7mABfL9Iy\nCwn2DmZQSH92le2luLbU06WJiEg3pdB2EbPJxOhBEZRXN7Anp6LlhrQN+Zs8XJmIiHRXCm0XOvou\n8tG2EYdG/krTyF8iInJKFNoulNg3DB+rmQ07CvG1+DAsIpHc6nxyqnI9XZqIiHRDCm0X8rKYGDkw\ngqLyOvbnV3GWbkgTEZHToNB2scPDdW7ILGRY+BB8LT6k5m/C4XR4uDIREeluFNouNrx/OF4WE2mZ\nhXiZvVpG/tpVppG/RETk5Ci0XczbaiYpPoyDRdXkFlczLnoMAOv1WlMRETlJCm03aLmLfEchA0Pi\nCfEOJk0jf4mIyElSaLvByIERmE0GGzILMRkmxkWNps5ex9biDE+XJiIi3YhC2w38fbwY0jeUfXmV\nFJXXtrxoRXeRi4jIyVBou8nhU+RpmUXEBcQQ6x9NetF2ajTyl4iIdJBC201GD7JhAGk7CgAYFz2a\nJqedjQVbPFuYiIh0GwptNwn2tzKoVzA7D5RTXt3A2KhRAKzLT/NwZSIi0l0otN1oTEIkTmBjZiFh\nPqEMDIlnV9leSuo08peIiJyYQtuNxgyOAJrfjgZwVlTzM9upGvlLREQ6QKHtRhHBvvSLDiRjXynV\ndY2MjhyOxTDrRSsiItIhCm03S06wYXc4+W5XEX5efgyLSORgdZ5G/hIRkRNSaLvZmMFH3o4GMO7w\nyF862hYRkRNQaLtZTLg/sRH+bN1bQl1DE0mHRv5an79RI3+JiEi7FNoeMGawjcYmB1v3lHxv5K+9\nni5NRES6MIW2B4xNODLGNnDktaZ5emZbRETaptD2gN6RAUQE+/DdriIamxwMDOlPiHcwGws18peI\niLRNoe0BhmGQnGCjrsHO9n0lmAwTY6NGUdtUR7pG/hIRkTYotD0keXAkAKnfu4t8nUb+EhGRNii0\nPaR/XBDBAVY27SzC7nAQFxBDjH+URv4SEZE2KbQ9xGQYjBlso6q2kczscgzD4KyoMc0jfxVq5C8R\nETmWQtuDkg+9aCXt0Cny5EMjf+lFKyIicjwKbQ8a3DsEfx8LaTsLcTidhPs2j/y1s2yPRv4SEZFj\nKLQ9yGI2MWpQBKWV9ew9WAEcuSFNI3+JiMj3dTi0q6qqACgqKiI1NRWH48Sv3MzMzGTatGm88cYb\nAOTm5jJ//nzmzZvH/PnzKSwsPMWyzxyH7yI//KKV0ZEjMGvkLxEROY4OhfZjjz3GihUrKCsrY86c\nOSxatIiHH3643WVqamp47LHHGD9+fMu0p556imuuuYY33niD6dOn88orr5xW8WeCYfGheFvNpO0o\nxOl04u/lR1L4EI38JSIix+hQaG/bto0f/OAHrFixgiuuuIKnn36affv2tbuM1Wpl4cKFREZGtkx7\n6KGHmDFjBgChoaGUlZWdRulnBi+LmZEDwikoq+VAYTUAY6M18peIiByrQ6HtdDoB+OKLL7jgggsA\naGhoaHcZi8WCj49Pq2l+fn6YzWbsdjuLFy/mkksuOZWazzhHhussAGB4eCI+Zh9S8zdp5C8REWlh\n6chM8fHxzJ49m7CwMBITE1m2bBnBwcGntEG73c4999zDOeec0+rU+fGEhvphsZhPaTvtsdkCO32d\np+P8QB9e/nA7m/eU8OMrRwIwvs8YPt/7NcXkM9Q22MMVnpqu1uczlfrsHuqze6jP7etQaP/2t78l\nMzOTAQMGADBo0KCWI+6Tdf/999O3b18WLFhwwnlLSzv/zWA2WyCFhZWdvt7TNaxfGJt2FbF1Rz5R\nYX4MD07ic77m44y12IwYT5d30rpqn8806rN7qM/uoT43a+8Xlw6dHt++fTt5eXlYrVb++te/8uc/\n/5nMzMyTLuT999/Hy8uLX/ziFye97Jku+XvDdQ4KPTzy12aN/CUiIkAHQ/u3v/0t8fHxpKamsmXL\nFh588EGeeeaZdpfZunUrKSkpLF26lNdff52UlBSef/55tm3bRkpKCikpKSe8A70nGTkwApNhsOHQ\n29FMhonkqJEa+UtERFp06PS4t7c3/fr146233uKaa65h4MCBmEzt531SUhKLFi3qlCJ7ggBfL4b0\nDWFbViklFXWEBfkwLmoMn+7/kk+z1zA8YihmU+df3xcRke6jQ0fatbW1rFixglWrVjFhwgTKysqo\nqKhwdW09Tsu7yA+dIu8VEMMoWxJ7yrN4b88KT5YmIiJdQIdC+8477+SDDz7gzjvvJCAggEWLFjF/\n/nwXl9bzjB5sw4CWU+SGYTAv8Roi/SL4dP+XpBVs9myBIiLiUR06PX7OOecwYsQI9u7dy7Zt27j5\n5pvx9fV1dW09TkiANwN6BZN5oIyK6gaC/K34Wny4ZfgN/Dn1WRZtf5sY/yhi/KM8XaqIiHhAh460\nV61axYUXXshDDz3EAw88wIwZM1i9erWra+uRkgfbcDph066ilmkx/lGkJF5Dg72BF7e8Rm1TnQcr\nFBERT+lQaL/00ku8//77LFmyhHfffZd33nmH5557ztW19UhH3o7WejCVMZEjmNp7EgU1RSza/nbL\nW+pERKTn6FBoe3l5ERYW1vJzVFQUXl5eLiuqJ7OF+NInKoBtWSXU1DW1+uyyAbMYFNKf7wq38sm+\nLzxToIiIeEyHQtvf359//vOfZGRkkJGRwUsvvYS/v7+ra+uxkgfbsDucfLe7qNV0s8nMTUnzCPEO\n5v09H5FRstNDFYqIiCd0KLR/97vfkZWVxX333cf9999PTk4Ov//9711dW481JqF5ZLS0HceONx5o\nDeDmpHmYDBP/TP8XxbWl7i5PREQ8pEN3j4eHh/Poo4+2mrZ79+5Wp8yl88RF+BMT7seWPcXUN9rx\n9mr9UpX44L78YPCl/HvHUl7czoVJAAAgAElEQVTa+jp3jvkZXmZdrhAROdN16Ej7eB555JHOrEO+\nZ8xgGw1NDrbuKTnu5xNiz+Gc6LHsr8zh7cxlbq5OREQ84ZRDW3cvu9bhAUTSMguO+7lhGFybcAW9\nA+P4Onc9a3O+dWd5IiLiAacc2oZhdGYd8j19owIJD/Jm065imuyO485jNXvx46QU/C1+vJ25jKyK\n/W6uUkRE3Knda9pLlixp87PCwmNvkpLOYxgGYwZH8klqNtv3lTK8f/hx5wv3DePGYXP5+3cv89KW\nN7h33C8ItAa4uVoREXGHdkN7w4YNbX42atSoTi9GWktOsPFJajZfbMwhKT6szbMbieGDubj/hXyw\nZyX/TF/MgpE3aUQwEZEzULuh/Yc//MFddchxDIwLJj4mkI07i3hz1U6umzaozeC+sO/5ZFVks6Vo\nGx/sWcnlA2e7uVoREXG1Dj3yNXfu3GPCwmw2Ex8fz89+9jOiojSAhSuYTAa//MFI/vzmRlZtOICX\nl4mrJw84bnCbDBM3DL2WP69/lk/2f0HfoN6MjhzugapFRMRVOnQj2rnnnkt0dDQ33HADN954I717\n9yY5OZn4+Hjuv/9+V9fYowX6WfnVnNFEhfmx4pv9vL82q815fS2+/Hj49VhNXiza/hZ51fnuK1RE\nRFyuQ6G9YcMGnnjiCS688EKmTZvGH//4R9LT05k/fz6NjY2urrHHC/a3cvecUUQE+/DeV3tZ8c2+\nNueNDYhmXuIPqLc38OKWRdRpRDARkTNGh0K7uLiYkpIjL/morKzk4MGDVFRUUFlZ6bLi5IiwIB/u\nuW40oYHevPPFblalZrc5b3LUKC7oPZH8mgIWbX9Hz9SLiJwhOnRN+/rrr2fWrFnExcVhGAYHDhzg\n1ltv5fPPP+faa691dY1ySESIL/dcN5o//iuNxat2YvUyM2lk7HHnvXzAbPZXHmBT4RZW7V/N9L5T\n3FusiIh0OsPZwcOwqqoqsrKycDgc9OnTh5CQEFfXRmFh5x/F22yBLlmvO+UUVvGnxRuprm3k5ouH\nMj4p+rjzVTRU8sd1T1PRUMmCUTczJGyQ22o8E/rcHajP7qE+u4f63MxmC2zzsw6dHq+urua1117j\nb3/7G8899xxvvfUWdXW6VuopcbYA7rp2FL7eFl76cBupGcd/1WmQNZCbh6dgMky8kr6YkjqNCCYi\n0p11KLQffPBBqqqqmDNnDtdccw1FRUU88MADrq5N2tE3OpA7rh2Jt5eZF95PZ9OuouPO1z+4L1cP\nuoSqxmpe2vIGjXbdOCgi0l11KLSLioq49957mTJlCueffz6//vWvyc/X40SeNiA2mF/+YCRms8E/\nlm4hfe/xRwSbGDees6OT2VeZzTs733NzlSIi0lk6FNq1tbXU1ta2/FxTU0N9fb3LipKOG9w7hJ9f\nNQIwePY/m9mx/9hT4IZhMCfhSnoFxLL24Dq+PrjO/YWKiMhp61BoX3vttcyaNYsFCxawYMECLrro\nIubOnevq2qSDhvUL47YrkrA7nDy1ZDO7c8qPmcdq9uLHw6/Hz+LLW5nL2FfR9iNjIiLSNXUotK++\n+mrefPNNLr/8cq644gr+/e9/s2vXLlfXJidh5MAIbr10GI2NDp58+zv25R17B2bEoRHB7A47C7cs\noqqh2gOViojIqerweNoxMTFMmzaNqVOnEhUVxebNm11Zl5yCsUMiufniROrqm3jirU0cKKw6Zp6h\n4QlcFH8hpfVlvJK+GIfz+GN1i4hI19Ph0P4+vWWrazpnWDTzZw2hqraRv/x7E3klNcfMM6Pf+QyP\nSCSjdCcf7FnpgSpFRORUnHJotzVEpHjexJGx/HD6YCqqG3j8zY0UltW2+txkmLg+cQ4233A+3vc5\nmwq3eqhSERE5Ge2+xnTy5MnHDWen00lpqV7U0ZVNTe5FY5ODtz/fxeNvbuS+H44hLMin5XM/L19u\nGX4Dj6c+y6JtbxE9NpJo/0gPViwiIifSbmgvXrzYXXWIC8w8uw8NTXaWrdnbEtzBAd4tn8cGRPPD\nxB/wSvpiFm55nbvHLsDH4tPOGkVExJPaDe24uDh31SEucsm5/WhodLD8m3385d+buGfuaAL9rC2f\nj40aRVbFfj7P/oo3tr/DTUnzdOlDRKSLOuVr2tI9GIbBVZP7M21sL3KKqnni35uormv9KtMrBlzE\nwJB4Nh4aEUxERLomhXYPYBgG100dxORRsewvqOLJt76jtr6p5XOzycyPhs0j2BrEe7tXsKNEz+CL\niHRFCu0ewjAMUmYkcG5SNHtzK3j6ne+ob7C3fB7sHcjNw+dhMkz8M/1flNaVebBaERE5HoV2D2Iy\nDG6cPYRxQyLJPFDOs+9uprHpSHD3D+7HVYdGBFu4dRGNjqZ21iYiIu6m0O5hzCYTP75kKKMGRrAt\nq5S/L91Kk/3IW9EmxY3nrOgx7KvI5p1MjQgmItKVKLR7IIvZxE8vT2JYfBibdxfzwvvp2B3NwW0Y\nBtclXElcQAxrD37L1wfXe7haERE5zKWhnZmZybRp03jjjTcAyM3NJSUlhblz53L77bfT0NDgys1L\nO7wsJhZcOZwhfULYsKOQlz/cjsPR/Gpaq9nKLS0jgi3ViGAiIl2Ey0K7pqaGxx57jPHjx7dMe+aZ\nZ5g7dy6LFy+mb9++LFmyxFWblw7w9jLz86tGMCAuiG/S83ntowwch94pH+Ebzvxh12lEMBGRLsRl\noW21Wlm4cCGRkUdejfntt98ydepUAM4//3z+97//uWrz0kG+3hbu+MFI+kYFsmZzLm9+srNlMJhh\n4UOYHT9NI4KJiHQR7b4R7bRWbLFgsbRefW1tLVZr89u4wsPDKSwsbHcdoaF+WCzmTq/NZgvs9HV2\nd7+/bQK/fm4tn6YdIDjIh/kXD21+TCzicnLr80g7uIVP8z5n7ojLO7xO9dk91Gf3UJ/dQ31un8tC\n+0Q6MrRnaemxw0qeLpstkMLCyk5f75ng9qtH8Kd/pfHuF7toamzi8on9AbhuwNXsLz3Isu0ribRE\nMdKWdMJ1qc/uoT67h/rsHupzs/Z+cXHr3eN+fn7U1dUBkJ+f3+rUuXhesL+Vu68bjS3Eh/fXZrH8\nm33A4RHBrsfL5MXr294iv7rAw5WKiPRMbg3tc889l5UrVwLw8ccfM3HiRHduXjogNNCbu+eMJizI\nmyVf7OaT9c13jscFxPDDIVdTZ6/nxa2LqGuq93ClIiI9j8tCe+vWraSkpLB06VJef/11UlJSWLBg\nAcuWLWPu3LmUlZVx+eUdvz4q7hMR4svdc0YTHGDlzU938sWmHADGRY9mSq/zyKvO542Mdzp0iUNE\nRDqP4ezCf/O64tqGrpl0XE5RNX/6VxrVtY3cdHEi5ybFYHfYeXrjC+wuz+KKgRcxrc/k4y6rPruH\n+uwe6rN7qM/Nusw1bele4iL8+dWcUfh6W3j5w+2szyjAbDJzU9I8gqyBvLd7BZmluz1d5imzO+zk\nVuezIX8TH+xZybq8NE+XJCLSLo/dPS7dQ5+oQO6aM4rH39zIi++nYzEbjB5k4+akFJ7a+Dwvb32D\n+8bdTqhPiKdLbZPT6aS0voyDVXkcrM5r+Xd+dQFNTnurec2GmeSokR6qVESkfTo9Lh2SmV3Gk29v\nwuFw8ourR5AUH84X2Wt5Z+d79Avqwy/H/AQv05HfAT3V5+rGmqPCOffQv/Ops9e1ms9q8iImIJpY\n/2iifKNoqvfik9zlOLBzx5if0jeot9trPxXan91DfXYP9blZe6fHFdrSYduySnjqnc2YDLjjmpEM\n7h3Ca9v+zfr8jUyIO4frEq5smdfVfW6wN5JXk98c0EcdQZc3VLSaz2SYiPSNIDYgmlj/GKL8IjE3\nBFFWbGFfXiV7cys5UFiF3eHEz1YC8esJsgZw99ifd+mzB4dpf3YP9dk91Odm7YW2To9Lhw3tF8aC\nK5N49j9beOqdzdw1ZxRzh1zFweo8vsr5hn5BfRgfM7ZTt+lwOiisLf7eqe1cCmuKcdL6981Q7xCG\nhQ8h1j+a2IBoov2icNb6k51fS9bBCjbkVbI/v5gm+5E38VnMBn2iAgkJsLJxJ8SEjaIseCMvbH6V\nO5J/hrfZ2qnfR0TkdOhIW07ahh2FPLdsK95WE3dfNxr/oEb+lPoMjY5G7kr+GX0Ce510n51OJ+UN\nFeRW5ZNTncvBqjxyq/PIrS6g0dHYal5fiy+x/tHEBUS3OoKurHSSlVdJVm4lWXkV7MuvpKHxyPvS\nzSaDXrYA+sUE0i86kH7RQcTZ/LGYTTidTv6+dCtpmQUMOiebA45tjLIlcVPSPExG171fU/uze6jP\n7qE+N9Pp8aNop+gc32zLY+H72/DzsXDv3DGUmbJ5bvMrhPmEcu+4XxAfG91mn2ub6sitziPn0Knt\n3ENH0NVNrV9bazFZiPGLJDYghtiAaGIOBXWQVyBFFfVk5VYcCunmgK6tP3JTmWE03/3eLzroUEgH\n0TvSH6923mVfVdvIQ/9cR3l1HQMmZnCgdh8z+l7ApQNmdk7TXED7s3uoz+6hPjdTaB9FO0XnWbP5\nIK8szyDIz4t7fziGtPK1LM9aRWLYYB6aejv5heXk1xSSU5VLbnU+B6tyyanKo7S+rNV6DAxsvuEt\nwRwbEE2cfzQRvuGYDBOllfXsPXT0fDioq+uajloeosP9Wo6e+8UE0icyEG/ryQ82s2N/KX9+cyOh\nwQb+I9ZRVFfM9YnXcnZM8um2yyW0P7uH+uwe6nMzXdMWl5g4IpbGJgdvfJzJX/69iXvmnse+ygOk\nF2ew4MMHKaktO2Y4z2BrIENCBzWf1g6IIdY/ihj/KKyHrh2XVzUH9P92VJCVl0tWbgUVNa1Pj0eG\n+DIsPox+0UHExwTSJyoQX+/O2ZUT+oRyybn9eH9tFnFFE6gO+ZjFGUuw+YXTP7hfp2xDRORUKbTl\ntFwwpheNTQ7e+mwXf3nzO26/9gqKa1+mvKGCvoG9D11zjm75d4DVv2XZypoGsvIq2bwlp/k0d14l\npZWt32keHuRNcoKt+Sg6Joi+UYEE+Hq59Dtdcl4/tu0rZcu2cmZOncWaqmW8sPk17hn7c8J9w1y6\nbRGR9uj0uHSKD9buZemavUSG+nLv3NEMio+gqKiq5fOausaWYM7KrWBvbiXFFa2fnQ4OsBJ/1DXo\nftGBBPl75u7tovJaHv7nepocDi66GD7KWU6sfzR3Jf8MH4uPR2o6Hu3P7qE+u4f63EzXtI+incJ1\n/rN6Nx/+bx+xEf7ceuUItu0qZO+ha9AFpbWt5g3w9SI+JujQEXRzSIcGenuo8uNLzSjgH8u20jsy\ngMRzc1hz8H8khQ/h1hHzu8wd5dqf3UN9dg/1uZmuaYtbXDmpPw2NDj5JzeahF//XMt3P28LQfqEt\nR8/xMUGEBXljGIYHqz2xsUMimTwqltWbDjI4O5FEWzFbizNYtms5Vw662NPliUgPpNCWTmMYBnOm\nDiQqzJfqBgdRwd70iw7EFuLb5QO6LXOmDiIzu4xPNxzkJ1fOorSujE+zvyTaP5JzY8/ydHki0sN0\njXN8csYwDIMLxvTiR5cM46zEKCJD/bptYAN4e5m59dJhWMwm3lixh+sG/BB/Lz/e3PFutx7hTES6\nJ4W2yAn0iQrk2gsGUlXbyNJVedw8LAUDg5e2LKKgpsjT5YlID6LQFumAC8bEMWpgBNv3lbJzh5k5\nCVdS3VTD85tfpaax9sQrEBHpBAptkQ4wDIMbZw8hJMDK0i/3EsVgpvaZRH5NAf9M/xd2h/3EKxER\nOU0KbZEOCvSz8uNLhuF0OnnhvXQujLuQpPBEtpdk8p9dH3i6PBHpARTaIichsW8os8f3pai8jn99\nspP5Q68j1j+a1Qe+5ssDX3u6PBE5wym0RU7SZRPiGRAbxLfb8knLKOUnI24k0CuAd3a+z/aSTE+X\nJyJnMIW2yEmymE3ccukwfL3NvPFxJo213twy4npMGLy89Q3yqgs8XaKInKEU2iKnwBbiyw0zh1Df\naOeF99Lp7d+HHyb+gNqmOp7b/ApVjdWeLlFEzkAKbZFTdFZiFBOGx7Avv5J3v9zNWdFjmNH3Aopq\ni3lpyyKaHE0nXomIyElQaIuchrnTBxEV5sfKddls2VPMxf0vZJQtiZ1le3g7cxldeDweEemGFNoi\np8HHauEnlw7DYjZ4+b/bqKxu5Pqhc+gdGMfag+v4PHuNp0sUkTOIQlvkNPWNDuTqKQOpqGnkpQ+3\n42Xy4tbhNxBsDeTdXR+ytWi7p0sUkTOEQlukE0wf24sRA8JJ31vCx+uyCfUJ4dYR87GYzLySvpiD\nVXmeLlFEzgAKbZFOYBgGP5qdSJC/lf+s3s3e3Ar6BvUmJfFa6uz1PL/5FSobqjxdpoh0cwptkU4S\n5G/lxxcPxe5w8sL76dTWN5EcNZKL4qdTXFfKi1tep1F3lIvIaVBoi3SiYfFhzDq7DwWltfzrk+a3\no83qN43kyJHsKc9iccYS3VEuIqdMoS3Sya6Y1J/4mEC+3prH/7bmYRgG8xKvoV9QH9blpfHJvi88\nXaKIdFMKbZFOZjGbuPXSYfhYzbz+8Q4KSmuwmr24ZfgNhHqH8N6eFWwq3OrpMkWkG1Joi7hAZKgf\nKRcmUN9g54X302myOwj2DuTWEfOxmq28lv4m2ZU5ni5TRLoZhbaIi4xPimb8sGj25laydM0eAHoH\nxjJ/6BwaHU08v/lVyusrPFyliHQnCm0RF5p34WAiQ31Z8c1+0veWADDSlsSlA2ZSVl/OC5tfo8He\n6OEqRaS7UGiLuJCvt4VbLx2G2WTw0n+3UVHdAMD0PlM4OzqZfZXZvLH9bd1RLiIdotAWcbH4mCCu\nmjyA8uoGXv5wOw6nE8MwuG7IVQwI7seGgu9YnrXK02WKSDfg1tCurq5mwYIFpKSkMGfOHNas0WAK\n0jNceFZvhsWHsWVPMatSDwDgZbLw4+HXE+4TyvK9n7Ahf5OHqxSRrs6tob106VLi4+NZtGgRTz/9\nNL/73e/cuXkRjzEZBjdflEignxdLvtjFvrxKAAKtAfxkxI34mL1ZtP1tsir2e7hSEenK3BraoaGh\nlJWVAVBRUUFoaKg7Ny/iUcEB3tx00VCa7E6efz+duobmV5rGBkTzo6Qf0uSw88Lm1yitK/NwpSLS\nVbk1tC+66CIOHjzI9OnTmTdvHvfee687Ny/icSMGhHPhuN7kl9SweNXOlunDwodw5aCLqWio5PnN\nr1Jvb/BglSLSVRlON962+t5775Gamspjjz1GRkYG//d//8e7777b5vxNTXYsFrO7yhNxi8YmO3c/\nu4bdB8q5e14yk0b3AsDpdLIwdTGr9nzFuLiR3HXeLZgM3SsqIkdY3LmxtLQ0JkyYAMCQIUMoKCjA\nbrdjNh8/mEtLazq9BpstkMLCyk5fr7SmPrfvptmJPPLKev72ziYiAqzYQnwBuLTPRewvyWV9znf8\n89slXDZgVrvrUZ/dQ312D/W5mc0W2OZnbv01vm/fvnz33XcA5OTk4O/v32Zgi5zJosP8+OH0wdTW\n23nx0GtOAcwmMzcPT8HmG87H+z7n29wNHq5URLoSt4b2tddeS05ODvPmzeOuu+7i4YcfdufmRbqU\n84ZHc/bQKHYfrOD9tXtbpvt7+fHTETfia/FlccYSdpdlea5IEelS3HpN+2S54jSJTr+4h/rcMTV1\nTTz8yjqKy+v41XWjSex75ImKjJKd/P27l/Gz+HLP2J8T7ht2zPLqs3uoz+6hPjfrMqfHRaQ1Px8L\nt142DJPJYOEH6VTWHLlrfEjYIH4w6DKqGqt5fvOr1DbVebBSEekKFNoiHjYgNpjLJ8ZTVtXAK8sz\nWr2HfFKv8UzudR4Hq/N4NX0xDqfDg5WKiKcptEW6gFnn9CWxbyibdhXxWVrrcbavGngxiWGD2Vqc\nwdJdH3qoQhHpChTaIl2AyTC4+eKhBPh68dZnu8guqGr5zGwyc1PSD4n2i+Sz7DWsPfitBysVEU9S\naIt0EaGB3vzookSa7A6ef28r9Y32ls98Lb78ZMSN+Hv58e8dS8ks3e3BSkXEUxTaIl3IqIERTEvu\nRW5xDf/+dGerz2x+4fw46XoMDF7asoiCmiIPVSkinqLQFulifnD+AHpHBrB600FSMwpafTYotD9z\nEq6kuqmG5ze/QnVD5781UES6LoW2SBfjZTFz66XDsFpMvLoig+Ly1o96nRs7jql9JpFfU8ijXzzF\n6gNfU1Rb7KFqRcSd3PrucRHpmNgIf+ZOH8yrKzJ48YN07pk7GrPpyO/Ylw+YTVldORsKvmNvaTYA\nkX4RDAsbQmJ4AoNC+mM1e3mqfBFxEb0RTVxCfT59TqeT595LJzWjgEvP68flE/sfO49fA1/t3MC2\n4kx2lO5sGdLTy2RhUOgAhoYlMCw8gUg/m7vLP6Nof3YP9blZe29E05G2SBdlGAbzZyaw92AFH3yd\nRWLfUBL6hLaaJ9I/nIlx45kYN54mRxO7y7LYVrKDbcVH/lmyEyJ8w1sCfFDoALzNVg99KxE5HTrS\nFpdQnzvPrgPl/PFfaQQHWHnkR2cR4HvktHd7fS6tK2sJ8IySXdTZm6+NW0wWBgbHMyw8gaHhCUT5\nRWIYhlu+S3el/dk91Odm7R1pK7TFJdTnzvX+2r0sW7OX5ME2fnZFUkvIdrTPdoedPeX72Fayg/Ti\nDHKqcls+C/MJZWh4AkPDEkgIHYCPxcdl36O70v7sHupzM50eF+nmLh7fj21ZpWzILGT1poNMGR13\nUsubTWYGhfZnUGh/Lhswi7L6crYXZ5JesoOMkp18lfMNX+V8g9kwMyC4H0PDExgWPoQY/ygdhYt0\nITrSFpdQnztfSUUdD/1zHQ1NDn5zw1jibAGd0me7w05WRTbbijPYVrKD/ZVH3n0e4h3cci08IWwg\nvhbf0/0a3ZL2Z/dQn5vp9PhRtFO4h/rsGmmZhfzt3S3E2fx58PqxxMWGdHqfKxoq2V6cybaSHWwv\nzqS6qfkFLibDRP/gvi2PlfUKiOkxR+Han91DfW6m0D6Kdgr3UJ9dZ9HHO/g8LYfzx8Rx5w/HurTP\nDqeDfRUH2FacQXrJDvZXHMBJ818ZwdZAEg9dC08MG4Sfl5/L6vA07c/uoT430zVtkTPItecPJDO7\njM/Tcjg7KZZBMQEuO+I1GSbig/sQH9yHi/pfSFVDNdtLMkkv3sH2kh18k5vKN7mpGBjEB/dtOZXe\nKzAWk6EXLop0Nh1pi0uoz651oLCKx15LpbHJgb+PhV62AHpFBtDL5t/874gAvK1ml9bgcDrIrsxp\nfh68ZAd7y/e3HIUHegWQGD6YYWEJDAkfTICXv0trcTXtz+6hPjfT6fGjaKdwD/XZ9dL3lvDN9gJ2\nHSijoKSGo/9HNgBbqC+9W8I8gN6R/kSE+GJy0VF5dWMNGSWZbDt0PbyiofJQLQZ9g3ofuiM9gT6B\nvbrdUbj2Z/dQn5sptI+incI91Gf3ONzn+kY7B4uqyS6o4kBBFQcKq8guqKK6rqnV/N5e5iNH47YA\neh86Ovfz6dz3lDucDnKqctlWvIP04h3srdiHw+kAmq+FT4w7l4lx5xBg7R5H4Nqf3UN9bqbQPop2\nCvdQn92jvT47nU7Kqhqag7zwSJjnFtdgd7T+3z48yLvlFHvvQ4EeFebbapCS01HTWMuO0l1sK84g\nrWALdfY6vEwWzo5O5vzeE4n2j+yU7biK9mf3UJ+bKbSPop3CPdRn9ziVPjfZHeQW13CgoIrsQ2Ge\nXVhFeVVDq/ksZhOxEX5HTrFHBtDbFkCQ/+m9t7yuqY7/5abyefZXFNeVADAsfAgX9J5IQujALvkY\nmfZn91Cfmym0j6Kdwj3UZ/fozD5X1DSQU1BFdmF1S5DnFFbTZHe0mi/I30rv751ijwn3x8tyckfl\nDqeDzYXpfJq9hj3lWQDEBcRwfu+JjI0ahZep6zzc0t3255K6UvaW78PP4keANYBAqz+BXgGYTa69\nOfF0dbc+u4pC+yjaKdxDfXYPV/fZ7nBQUFp71Cn25uvmxRV1reYzGQYx4X4td7AfPsUeGujdoSPn\nrIr9fLZ/DRsLt+BwOgi0BjA57lwmxJ1DoDXAVV+vw7rD/lzbVMfGgi2sy9vAzrI9x53H3+JHoDWA\nQGsAAdYAgqwBBHod9WdrAAFezX/2Nnfsv11n6g59dgeF9lG0U7iH+uwenupzTV0jBwqrW66VZxdW\ncaCwmvoGe6v5Wh5HswXQK/LI0bm31/GP+ErqSll94GvWHvyW2qbm695nRY/h/N4TifGPcsdXO66u\nuj/bHXa2l2SyLi+NzUXpNDqabzwcEBzPCNtQmhxNVDRUUdVQRWVDFRWNzX+ubqxpeTyvLV4my6EA\nD2w+UrcGNge+11F/PvSPv8WvU47iu2qf3U2hfRTtFO6hPrtHV+qzw+mkqLyu+Ya3o4L8+4+jWb1M\nnJcUw7SxvYgJP/7d44eve3+R/RVFh657Dw1L4II+ExkSOqhHHwE6nU6yK3NYl5dGav4mKhurAIj0\ni+CsqGTOih5NuG9Yu+uwO+xUNdZQ1VhFRUMllYeCvaKhisrGo/586OcmR1O76zMw8Pc6dBTvFdAq\n0Fv/3Bz2bY3n3pX67EkK7aNop3AP9dk9ukOf6xvsHCxuPq2eXVDFpp2FFFfUAzC8fzjTx/ViWL+w\n4waxw+lgc9E2Ptu/ht3lewGI9Y/mgsPXvc2d+6haW7pCn0vqSlmft5F1eWnk1RQAEODlT3LUSM6K\nHkPfwN4u+WXG6XRSZ69vDvBDId7850oqG6oP/Xzozw2V1DTVnnCdVpPXUUfr/gR6Nf85LtxGL2sf\novxsnf49uhOF9lG6wv98PYH67B7dsc92h4ONmUV8nJrNrgPlAMSE+zF9bG/GJ0W3eep8X0U2n2Wv\nIa1gc/N1b68AJvUaz8S48S6/7u2pPtc21bGpYAvr8tLYWbYHJ04sJgvDwxM5OyaZoWEJXe7msiZH\nE1WN1UdCvlXQH/uz3frtH0QAABPKSURBVGk/Zh0x/lGMsiUx0ja8Rw1Mc5hC+yjd8S+57kh9do/u\n3ue9uRWsSs1m3fYC7A4n/j4WJo+K44IxcYQF+Rx3mdK6MlYf+JqvDn5DbVMdFpOFs6LGcH7vCcQG\nRLukTnf2ub3r1GdHj2F05Aj8vM6MIVKdTie1TXXNR+qN1dSaK1m7dwPbS3a2nJIP9wljlC2JUZFJ\n9Avq0+3epncqFNpH6e5/yXUX6rN7nCl9Lq2s5/ONOXyxMYeq2kZMhsHYITamj+3NgLjg4y5T11TP\nN3nNz3sX1RYDkBg2mKm9JzEkrHOve7u6z06nk+yqHNblHv869bjo0USc4Dr1meBwn+ua6kgv3sF3\nhVvZWrydenvzOwSCrYGMsCUxypbEoJD+Xe4sQ2dRaB/lTPlLrqtTn93jTOtzQ6Odb7fl80lqNgcK\nqwHoHxvE9LG9SU6wYTEfe5TlcDrYUrSNz7LXsKus+bp3jH8UF/SeyLio0Z1y3dtVfS6tK2N93ka+\nzU8jrzofAH8vP5IjR3FW9Bj6BZ3aderc4mr2HKzA6QTDOPyPgWE0P55nGAYGracbhoHp6J9pY3rL\nskev73ifH/vZ4ffeH2+dJgOio4OpKKtp9V0a7Y3sKN3FpsKtbC5K///27jw2qnL/4/h72mmhK91m\nOi1tWUqhdF/1FqmigCZ6IxGXIlr95xqX3Gs0ai7hXi/eeGOCiYlRjEvURDGGKrhgXFFAi5S1y7Rl\naSmVtnTazsB0X2fm/P6YMr8CLRRsZ+v39Y/SOTM88+XkfPqc5zzPQ9+I/fVAdQDpUSlkadJIjliM\nv5Oeb3AGCe0xvO0i566kzs7hrXVWFIUTZ8zsOtJC1SkTChAeMovbcuZyS9ZcggPGv0A3dbewu7mU\nox1V2BQbwX5B3Dy3gJvjlv2pce+prPO449QqX9KjUrhBl0NK5BLU17iwjE1RON3aTUWdkYp6E23n\n+6/+JjekUkHK/AgKM2LITtJctmCP1WaloauRSmMNlR01dA13A+Dv609qZDJZmjRSI5MJUI8/tOIp\nJLTH8NaLnLuROjvHTKhzu7mfX460UFptYGjYip/ah2VpOlblxjFXM34Q//+490EGLAOj497Z3Bpf\neF3j3n+2zlablRPmeg61lVNlrGXENgJA4pz53KjLva5x6hGLlWN/mKmoN1F5ykR3n/0Wsr+fD2kL\nIkmdH46/ny82RUFR7L8IXfjvhaXnx39NGX1tvPfY/3zp+2yKAgr2/2fsa6PvG/MZCpd85pjP6Buy\nUNfUCdjn+Bek6ijMjCVee/m/s02xcaa7hSpjDRXGascQiVrlS3JEEpmadDKiUjxmU5qxJLTHmAkX\nOXcgdXaOmVTn/kEL+/St/Hy0BVOXfUW21PnhrM6PJ21h5Lhbjg5ahjjYdpQ9zaUYx4x73xpfSErE\n4knfer6eOjvGqS/Mpx4eHacOiOIGXQ75upxrHqfuHRhB32Ciot5EzenzDI3Yn7wOCfQja1EU2Uka\nUkbD2hNpNCFUHW9jX7WB/dUGuvvtv9zM14VQmBnLjUu14+5IpygKrX1tVBprqDLWcLbXANhv8SeF\nLSRTm0ZmVCrhs8Oc+n2ul4T2GDPpIudKUmfnmIl1ttkUKk+Z2HW4mZPN9l5ZdEQgq/PiWJamY7b/\n5beWbYqNGtNxdjeXOpb41AVFc1v8cvKjc646HnotdZ7qcWpT1wAV9SYq6ozUNXc5esLa8ABykjRk\nL44iMXYOPj6ePy1qbJ0tVhv6hnPs0xvQN5zDpij4qX3IW6KhMCOWJQlhE9axo99E1WiAN3Y3OX4+\nPzRhdCpZKlo3ngsuoT3GTLzIuYLU2Tlmep2b2nvYdaSZg8fasVgVAmapuSUzltty5xI1Z/zbzU09\nLexu2sfRjkrHuHfh3AJujisg1H/8i+XV6jxoGaTCWGMfpzY3OMap00bHqVOvYZxaURSaO3oprzNS\nWW+iqaPX8dqCmFByFkeRlaQhNjLQ6+YvT1Rnc88Q+2sM7NMbaDfbF2/RhgVwU0YMy9NjCA+ZNeFn\ndg51UWWspdJYw6nO04593WODdKNTydKJDdK5VS0ltMeY6Rc5Z5E6O4fU2a6rb5i9FWfZU95Cd/8I\nKhXkLtawKi+epLg5416QO4e67OPeZw/QbxlArfIlT5fNbfGFzA2OuejY8ep8pXHqG3Q55GgzCPQL\nnFT7LVYb9c2d9h51vcmxIYuvj4ql88PJTtKQtSjqiuHkDa52PiuKQl1zJ/v0Bg6f7GB4xIZKZV9Z\nb3l6DFlJUePOMLigd7iPatMxqkw1F80FjwqIHO2BpzE/NN7lc8EltMeQi5xzSJ2dQ+p8sRGLjUPH\n29l1uNnRQ52nC+H2vHjyl2rHvaAPWYc5OLq/d8eACYDk8CRuSyhkacRifFQ+jjorikJLbyuH2so5\n3F7hGKfWBERyo+7CfOrISbV1cNhCzenzVNQb0Teco2/QHiABs9RkJEaSnRRF+sJIAma5zxal0+1a\nzueBIQsHj7ezT2/gdKv9KfKQQD/Hw2tzo678ANqV5oJnjga4q+aCu1Vo79y5k/fffx+1Ws3TTz/N\nihUrJjxWQttzSZ2dQ+o8vgs9sl1HWqioM6IAc4L8uTVnLiuy5hIadPmGFTbFRu25E+xuKqWuswEA\nXaCWW+OXU5CYyS8nD3CorRzDhXFqdaBj3e/5oQmTur3a1TtE5Sl7b/rYH2bHXuXhIbPITrI/SLYk\nIeyKvUVvdr3nc4uxl316A/tr2ugdsN/xWBgbSmFGDDcsjb7qLz4j1hFOmOupNNZQbTxGn8U+ZS5I\nHWifC65NIzk8yalr3U/EqaFtNptZt24dO3bsoL+/nzfffJOXX355wuMltD2X1Nk5pM5X19E5wO6j\nLZTqWxkYsqL29eEvqdGszosfdyoRQHPPWXY3l3KkvdIxBgpc1zi14VwflfUmyuuNnD7b7djxLE4T\nRFaShpzFUcyLDnGrMVVX+bPns8Vqo7LeRKneQE3jORTFPgUuP1lLYUbshEMlY1ltVk51NjqeRL8w\nF3zWJXPBZ0/jXHC3Ce3vvvuOQ4cO8dJLL03qeAltzyV1dg6p8+QNDFn4vdrAz0da6Oi0P8y0dF44\nq/PiyVg0/pSxzqEufmspwzhiZHFIErmTGKe2KQqNrd2U19sfJDOcs/faVCpYHBdGdlIUWYs1aMO8\nY/3wqTSV5/P57kF+rzZQqjc4pghGRwRSmBHDsjQdYcFXfz7APhe8eXQxl2rHNrFqHzXJ4UlkadJI\n16QQ7De1c8HdJrTfe+89Tp8+TWdnJ93d3fzjH/+goKBgwuMtFitqtWfONxRCuCebTeHIiXZ2/tZA\nVb19DDsmMoi/Fi5gVX7CuPOAr2Z4xIr+lIkDNQYO1bZh7rFvPerv50vOEg1/SYshb2k0cyYRFGJq\n2WwKNadN7DrYxH59K8MWGz4+KvKSo1l9YwJ5S6MnNRyhKApNXWc52FLJoZZKmrrOAuDr48umFc+Q\nrFk03V8FcEFol5eXs2XLFlpbW3nkkUfYs2fPhLcrpKftuaTOziF1/nNaOnrZdaSZstp2LFYbAbN8\nKcyI5bbcuIt6wuPVuW9wBH3DOSrqjFQ3nmdo2L7QSXCAH1lJUWQnRZEyP2LCrUbF5ab7fO4fHOHg\nsXZ+0xs402b/e0KD/FmWpqMwI4aYyMn3mDv6jVQZa2nsOsOaRXdO6R7gbtPT3rFjByaTiccffxyA\nu+66i48//pjIyPGftpTQ9lxSZ+eQOk+N7v5hfq1sZXd5C129w6iArKQobs+PZ3F8GFptKEZjD+e6\nBqmot6/vXdfciXV0PVBtWADZi+0Pki2a6x0LnbiCM8/npvYeSvUGDtS2OZ7cXxQ3h8KMGPKTteMu\n0uMsbhPa7e3tbNiwgQ8++ICuri7Wrl3LL7/8go/P+LcmJLQ9l9TZOaTOU8titXH4RAe7Djfzx2hP\nLEEbTH6qjsPH2mhqH7vQSQjZSRqyk6KIjQqSB8mmgCvO5xGLlYp6E6VVrRz7w4wCzPL35YZkLYWZ\nsSTGhjr939ZtQhtg27ZtbN++HYAnn3ySlStXTnishLbnkjo7h9R5eiiKwqmzXew60sLRkx0oyuhC\nJ/PC7Q+SJWm8fqETV3D1+WzqGuD36jb26Q2OBW5iIgMpzIhlWZpu3KmC08GtQvtaSGh7Lqmzc0id\np9+5rkF6R2xogv0JnD1zFjpxBXc5n22KwvE/zJTqWymvM2KxKvj6qMhcFMXyjBjSF0bgO8Ed4qlw\npdCWM1AIIa4gcs5skt0kTIRz+KhUpC6IIHVBBL0DIxyobaNUb6C8zkh5nZGwYH9uSrevex4dMbml\naqeKhLYQQggxgeAAP1blxbMyN46m9l5+07dyoLadb8vO8G3ZGZbEh/G3v6YQOWf6FlsZS0JbCCGE\nuAqVSsU8XQjFuiUU3bqIo3VGSqtaOdnUSZu5X0JbCCGEcEf+fr4UpOooSNVhtdmmdXz7UjNzVXoh\nhBBiCjgzsEFCWwghhPAYEtpCCCGEh5DQFkIIITyEhLYQQgjhISS0hRBCCA8hoS2EEEJ4CAltIYQQ\nwkNIaAshhBAeQkJbCCGE8BAS2kIIIYSHkNAWQgghPIRKURTF1Y0QQgghxNVJT1sIIYTwEBLaQggh\nhIeQ0BZCCCE8hIS2EEII4SEktIUQQggPIaEthBBCeIgZE9qvvPIKRUVFrFu3Dr1e7+rmeLVXX32V\noqIi7r33Xn766SdXN8erDQ4OsmrVKr744gtXN8Vr7dy5k7vvvpu1a9eyd+9eVzfHK/X19fH3v/+d\n4uJi1q1bR2lpqaub5LbUrm6AMxw6dIgzZ85QUlJCQ0MDGzdupKSkxNXN8koHDhygvr6ekpISzGYz\n99xzD7fffrurm+W13n77bebMmePqZngts9nMW2+9xY4dO+jv7+fNN99kxYoVrm6W1/nyyy9ZsGAB\nzz33HO3t7Tz66KP88MMPrm6WW5oRoV1WVsaqVasASExMpKuri97eXoKDg13cMu+Tn59PRkYGAKGh\noQwMDGC1WvH19XVxy7xPQ0MDp06dkhCZRmVlZRQUFBAcHExwcDAvv/yyq5vklcLDwzl58iQA3d3d\nhIeHu7hF7mtG3B43mUwXnQQREREYjUYXtsh7+fr6EhgYCMD27du5+eabJbCnyebNm9mwYYOrm+HV\nWlpaGBwc5IknnmD9+vWUlZW5ukle6a677qK1tZXVq1fz8MMP889//tPVTXJbM6KnfSlZuXX6/fzz\nz2zfvp0PP/zQ1U3xSl999RVZWVnEx8e7uiler7Ozky1bttDa2sojjzzCnj17UKlUrm6WV/n666+J\njY3lgw8+4MSJE2zcuFGe05jAjAhtrVaLyWRy/LmjowONRuPCFnm30tJS3nnnHd5//31CQkJc3Ryv\ntHfvXpqbm9m7dy9tbW34+/uj0+lYtmyZq5vmVSIjI8nOzkatVpOQkEBQUBDnz58nMjLS1U3zKuXl\n5SxfvhyA5ORkOjo6ZFhtAjPi9vhNN93Ejz/+CEBtbS1arVbGs6dJT08Pr776Ku+++y5hYWGubo7X\nev3119mxYwefffYZ999/P0899ZQE9jRYvnw5Bw4cwGazYTab6e/vl/HWaTBv3jyqqqoAOHv2LEFB\nQRLYE5gRPe2cnBxSU1NZt24dKpWKTZs2ubpJXuu7777DbDbzzDPPOH62efNmYmNjXdgqIa5PdHQ0\nd9xxBw888AAA//73v/HxmRF9HacqKipi48aNPPzww1gsFl566SVXN8ltydacQgghhIeQXxmFEEII\nDyGhLYQQQngICW0hhBDCQ0hoCyGEEB5CQlsIIYTwEBLaQniZlpYW0tLSKC4uduya9Nxzz9Hd3T3p\nzyguLsZqtU76+AcffJCDBw9eT3OFENdAQlsILxQREcHWrVvZunUr27ZtQ6vV8vbbb0/6/Vu3bpXF\nLYRwQzNicRUhZrr8/HxKSko4ceIEmzdvxmKxMDIywn/+8x9SUlIoLi4mOTmZ48eP89FHH5GSkkJt\nbS3Dw8O8+OKLtLW1YbFYWLNmDevXr2dgYIBnn30Ws9nMvHnzGBoaAqC9vZ3nn38esO/1XVRUxH33\n3efKry6EV5HQFsLLWa1Wdu3aRW5uLi+88AJvvfUWCQkJl23MEBgYyCeffHLRe7du3UpoaCivvfYa\ng4OD3HnnnRQWFrJ//35mz55NSUkJHR0drFy5EoDvv/+ehQsX8t///pehoSE+//xzp39fIbyZhLYQ\nXuj8+fMUFxcDYLPZyMvL49577+WNN97gX//6l+O43t5ebDYbYF/u91JVVVWsXbsWgNmzZ5OWlkZt\nbS11dXXk5uYC9g15Fi5cCEBhYSGffvopGzZs4JZbbqGoqGhav6cQM42EthBe6MKY9lg9PT34+fld\n9vML/Pz8LvvZpVtQKoqCSqVCUZSL1uC+EPyJiYl8++23HD58mB9++IGPPvqIbdu2/dmvI4QYJQ+i\nCTFDhISEEBcXx6+//gpAY2MjW7ZsueJ7MjMzKS0tBaC/v5/a2lpSU1NJTEykoqICAIPBQGNjIwDf\nfPMN1dXVLFu2jE2bNmEwGLBYLNP4rYSYWaSnLcQMsnnzZv73v//x3nvvYbFY2LBhwxWPLy4u5sUX\nX+Shhx5ieHiYp556iri4ONasWcPu3btZv349cXFxpKenA7Bo0SI2bdqEv78/iqLw2GOPoVbLZUaI\nqSK7fAkhhBAeQm6PCyGEEB5CQlsIIYTwEBLaQgghhIeQ0BZCCCE8hIS2EEII4SEktIUQQggPIaEt\nhBBCeAgJbSGEEMJD/B+NdZDfCwotrAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb028ba48d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAFnCAYAAACM3c9QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiJJGCRERCQJg4SIiCRhkBARkST/D3UVxtENXumbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb026c06490>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "EBgMYkG5bNP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "266KQvZoMxMv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below for one possible solution."
      ]
    },
    {
      "metadata": {
        "id": "lRWcn24DM3qa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here is a set of parameters that should attain roughly 0.9 accuracy."
      ]
    },
    {
      "metadata": {
        "id": "TGlBMrUoM1K_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_ = train_linear_classification_model(\n",
        "    learning_rate=0.03,\n",
        "    steps=1000,\n",
        "    batch_size=30,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mk095OfpPdOx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2: Replace the Linear Classifier with a Neural Network\n",
        "\n",
        "**Replace the LinearClassifier above with a [`DNNClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) and find a parameter combination that gives 0.95 or better accuracy.**\n",
        "\n",
        "You may wish to experiment with additional regularization methods, such as dropout. These additional regularization methods are documented in the comments for the `DNNClassifier` class."
      ]
    },
    {
      "metadata": {
        "id": "rm8P_Ttwu8U4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE: Replace the linear classifier with a neural network.\n",
        "#\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TOfmiSvqu8U9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once you have a good model, double check that you didn't overfit the validation set by evaluating on the test data that we'll load below.\n"
      ]
    },
    {
      "metadata": {
        "id": "evlB5ubzu8VJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_test_dataframe = pd.read_csv(\n",
        "  \"https://download.mlcc.google.com/mledu-datasets/mnist_test.csv\",\n",
        "  sep=\",\",\n",
        "  header=None)\n",
        "\n",
        "test_targets, test_examples = parse_labels_and_features(mnist_test_dataframe)\n",
        "test_examples.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDuLd2Hcu8VL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE: Calculate accuracy on the test set.\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6sfw3LH0Oycm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below for a possible solution."
      ]
    },
    {
      "metadata": {
        "id": "XatDGFKEO374",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The code below is almost identical to the original `LinearClassifer` training code, with the exception of the NN-specific configuration, such as the hyperparameter for hidden units."
      ]
    },
    {
      "metadata": {
        "id": "kdNTx8jkPQUx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_nn_classification_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    hidden_units,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a neural network classification model for the MNIST digits dataset.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  a plot of the training and validation loss over time, as well as a confusion\n",
        "  matrix.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: An `int`, the learning rate to use.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    hidden_units: A `list` of int values, specifying the number of neurons in each layer.\n",
        "    training_examples: A `DataFrame` containing the training features.\n",
        "    training_targets: A `DataFrame` containing the training labels.\n",
        "    validation_examples: A `DataFrame` containing the validation features.\n",
        "    validation_targets: A `DataFrame` containing the validation labels.\n",
        "      \n",
        "  Returns:\n",
        "    The trained `DNNClassifier` object.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  # Caution: input pipelines are reset with each call to train. \n",
        "  # If the number of steps is small, your model may never see most of the data.  \n",
        "  # So with multiple `.train` calls like this you may want to control the length \n",
        "  # of training with num_epochs passed to the input_fn. Or, you can do a really-big shuffle, \n",
        "  # or since it's in-memory data, shuffle all the data in the `input_fn`.\n",
        "  steps_per_period = steps / periods  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create feature columns.\n",
        "  feature_columns = [tf.feature_column.numeric_column('pixels', shape=784)]\n",
        "\n",
        "  # Create a DNNClassifier object.\n",
        "  my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  classifier = tf.estimator.DNNClassifier(\n",
        "      feature_columns=feature_columns,\n",
        "      n_classes=10,\n",
        "      hidden_units=hidden_units,\n",
        "      optimizer=my_optimizer,\n",
        "      config=tf.contrib.learn.RunConfig(keep_checkpoint_max=1)\n",
        "  )\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"LogLoss error (on validation data):\")\n",
        "  training_errors = []\n",
        "  validation_errors = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "  \n",
        "    # Take a break and compute probabilities.\n",
        "    training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
        "    training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
        "    training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10)\n",
        "        \n",
        "    validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
        "    validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
        "    validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10)    \n",
        "    \n",
        "    # Compute training and validation errors.\n",
        "    training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_errors.append(training_log_loss)\n",
        "    validation_errors.append(validation_log_loss)\n",
        "  print(\"Model training finished.\")\n",
        "  # Remove event files to save disk space.\n",
        "  _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
        "  \n",
        "  # Calculate final predictions (not probabilities, as above).\n",
        "  final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
        "  final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
        "  \n",
        "  \n",
        "  accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
        "  print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.plot(training_errors, label=\"training\")\n",
        "  plt.plot(validation_errors, label=\"validation\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "  # Output a plot of the confusion matrix.\n",
        "  cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
        "  # Normalize the confusion matrix by row (i.e by the number of samples\n",
        "  # in each class).\n",
        "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
        "  ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
        "  ax.set_aspect(1)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.ylabel(\"True label\")\n",
        "  plt.xlabel(\"Predicted label\")\n",
        "  plt.show()\n",
        "\n",
        "  return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZfzsTYGPPU8I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier = train_nn_classification_model(\n",
        "    learning_rate=0.05,\n",
        "    steps=1000,\n",
        "    batch_size=30,\n",
        "    hidden_units=[100, 100],\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qXvrOgtUR-zD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we verify the accuracy on the test set."
      ]
    },
    {
      "metadata": {
        "id": "scQNpDePSFjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_test_dataframe = pd.read_csv(\n",
        "  \"https://download.mlcc.google.com/mledu-datasets/mnist_test.csv\",\n",
        "  sep=\",\",\n",
        "  header=None)\n",
        "\n",
        "test_targets, test_examples = parse_labels_and_features(mnist_test_dataframe)\n",
        "test_examples.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EVaWpWKvSHmu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_test_input_fn = create_predict_input_fn(\n",
        "    test_examples, test_targets, batch_size=100)\n",
        "\n",
        "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
        "test_predictions = np.array([item['class_ids'][0] for item in test_predictions])\n",
        "  \n",
        "accuracy = metrics.accuracy_score(test_targets, test_predictions)\n",
        "print(\"Accuracy on test data: %0.2f\" % accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WX2mQBAEcisO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 3: Visualize the weights of the first hidden layer.\n",
        "\n",
        "Let's take a few minutes to dig into our neural network and see what it has learned by accessing the `weights_` attribute of our model.\n",
        "\n",
        "The input layer of our model has `784` weights corresponding to the `28×28` pixel input images. The first hidden layer will have `784×N` weights where `N` is the number of nodes in that layer. We can turn those weights back into `28×28` images by *reshaping* each of the `N` `1×784` arrays of weights into `N` arrays of size `28×28`.\n",
        "\n",
        "Run the following cell to plot the weights. Note that this cell requires that a `DNNClassifier` called \"classifier\" has already been trained."
      ]
    },
    {
      "metadata": {
        "id": "eUC0Z8nbafgG",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classifier.get_variable_names())\n",
        "\n",
        "weights0 = classifier.get_variable_value(\"dnn/hiddenlayer_0/kernel\")\n",
        "\n",
        "print(\"weights0 shape:\", weights0.shape)\n",
        "\n",
        "num_nodes = weights0.shape[1]\n",
        "num_rows = int(math.ceil(num_nodes / 10.0))\n",
        "fig, axes = plt.subplots(num_rows, 10, figsize=(20, 2 * num_rows))\n",
        "for coef, ax in zip(weights0.T, axes.ravel()):\n",
        "    # Weights in coef is reshaped from 1x784 to 28x28.\n",
        "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.pink)\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kL8MEhNgrx9N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first hidden layer of the neural network should be modeling some pretty low level features, so visualizing the weights will probably just show some fuzzy blobs or possibly a few parts of digits.  You may also see some neurons that are essentially noise -- these are either unconverged or they are being ignored by higher layers.\n",
        "\n",
        "It can be interesting to stop training at different numbers of iterations and see the effect.\n",
        "\n",
        "**Train the classifier for 10, 100 and respectively 1000 steps. Then run this visualization again.**\n",
        "\n",
        "What differences do you see visually for the different levels of convergence?"
      ]
    }
  ]
}