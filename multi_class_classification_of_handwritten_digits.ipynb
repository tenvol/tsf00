{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi-class_classification_of_handwritten_digits.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL",
        "266KQvZoMxMv",
        "6sfw3LH0Oycm"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tenvol/tsf00/blob/master/multi_class_classification_of_handwritten_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JndnmDMp66FL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "metadata": {
        "id": "hMqWDc_m6rUC",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mPa95uXvcpcn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classifying Handwritten Digits with Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "Fdpn8b90u8Tp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![img](https://www.tensorflow.org/versions/r0.11/images/MNIST.png)"
      ]
    },
    {
      "metadata": {
        "id": "c7HLCm66Cs2p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Learning Objectives:**\n",
        "  * Train both a linear model and a neural network to classify handwritten digits from the classic [MNIST](http://yann.lecun.com/exdb/mnist/) data set\n",
        "  * Compare the performance of the linear and neural network classification models\n",
        "  * Visualize the weights of a neural-network hidden layer"
      ]
    },
    {
      "metadata": {
        "id": "HSEh-gNdu8T0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our goal is to map each input image to the correct numeric digit. We will create a NN with a few hidden layers and a Softmax layer at the top to select the winning class."
      ]
    },
    {
      "metadata": {
        "id": "2NMdE1b-7UIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "First, let's download the data set, import TensorFlow and other utilities, and load the data into a *pandas* `DataFrame`. Note that this data is a sample of the original MNIST training data; we've taken 20000 rows at random."
      ]
    },
    {
      "metadata": {
        "id": "4LJ4SD8BWHeh",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "88d4b9f0-a907-4e1a-a39e-7cfc8f2704a4"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import glob\n",
        "import math\n",
        "import os\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "\n",
        "mnist_dataframe = pd.read_csv(\n",
        "  \"https://download.mlcc.google.com/mledu-datasets/mnist_train_small.csv\",\n",
        "  sep=\",\",\n",
        "  header=None)\n",
        "\n",
        "# Use just the first 10,000 records for training/validation.\n",
        "mnist_dataframe = mnist_dataframe.head(10000)\n",
        "\n",
        "mnist_dataframe = mnist_dataframe.reindex(np.random.permutation(mnist_dataframe.index))\n",
        "mnist_dataframe.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5102</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7103</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7024</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3158</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1    2    3    4    5    6    7    8    9   ...   775  776  777  \\\n",
              "5102    2    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "7103    1    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "7024    1    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "110     2    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "3158    8    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "\n",
              "      778  779  780  781  782  783  784  \n",
              "5102    0    0    0    0    0    0    0  \n",
              "7103    0    0    0    0    0    0    0  \n",
              "7024    0    0    0    0    0    0    0  \n",
              "110     0    0    0    0    0    0    0  \n",
              "3158    0    0    0    0    0    0    0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "gC_j3j7V9wwl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mndf = mnist_dataframe.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LJWAETrU91rV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a322ec78-a85b-4fed-e17c-2e56eafb1cb2"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "_6fNG_XG93zE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "7fe78ceb-25f7-4f5c-9b5d-6959dfb1a625"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.head(3)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5102</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7103</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7024</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1    2    3    4    5    6    7    8    9   ...   775  776  777  \\\n",
              "5102    2    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "7103    1    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "7024    1    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "\n",
              "      778  779  780  781  782  783  784  \n",
              "5102    0    0    0    0    0    0    0  \n",
              "7103    0    0    0    0    0    0    0  \n",
              "7024    0    0    0    0    0    0    0  \n",
              "\n",
              "[3 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "BU-6_KTb96hK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "2a7db1bd-7a50-4c00-b2a0-cfac1956b323"
      },
      "cell_type": "code",
      "source": [
        "mndf.groupby(0).apply(lambda x: x[0].count())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0     979\n",
              "1    1107\n",
              "2    1001\n",
              "3     981\n",
              "4     943\n",
              "5     894\n",
              "6    1021\n",
              "7    1085\n",
              "8     973\n",
              "9    1016\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "L00-M8Vh-r2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "dd084003-df19-4415-8803-57dafbc3e764"
      },
      "cell_type": "code",
      "source": [
        "mndf.groupby(0).apply(lambda x: x[9].count())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0     979\n",
              "1    1107\n",
              "2    1001\n",
              "3     981\n",
              "4     943\n",
              "5     894\n",
              "6    1021\n",
              "7    1085\n",
              "8     973\n",
              "9    1016\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "-3tdNrN4-yha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "47b67246-1025-4ede-8d94-9c5d1540e52a"
      },
      "cell_type": "code",
      "source": [
        "mndf.groupby(0).agg('count')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>...</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>...</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>...</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>...</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>...</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>...</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>...</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>...</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>...</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>...</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    1     2     3     4     5     6     7     8     9     10   ...    775  \\\n",
              "0                                                              ...          \n",
              "0   979   979   979   979   979   979   979   979   979   979  ...    979   \n",
              "1  1107  1107  1107  1107  1107  1107  1107  1107  1107  1107  ...   1107   \n",
              "2  1001  1001  1001  1001  1001  1001  1001  1001  1001  1001  ...   1001   \n",
              "3   981   981   981   981   981   981   981   981   981   981  ...    981   \n",
              "4   943   943   943   943   943   943   943   943   943   943  ...    943   \n",
              "5   894   894   894   894   894   894   894   894   894   894  ...    894   \n",
              "6  1021  1021  1021  1021  1021  1021  1021  1021  1021  1021  ...   1021   \n",
              "7  1085  1085  1085  1085  1085  1085  1085  1085  1085  1085  ...   1085   \n",
              "8   973   973   973   973   973   973   973   973   973   973  ...    973   \n",
              "9  1016  1016  1016  1016  1016  1016  1016  1016  1016  1016  ...   1016   \n",
              "\n",
              "    776   777   778   779   780   781   782   783   784  \n",
              "0                                                        \n",
              "0   979   979   979   979   979   979   979   979   979  \n",
              "1  1107  1107  1107  1107  1107  1107  1107  1107  1107  \n",
              "2  1001  1001  1001  1001  1001  1001  1001  1001  1001  \n",
              "3   981   981   981   981   981   981   981   981   981  \n",
              "4   943   943   943   943   943   943   943   943   943  \n",
              "5   894   894   894   894   894   894   894   894   894  \n",
              "6  1021  1021  1021  1021  1021  1021  1021  1021  1021  \n",
              "7  1085  1085  1085  1085  1085  1085  1085  1085  1085  \n",
              "8   973   973   973   973   973   973   973   973   973  \n",
              "9  1016  1016  1016  1016  1016  1016  1016  1016  1016  \n",
              "\n",
              "[10 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "P1-awioT-7ZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "408a8db1-1f60-466f-eff2-5b17096100e6"
      },
      "cell_type": "code",
      "source": [
        "mndf.groupby(0).agg({9: 'count', 700: 'count'})"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>9</th>\n",
              "      <th>700</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>979</td>\n",
              "      <td>979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1107</td>\n",
              "      <td>1107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1001</td>\n",
              "      <td>1001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>981</td>\n",
              "      <td>981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>943</td>\n",
              "      <td>943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>894</td>\n",
              "      <td>894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1085</td>\n",
              "      <td>1085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>973</td>\n",
              "      <td>973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1016</td>\n",
              "      <td>1016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    9     700\n",
              "0            \n",
              "0   979   979\n",
              "1  1107  1107\n",
              "2  1001  1001\n",
              "3   981   981\n",
              "4   943   943\n",
              "5   894   894\n",
              "6  1021  1021\n",
              "7  1085  1085\n",
              "8   973   973\n",
              "9  1016  1016"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "ZVHS5zU--e-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "79a79398-80ed-4696-e7e3-0806f2f0d5e5"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.groupby(0)[0].hist(bins=10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "3    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "4    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "5    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "6    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "7    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "8    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "9    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFKCAYAAAA0WNeQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0e465e4dd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "m9_QtHI4AHrc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "dff0c352-a947-463c-9903-80bff7e82665"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.groupby(0).agg({784: 'count'})"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    784\n",
              "0      \n",
              "0   979\n",
              "1  1107\n",
              "2  1001\n",
              "3   981\n",
              "4   943\n",
              "5   894\n",
              "6  1021\n",
              "7  1085\n",
              "8   973\n",
              "9  1016"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Us9DPw6gBReZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c3a666a-66de-4aa1-c560-af1f8bef2876"
      },
      "cell_type": "code",
      "source": [
        "type(mnist_dataframe.groupby(0).agg('count'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "pVopUSR2EL50",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ba0fb8ec-3ed1-4860-c7dd-73bf32ef73d7"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.groupby(0).agg('count')[96]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0     979\n",
              "1    1107\n",
              "2    1001\n",
              "3     981\n",
              "4     943\n",
              "5     894\n",
              "6    1021\n",
              "7    1085\n",
              "8     973\n",
              "9    1016\n",
              "Name: 96, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "85BIEKNgIvIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "81587ae9-f6df-438a-93cd-fac6c8e21a90"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.groupby(0)[9].hist(bins=10)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "3    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "4    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "5    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "6    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "7    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "8    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "9    AxesSubplot(0.125,0.125;0.775x0.755)\n",
              "Name: 9, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFKCAYAAADScRzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0e43d62650>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Pi4ggs46BZCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b818ae0b-aa0a-48da-eb9b-ff8bf1b511a4"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.groupby(0)[9].agg('count').plot(kind='bar')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0e437c8f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFUCAYAAADrrX8/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAGXNJREFUeJzt3X1QlIe99vFrBVYGsyqLu2awxqbm\nRGcsvjAmVhQNogbtjNIqiIiJczgzekJs0jqjlDHG1kxqYpvUWNq0Nb6MHSsNrZZmbDBpKrVHgra0\n1DhNjDY1jSawVAwq4uv9/JHn7NGAGlaW/S18PzPOyA3c97UE+WYXXF2O4zgCAAAm9Yr0AAAAcGOE\nGgAAwwg1AACGEWoAAAwj1AAAGEaoAQAwLDbSA9oTCJwJy3kTExPU1NQSlnOHS7Rtjra9Epu7QrTt\nldjcFaJtrxS+zT6f54av61H3qGNjYyI9ocOibXO07ZXY3BWiba/E5q4QbXulyGzuUaEGACDaEGoA\nAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADDM5L+e\n1d0VvbE8LOctnfJsWM4LAIgc7lEDAGAYoQYAwDBCDQCAYYQaAADDCDUAAIbxU98AYNR/rn0jbOfe\nVDwlbOdG5+IeNQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoA\nAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDYiM9AAC6yn+ufSMs591UPCUs5wWkzxjq\nI0eO6JFHHtGiRYtUUFCgDz/8UMuXL9eVK1fk8/m0bt06ud1uVVRUaOvWrerVq5dyc3OVk5OjS5cu\nqbi4WCdPnlRMTIy+853vaPDgweG+XQAAfCZH/mvRZ3/bDpz33o1bOjqlXbd86LulpUVr1qzR+PHj\ng8deeOEF5efna/v27RoyZIjKy8vV0tKi0tJSbdmyRdu2bdPWrVt1+vRpvfLKK+rbt69+/vOfa8mS\nJfre977XKcMBAOgJbhlqt9utn/70p/L7/cFjNTU1yszMlCRlZGSourpadXV1SklJkcfjUXx8vFJT\nU1VbW6vq6mpNmzZNkpSWlqba2tow3RQAALqfW4Y6NjZW8fHx1x07f/683G63JCkpKUmBQECNjY3y\ner3Bt/F6vW2O9+rVSy6XSxcvXuzM2wAAQLd12z9M5jhOpxy/VmJigmJjY25r1434fJ6wnNeCcN22\n/5k95zO/bUe+fzPh17/s+JgwicbPi2jbHG17OyIab5uVzRZ2dOTrVkd01m0LKdQJCQlqbW1VfHy8\n6uvr5ff75ff71djYGHybhoYGjR49Wn6/X4FAQMOHD9elS5fkOE7w3viNNDW1hDLrlnw+jwKBM2E5\ntwXRdtus7I3Gz4to2xxtezsqGm+bhc18Xvyfm0U9pL9HnZaWpsrKSknSnj17lJ6erlGjRunQoUNq\nbm7WuXPnVFtbq7Fjx2rChAl69dVXJUm///3vNW7cuFAuCQBAj3TLe9RvvfWWnnnmGZ04cUKxsbGq\nrKzUd7/7XRUXF6usrEzJycnKzs5WXFycli1bpsLCQrlcLhUVFcnj8WjmzJnav3+/5s+fL7fbrbVr\n13bF7QIAoFu4Zai/+MUvatu2bW2Ob968uc2xrKwsZWVlXXfsf//uNAAA6Liof2YynmkI7fnR2r1h\nOe9/Fz8QlvMCwI3wXN8AABgW9feoAQB2FL2xPCznLZ3ybFjOGw24Rw0AgGGEGgAAwwg1AACGEWoA\nAAwj1AAAGEaoAQAwjFADAGAYf48aMOD9v3y7Y2/fgbe9a8yqjo0BYAr3qAEAMIxQAwBgGKEGAMAw\nQg0AgGGEGgAAwwg1AACGEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDCe6xtASEoOvhuW8z5933+E\n5bxAtOIeNQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoAAAwj\n1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYFhvKO507d04rVqzQ\nxx9/rEuXLqmoqEg+n0+rV6+WJA0bNkzf+ta3JEkbN27Uq6++KpfLpUcffVSTJ0/utPEAAHR3IYV6\n586duvvuu7Vs2TLV19fr4Ycfls/nU0lJiUaOHKlly5apqqpKX/jCF7R7927t2LFDZ8+eVX5+viZO\nnKiYmJjOvh0AAHRLIT30nZiYqNOnT0uSmpub1b9/f504cUIjR46UJGVkZKi6ulo1NTVKT0+X2+2W\n1+vVoEGDdPTo0c5bDwBANxdSqL/85S/r5MmTmjZtmgoKCrR8+XL17ds3+PqkpCQFAgE1NjbK6/UG\nj3u9XgUCgdtfDQBADxHSQ9+//vWvlZycrJdeeklvv/22ioqK5PF4gq93HKfd97vR8U9LTExQbGxk\nHx73+Ty3fiNjwrX5SFjOysf4Wu+H5ayfiLaPc7TtldjcFcK51/rXuJBCXVtbq4kTJ0qShg8frgsX\nLujy5cvB19fX18vv98vv9+u9995rc/xWmppaQpnVqQKBM5Ge0GHRtjna9kps7grRtldic1eItr1S\nxzbfLOohPfQ9ZMgQ1dXVSZJOnDihPn36aOjQofrTn/4kSdqzZ4/S09P1pS99SXv37tXFixdVX1+v\nhoYG3XPPPaFcEgCAHimke9Tz5s1TSUmJCgoKdPnyZa1evVo+n0+rVq3S1atXNWrUKKWlpUmScnNz\nVVBQIJfLpdWrV6tXL/7qNgAAn1VIoe7Tp4/Wr1/f5vj27dvbHFu4cKEWLlwYymUAAOjxuHsLAIBh\nhBoAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoAAAwj\n1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYBih\nBgDAMEINAIBhhBoAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1\nAACGEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIbFhvqOFRUV2rhxo2Jj\nY/W1r31Nw4YN0/Lly3XlyhX5fD6tW7dObrdbFRUV2rp1q3r16qXc3Fzl5OR05n4AALq1kELd1NSk\n0tJS/fKXv1RLS4s2bNigyspK5efna8aMGXruuedUXl6u7OxslZaWqry8XHFxcZo7d66mTZum/v37\nd/btAACgWwrpoe/q6mqNHz9ed9xxh/x+v9asWaOamhplZmZKkjIyMlRdXa26ujqlpKTI4/EoPj5e\nqampqq2t7dQbAABAdxbSPeoPPvhAra2tWrJkiZqbm7V06VKdP39ebrdbkpSUlKRAIKDGxkZ5vd7g\n+3m9XgUCgc5ZDgBADxDy96hPnz6tH/zgBzp58qQeeughOY4TfN21v7/WjY5/WmJigmJjY0Kd1il8\nPk9Erx+KcG0+Epaz8jG+1vthOesnou3jHG17JTZ3hXDutf41LqRQJyUlacyYMYqNjdVdd92lPn36\nKCYmRq2trYqPj1d9fb38fr/8fr8aGxuD79fQ0KDRo0ff8vxNTS2hzOpUgcCZSE/osGjbHG17JTZ3\nhWjbK7G5K0TbXqljm28W9ZC+Rz1x4kS9+eabunr1qpqamtTS0qK0tDRVVlZKkvbs2aP09HSNGjVK\nhw4dUnNzs86dO6fa2lqNHTs2lEsCANAjhXSPeuDAgXrwwQeVm5srSVq5cqVSUlK0YsUKlZWVKTk5\nWdnZ2YqLi9OyZctUWFgol8uloqIieTzR9XALAACRFPL3qPPy8pSXl3fdsc2bN7d5u6ysLGVlZYV6\nGQAAejSemQwAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACG\nEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCM\nUAMAYBihBgDAMEINAIBhhBoAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGE\nGgAAwwg1AACGEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIbdVqhbW1s1\ndepU/epXv9KHH36ohQsXKj8/X4899pguXrwoSaqoqNCcOXOUk5Ojl19+uVNGAwDQU9xWqH/0ox+p\nX79+kqQXXnhB+fn52r59u4YMGaLy8nK1tLSotLRUW7Zs0bZt27R161adPn26U4YDANAThBzqY8eO\n6ejRo3rggQckSTU1NcrMzJQkZWRkqLq6WnV1dUpJSZHH41F8fLxSU1NVW1vbKcMBAOgJQg71M888\no+Li4uDL58+fl9vtliQlJSUpEAiosbFRXq83+DZer1eBQOA25gIA0LPEhvJOu3bt0ujRozV48OB2\nX+84ToeOf1piYoJiY2NCmdZpfD5PRK8finBtPhKWs/Ixvtb7YTnrJ6Lt4xxteyU2d4Vw7rX+NS6k\nUO/du1f/+te/tHfvXn300Udyu91KSEhQa2ur4uPjVV9fL7/fL7/fr8bGxuD7NTQ0aPTo0bc8f1NT\nSyizOlUgcCbSEzos2jZH216JzV0h2vZKbO4K0bZX6tjmm0U9pFB///vfD/5+w4YNGjRokP7yl7+o\nsrJSs2fP1p49e5Senq5Ro0Zp5cqVam5uVkxMjGpra1VSUhLKJQEA6JFCCnV7li5dqhUrVqisrEzJ\nycnKzs5WXFycli1bpsLCQrlcLhUVFcnjia6HWwAAiKTbDvXSpUuDv9+8eXOb12dlZSkrK+t2LwMA\nQI/EM5MBAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYBihBgDAMEIN\nAIBhhBoAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoA\nAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMA\nYBihBgDAMEINAIBhhBoAAMMINQAAhhFqAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGxob7j\ns88+qz//+c+6fPmyFi9erJSUFC1fvlxXrlyRz+fTunXr5Ha7VVFRoa1bt6pXr17Kzc1VTk5OZ+4H\nAKBbCynUb775pt59912VlZWpqalJX/nKVzR+/Hjl5+drxowZeu6551ReXq7s7GyVlpaqvLxccXFx\nmjt3rqZNm6b+/ft39u0AAKBbCumh7/vuu0/r16+XJPXt21fnz59XTU2NMjMzJUkZGRmqrq5WXV2d\nUlJS5PF4FB8fr9TUVNXW1nbeegAAurmQQh0TE6OEhARJUnl5uSZNmqTz58/L7XZLkpKSkhQIBNTY\n2Civ1xt8P6/Xq0Ag0AmzAQDoGUL+HrUkvf766yovL9emTZs0ffr04HHHcdp9+xsd/7TExATFxsbc\nzrTb5vN5Inr9UIRr85GwnJWP8bXeD8tZPxFtH+do2yuxuSuEc6/1r3Ehh3rfvn168cUXtXHjRnk8\nHiUkJKi1tVXx8fGqr6+X3++X3+9XY2Nj8H0aGho0evToW567qakl1FmdJhA4E+kJHRZtm6Ntr8Tm\nrhBteyU2d4Vo2yt1bPPNoh7SQ99nzpzRs88+qx//+MfBHwxLS0tTZWWlJGnPnj1KT0/XqFGjdOjQ\nITU3N+vcuXOqra3V2LFjQ7kkAAA9Ukj3qHfv3q2mpiY9/vjjwWNr167VypUrVVZWpuTkZGVnZysu\nLk7Lli1TYWGhXC6XioqK5PFE18MtAABEUkihnjdvnubNm9fm+ObNm9scy8rKUlZWViiXAQCgx+OZ\nyQAAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoAAAwj1AAAGEaoAQAwjFADAGAYoQYAwDBC\nDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYBihBgDAMEINAIBhhBoAAMMINQAAhhFq\nAAAMI9QAABhGqAEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoAAAwj1AAAGEaoAQAwjFAD\nAGAYoQYAwDBCDQCAYYQaAADDCDUAAIYRagAADCPUAAAYRqgBADCMUAMAYFhsV1zk6aefVl1dnVwu\nl0pKSjRy5MiuuCwAAFEv7KE+cOCAjh8/rrKyMh07dkwlJSUqKysL92UBAOgWwv7Qd3V1taZOnSpJ\nGjp0qD7++GOdPXs23JcFAKBbCHuoGxsblZiYGHzZ6/UqEAiE+7IAAHQLLsdxnHBe4IknntDkyZOD\n96rnz5+vp59+WnfffXc4LwsAQLcQ9nvUfr9fjY2NwZcbGhrk8/nCfVkAALqFsId6woQJqqyslCQd\nPnxYfr9fd9xxR7gvCwBAtxD2n/pOTU3ViBEjlJeXJ5fLpSeffDLclwQAoNsI+/eoAQBA6HhmMgAA\nDCPUAAAYRqgBADCsW4f63LlzOn78uI4fP66WlpZIzwlZc3NzpCfcVHs/5vDRRx9FYEnHnTp1KtIT\nOqy6ujrSEzrk8uXLOnHihC5fvhzpKZ9ZNH5eRKNo+BEpx3F06tQp/fvf/47Yhm4Z6kOHDikvL085\nOTkqKSnRN7/5Tc2aNUsLFizQO++8E+l5Hfboo49GekK7XnvtNWVkZGj8+PFasWLFdU8Nu3z58ggu\na9/evXv14IMPatGiRTpy5IhmzZqlhQsXasqUKaqqqor0vHbt2rXrul87d+7Uk08+GXzZoqeeeir4\n+/3792vatGl6/PHHNX36dO3bty+Cy9pXVVWlVatWSfrkf4IyMjL00EMPacqUKdq7d29kx91Aamqq\n1qxZE9F4dNQf//hHzZgxQwsWLNDf/vY3zZkzR5MmTVJWVpYOHDgQ6XltvPfee1qyZIlmzZqlzMxM\nLV68OPi5XF9f37VjnG4oLy/POXr0aJvjb731lpOfnx+BRbf2s5/97Ia/pk+fHul57Zo7d67T1NTk\nXLlyxdmxY4eTm5vrNDc3O47jOAUFBRFe11Zubq5z4sQJ5+DBg05GRobz97//3XEcxwkEAs6cOXMi\nvK59U6dOdebOnets2LAh+GvSpEnB31t07X/7/Px85/3333ccx3EaGhqc3NzcSM26oa9+9atOIBBw\nHMdxFixYENx76tQpJycnJ5LTbqigoMA5cOCA8/DDDzvFxcXOgQMHnEuXLkV61k3l5eU59fX1zpEj\nR5xx48YF//x98MEHzvz58yO8rq2FCxcGPxeOHTvmrF692nEcx6mqquryr29d8s9cdjXHcTR06NA2\nx0eMGKErV65EYNGtbdmyRePHj5ff72/zOqsPGcbExKh///6SpHnz5ikpKUmFhYV68cUX5XK5Iryu\nLbfbreTkZCUnJ8vv92v48OGSpAEDBqh3794RXte+V155RT/84Q/1zjvvqLi4WIMGDdK+ffvMPsoi\n6br/9v369dPgwYMlST6fT7Gx9r7kXL58WX369JEkeTwefe5zn5Mk9e/f3+xDsy6XS/fdd5+2bNmi\nQ4cO6eWXX9YTTzyhPn36KCkpST/5yU8iPbGNuLg4+f1++f1+9e3bN/jnb9CgQYqJiYnwurYuXrwY\n/Nz9/Oc/H3w0dtKkSdqwYUOXbrH3p6YTjBo1SkuWLNHUqVPl9XolffKPg1RWVur++++P8Lr2lZaW\n6qmnntLKlSvldruve11NTU2EVt1camqqFi9erPXr1ys+Pl5Tp05V7969tWjRIp0+fTrS89pISkrS\nSy+9pMLCQu3YsUPSJ99L37Rpk+68884Ir2tf79699fWvf13/+Mc/9O1vf1tjxozR1atXIz3rpt59\n91099thjchxHx48f129/+1vNmDFDmzZtksfjifS8NgoLC5Wdna0JEyaof//+euSRRzRmzBjV1NQo\nJycn0vPade3/QKSkpCglJUXSJ0/RbPUfPerXr5+ef/55NTU16a677tKqVauUnp6uv/71r0pKSor0\nvDbuvfdefeMb39DIkSO1b98+jRs3TpJUUlKie+65p0u3dNsnPDl48KCqq6uDzzPu9/s1YcIEjRkz\nJsLLbuz8+fPq3bu3evW6/kcHDh8+rBEjRkRo1c3V1NTo/vvvv+5e1NmzZ7V7927l5uZGcFlbra2t\neuONNzRz5szgscOHD+vgwYOaP3++2XvV19q1a5eqqqr0/PPPR3rKDX36+41DhgzRwIED9Zvf/EZT\npkwJ3nu15PTp09q/f79OnDghx3E0YMAATZgwQQMHDoz0tHaVl5dr7ty5kZ7RIS0tLdq5c6cSExM1\nc+ZMVVRUqLa2VkOGDNG8efOUkJAQ6YnXcRxHv/vd7/TPf/5T9957ryZNmiRJevvttzVs2LAufdSw\n24YaAIDuoFv+1DcAAN0FoQYAwLBu+cNkADqmtLRUVVVVchxHkydPNv1T5UBPQ6iBHq6urk6vvfaa\nfvGLX0iS5s+fr7S0NKWmpkZ4GQCJh76BHu8Pf/iDMjMz5Xa75Xa7lZmZafaZ2oCeiFADPVxDQ4MG\nDBgQfNnn86mhoSGCiwBci1ADuI7jOCafWQ7oqQg10MPdeeed192DbmhoMPtMbUBPRKiBHu6BBx7Q\n66+/rgsXLujChQvas2ePMjIyIj0LwP/HT30DPdyIESM0e/ZsLViwQC6XS7Nnzw4+dzSAyOMpRAEA\nMIyHvgEAMIxQAwBgGKEGAMAwQg0AgGGEGgAAwwg1AACGEWoAAAwj1AAAGPb/AEFYd0ycUnuUAAAA\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0e438b2410>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MdTlM4chLo8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "cda3ce7b-992b-4043-c212-c13c3a69b9f1"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.groupby(0)[9].agg('count')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0     979\n",
              "1    1107\n",
              "2    1001\n",
              "3     981\n",
              "4     943\n",
              "5     894\n",
              "6    1021\n",
              "7    1085\n",
              "8     973\n",
              "9    1016\n",
              "Name: 9, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "iR4gF8S1LsXA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kg0-25p2mOi0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each row represents one labeled example. Column 0 represents the label that a human rater has assigned for one handwritten digit. For example, if Column 0 contains '6', then a human rater interpreted the handwritten character as the digit '6'.  The ten digits 0-9 are each represented, with a unique class label for each possible digit. Thus, this is a multi-class classification problem with 10 classes."
      ]
    },
    {
      "metadata": {
        "id": "PQ7vuOwRCsZ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![img](https://www.tensorflow.org/versions/r0.11/images/MNIST-Matrix.png)"
      ]
    },
    {
      "metadata": {
        "id": "dghlqJPIu8UM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Columns 1 through 784 contain the feature values, one per pixel for the 28×28=784 pixel values. The pixel values are on a gray scale in which 0 represents white, 255 represents black, and values between 0 and 255 represent shades of gray. Most of the pixel values are 0; you may want to take a minute to confirm that they aren't all 0.  For example, adjust the following text block to print out the values in column 72."
      ]
    },
    {
      "metadata": {
        "id": "2ZkrL5MCqiJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "5be9b869-9e06-400c-fa0c-3d610455152a"
      },
      "cell_type": "code",
      "source": [
        "mnist_dataframe.loc[:, 72:72]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>72</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9404</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6090</th>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8417</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4937</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5990</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5652</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1989</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2385</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       72\n",
              "9404    0\n",
              "6090  170\n",
              "8417    0\n",
              "4937    0\n",
              "5990    0\n",
              "...   ...\n",
              "613     0\n",
              "5652    0\n",
              "1989    0\n",
              "2385    0\n",
              "878     0\n",
              "\n",
              "[10000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "ep4Smv_o-JIz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vLNg2VxqhUZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let's parse out the labels and features and look at a few examples. Note the use of `loc` which allows us to pull out columns based on original location, since we don't have a header row in this data set."
      ]
    },
    {
      "metadata": {
        "id": "JfFWWvMWDFrR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parse_labels_and_features(dataset):\n",
        "  \"\"\"Extracts labels and features.\n",
        "  \n",
        "  This is a good place to scale or transform the features if needed.\n",
        "  \n",
        "  Args:\n",
        "    dataset: A Pandas `Dataframe`, containing the label on the first column and\n",
        "      monochrome pixel values on the remaining columns, in row major order.\n",
        "  Returns:\n",
        "    A `tuple` `(labels, features)`:\n",
        "      labels: A Pandas `Series`.\n",
        "      features: A Pandas `DataFrame`.\n",
        "  \"\"\"\n",
        "  labels = dataset[0]\n",
        "\n",
        "  # DataFrame.loc index ranges are inclusive at both ends.\n",
        "  features = dataset.loc[:,1:784]\n",
        "  # Scale the data to [0, 1] by dividing out the max value, 255.\n",
        "  features = features / 255\n",
        "\n",
        "  return labels, features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GcoWUz6cPejV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFY_-7vZu8UU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "d847761a-fb23-4810-dc42-a0051442e97d"
      },
      "cell_type": "code",
      "source": [
        "training_targets, training_examples = parse_labels_and_features(mnist_dataframe[:7500])\n",
        "training_examples.describe()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         1      2      3      4      5      6      7      8      9      10   \\\n",
              "count 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0   \n",
              "mean     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "       ...      775    776    777    778    779    780    781    782    783  \\\n",
              "count  ...   7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0   \n",
              "mean   ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max    ...      1.0    1.0    0.3    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "         784  \n",
              "count 7500.0  \n",
              "mean     0.0  \n",
              "std      0.0  \n",
              "min      0.0  \n",
              "25%      0.0  \n",
              "50%      0.0  \n",
              "75%      0.0  \n",
              "max      0.0  \n",
              "\n",
              "[8 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "mNcT3Al1PnQ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4-Vgg-1zu8Ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "f418fab9-aa0e-47c3-9306-8f5b058b3f54"
      },
      "cell_type": "code",
      "source": [
        "validation_targets, validation_examples = parse_labels_and_features(mnist_dataframe[7500:10000])\n",
        "validation_examples.describe()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         1      2      3      4      5      6      7      8      9      10   \\\n",
              "count 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0   \n",
              "mean     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "       ...      775    776    777    778    779    780    781    782    783  \\\n",
              "count  ...   2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0   \n",
              "mean   ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max    ...      1.0    1.0    0.8    0.2    1.0    0.2    0.0    0.0    0.0   \n",
              "\n",
              "         784  \n",
              "count 2500.0  \n",
              "mean     0.0  \n",
              "std      0.0  \n",
              "min      0.0  \n",
              "25%      0.0  \n",
              "50%      0.0  \n",
              "75%      0.0  \n",
              "max      0.0  \n",
              "\n",
              "[8 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "wrnAI1v6u8Uh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Show a random example and its corresponding label."
      ]
    },
    {
      "metadata": {
        "id": "s-euVJVtu8Ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "0b595ef7-e3ff-41d4-a7db-2267be699f6e"
      },
      "cell_type": "code",
      "source": [
        "rand_example = np.random.choice(training_examples.index)\n",
        "_, ax = plt.subplots()\n",
        "ax.matshow(training_examples.loc[rand_example].values.reshape(28, 28))\n",
        "ax.set_title(\"Label: %i\" % training_targets.loc[rand_example])\n",
        "ax.grid(False)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFXCAYAAAAro2x+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0e4247ee90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "GxY_G9SrQNZ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "e4de65a0-d9ac-46b1-ea13-048169e29c8f"
      },
      "cell_type": "code",
      "source": [
        "rand_example = np.random.choice(training_examples.index)\n",
        "_, ax = plt.subplots()\n",
        "ax.matshow(training_examples.loc[rand_example].values.reshape(28, 28))\n",
        "ax.set_title(\"Label: %i\" % training_targets.loc[rand_example])\n",
        "ax.grid(False)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFXCAYAAAAro2x+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0e422ea850>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_48rauOvQnQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e42aef78-c5d3-4ef1-b10a-9981fa869364"
      },
      "cell_type": "code",
      "source": [
        "training_examples.loc[rand_example]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     0.0\n",
              "2     0.0\n",
              "3     0.0\n",
              "4     0.0\n",
              "5     0.0\n",
              "       ..\n",
              "780   0.0\n",
              "781   0.0\n",
              "782   0.0\n",
              "783   0.0\n",
              "784   0.0\n",
              "Name: 5787, Length: 784, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "YeBMIlw5REUx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2873
        },
        "outputId": "d7e6a441-c57d-47e6-a2ec-56fa03705a1f"
      },
      "cell_type": "code",
      "source": [
        "training_examples.loc[rand_example].values.reshape(28,28)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04313725, 0.2       , 0.2       , 0.2       , 0.2       ,\n",
              "        0.2       , 0.28235294, 0.59607843, 0.83921569, 0.83529412,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.16078431,\n",
              "        0.83529412, 0.98823529, 0.99215686, 0.98823529, 0.99215686,\n",
              "        0.98823529, 0.99215686, 0.98823529, 0.99215686, 0.67058824,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.48235294,\n",
              "        1.        , 0.99215686, 1.        , 0.91372549, 0.71764706,\n",
              "        0.55686275, 0.83921569, 0.99215686, 1.        , 0.19607843,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.08235294, 0.8745098 ,\n",
              "        0.99215686, 0.98823529, 0.35686275, 0.11764706, 0.        ,\n",
              "        0.        , 0.51764706, 0.98823529, 0.6745098 , 0.03921569,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.67843137, 0.99215686,\n",
              "        1.        , 0.6745098 , 0.32156863, 0.        , 0.        ,\n",
              "        0.08235294, 1.        , 0.99215686, 0.16078431, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.83529412, 0.98823529,\n",
              "        0.83529412, 0.03921569, 0.        , 0.        , 0.        ,\n",
              "        0.4       , 0.99215686, 0.98823529, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.24313725, 0.4       ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.63921569, 0.99607843, 0.51372549, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.08235294,\n",
              "        0.8745098 , 0.91372549, 0.11764706, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.44313725,\n",
              "        0.99215686, 0.79607843, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.59607843,\n",
              "        0.98823529, 0.63529412, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.24313725, 0.99607843,\n",
              "        0.99215686, 0.32156863, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.55686275, 0.99215686,\n",
              "        0.67058824, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.04313725, 0.83529412, 0.99607843,\n",
              "        0.35686275, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.36078431, 0.98823529, 0.6745098 ,\n",
              "        0.03921569, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.99607843, 0.99215686, 0.4       ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.16078431, 0.99215686, 0.83137255, 0.07843137,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.63921569, 0.95686275, 0.15686275, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.16078431, 0.95294118, 0.63529412, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.2       , 0.99215686, 0.16078431, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.2       , 0.98823529, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "6wJAZA5YQ5T0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2686
        },
        "outputId": "20d4ef5b-db0c-49bf-c4dc-6e7c8d605fa3"
      },
      "cell_type": "code",
      "source": [
        "training_examples.loc[rand_example].values"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.04313725,\n",
              "       0.2       , 0.2       , 0.2       , 0.2       , 0.2       ,\n",
              "       0.28235294, 0.59607843, 0.83921569, 0.83529412, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.16078431, 0.83529412, 0.98823529, 0.99215686,\n",
              "       0.98823529, 0.99215686, 0.98823529, 0.99215686, 0.98823529,\n",
              "       0.99215686, 0.67058824, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.48235294,\n",
              "       1.        , 0.99215686, 1.        , 0.91372549, 0.71764706,\n",
              "       0.55686275, 0.83921569, 0.99215686, 1.        , 0.19607843,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.08235294, 0.8745098 , 0.99215686, 0.98823529,\n",
              "       0.35686275, 0.11764706, 0.        , 0.        , 0.51764706,\n",
              "       0.98823529, 0.6745098 , 0.03921569, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.67843137,\n",
              "       0.99215686, 1.        , 0.6745098 , 0.32156863, 0.        ,\n",
              "       0.        , 0.08235294, 1.        , 0.99215686, 0.16078431,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.83529412, 0.98823529, 0.83529412,\n",
              "       0.03921569, 0.        , 0.        , 0.        , 0.4       ,\n",
              "       0.99215686, 0.98823529, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.24313725, 0.4       , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.63921569, 0.99607843, 0.51372549,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.08235294,\n",
              "       0.8745098 , 0.91372549, 0.11764706, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.44313725, 0.99215686, 0.79607843,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.59607843, 0.98823529, 0.63529412, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.24313725, 0.99607843, 0.99215686,\n",
              "       0.32156863, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.55686275, 0.99215686, 0.67058824, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.04313725, 0.83529412, 0.99607843,\n",
              "       0.35686275, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.36078431, 0.98823529, 0.6745098 , 0.03921569, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.99607843, 0.99215686,\n",
              "       0.4       , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.16078431, 0.99215686, 0.83137255, 0.07843137, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.63921569, 0.95686275,\n",
              "       0.15686275, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.16078431, 0.95294118, 0.63529412, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.2       , 0.99215686,\n",
              "       0.16078431, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.2       , 0.98823529, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "8v2b5wtCQ7Ql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ScmYX7xdZMXE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 1: Build a Linear Model for MNIST\n",
        "\n",
        "First, let's create a baseline model to compare against. The `LinearClassifier` provides a set of *k* one-vs-all classifiers, one for each of the *k* classes.\n",
        "\n",
        "You'll notice that in addition to reporting accuracy, and plotting Log Loss over time, we also display a [**confusion matrix**](https://en.wikipedia.org/wiki/Confusion_matrix).  The confusion matrix shows which classes were misclassified as other classes. Which digits get confused for each other?\n",
        "\n",
        "Also note that we track the model's error using the `log_loss` function. This should not be confused with the loss function internal to `LinearClassifier` that is used for training."
      ]
    },
    {
      "metadata": {
        "id": "cpoVC4TSdw5Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns():\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\" \n",
        "  \n",
        "  # There are 784 pixels in each image.\n",
        "  return set([tf.feature_column.numeric_column('pixels', shape=784)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k4TUt2L9Uvz3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMmL89yGeTfz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we'll make separate input functions for training and for prediction. We'll nest them in `create_training_input_fn()` and `create_predict_input_fn()`, respectively, so we can invoke these functions to return the corresponding `_input_fn`s to pass to our `.train()` and `.predict()` calls."
      ]
    },
    {
      "metadata": {
        "id": "OeS47Bmn5Ms2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_training_input_fn(features, labels, batch_size, num_epochs=None, shuffle=True):\n",
        "  \"\"\"A custom input_fn for sending MNIST data to the estimator for training.\n",
        "\n",
        "  Args:\n",
        "    features: The training features.\n",
        "    labels: The training labels.\n",
        "    batch_size: Batch size to use during training.\n",
        "\n",
        "  Returns:\n",
        "    A function that returns batches of training features and labels during\n",
        "    training.\n",
        "  \"\"\"\n",
        "  def _input_fn(num_epochs=None, shuffle=True):\n",
        "    # Input pipelines are reset with each call to .train(). To ensure model\n",
        "    # gets a good sampling of data, even when number of steps is small, we \n",
        "    # shuffle all the data before creating the Dataset object\n",
        "    idx = np.random.permutation(features.index)\n",
        "    raw_features = {\"pixels\":features.reindex(idx)}\n",
        "    raw_targets = np.array(labels[idx])\n",
        "   \n",
        "    ds = Dataset.from_tensor_slices((raw_features,raw_targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "    \n",
        "    # Return the next batch of data.\n",
        "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
        "    return feature_batch, label_batch\n",
        "\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OYlULlueainZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8zoGWAoohrwS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_predict_input_fn(features, labels, batch_size):\n",
        "  \"\"\"A custom input_fn for sending mnist data to the estimator for predictions.\n",
        "\n",
        "  Args:\n",
        "    features: The features to base predictions on.\n",
        "    labels: The labels of the prediction examples.\n",
        "\n",
        "  Returns:\n",
        "    A function that returns features and labels for predictions.\n",
        "  \"\"\"\n",
        "  def _input_fn():\n",
        "    raw_features = {\"pixels\": features.values}\n",
        "    raw_targets = np.array(labels)\n",
        "    \n",
        "    ds = Dataset.from_tensor_slices((raw_features, raw_targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size)\n",
        "    \n",
        "        \n",
        "    # Return the next batch of data.\n",
        "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
        "    return feature_batch, label_batch\n",
        "\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7qCsnIhLajwy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6DjSLZMu8Um",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_linear_classification_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear classification model for the MNIST digits dataset.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  a plot of the training and validation loss over time, and a confusion\n",
        "  matrix.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: An `int`, the learning rate to use.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    training_examples: A `DataFrame` containing the training features.\n",
        "    training_targets: A `DataFrame` containing the training labels.\n",
        "    validation_examples: A `DataFrame` containing the validation features.\n",
        "    validation_targets: A `DataFrame` containing the validation labels.\n",
        "      \n",
        "  Returns:\n",
        "    The trained `LinearClassifier` object.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "\n",
        "  steps_per_period = steps / periods  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create a LinearClassifier object.\n",
        "  my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  classifier = tf.estimator.LinearClassifier(\n",
        "      feature_columns=construct_feature_columns(),\n",
        "      n_classes=10,\n",
        "      optimizer=my_optimizer,\n",
        "      config=tf.estimator.RunConfig(keep_checkpoint_max=1)\n",
        "  )\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"LogLoss error (on validation data):\")\n",
        "  training_errors = []\n",
        "  validation_errors = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "  \n",
        "    # Take a break and compute probabilities.\n",
        "    training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
        "    training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
        "    training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10)\n",
        "        \n",
        "    validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
        "    validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
        "    validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10)    \n",
        "    \n",
        "    # Compute training and validation errors.\n",
        "    training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_errors.append(training_log_loss)\n",
        "    validation_errors.append(validation_log_loss)\n",
        "  print(\"Model training finished.\")\n",
        "  # Remove event files to save disk space.\n",
        "  _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
        "  \n",
        "  # Calculate final predictions (not probabilities, as above).\n",
        "  final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
        "  final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
        "  \n",
        "  \n",
        "  accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
        "  print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.plot(training_errors, label=\"training\")\n",
        "  plt.plot(validation_errors, label=\"validation\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "  # Output a plot of the confusion matrix.\n",
        "  cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
        "  # Normalize the confusion matrix by row (i.e by the number of samples\n",
        "  # in each class).\n",
        "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
        "  ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
        "  ax.set_aspect(1)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.ylabel(\"True label\")\n",
        "  plt.xlabel(\"Predicted label\")\n",
        "  plt.show()\n",
        "\n",
        "  return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ItHIUyv2u8Ur",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Spend 5 minutes seeing how well you can do on accuracy with a linear model of this form. For this exercise, limit yourself to experimenting with the hyperparameters for batch size, learning rate and steps.**\n",
        "\n",
        "Stop if you get anything above about 0.9 accuracy."
      ]
    },
    {
      "metadata": {
        "id": "yaiIhIQqu8Uv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "outputId": "26b60f3b-e27a-4d23-d572-c66fa3f0de67"
      },
      "cell_type": "code",
      "source": [
        "classifier = train_linear_classification_model(\n",
        "             learning_rate=0.02,\n",
        "             steps=100,\n",
        "             batch_size=10,\n",
        "             training_examples=training_examples,\n",
        "             training_targets=training_targets,\n",
        "             validation_examples=validation_examples,\n",
        "             validation_targets=validation_targets)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "LogLoss error (on validation data):\n",
            "  period 00 : 16.92\n",
            "  period 01 : 10.28\n",
            "  period 02 : 10.15\n",
            "  period 03 : 7.49\n",
            "  period 04 : 8.25\n",
            "  period 05 : 6.05\n",
            "  period 06 : 6.20\n",
            "  period 07 : 6.15\n",
            "  period 08 : 6.34\n",
            "  period 09 : 5.98\n",
            "Model training finished.\n",
            "Final accuracy (on validation data): 0.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFnCAYAAACLnxFFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xl4VOXd//H3mS3JZF9JCFtI2ENA\ncCHK5oKA1roWKRXFLvap2trq01ZafWql1fqz2qqttmprFZeq1F0BRRQBKQrKEkIIhLAFsu+ZLLP9\n/ghEIgQSyMwkmc/runKRnJlzzvfcxnzmPuc+9zG8Xq8XERER6fFMgS5AREREOkehLSIi0ksotEVE\nRHoJhbaIiEgvodAWERHpJRTaIiIivYRCW6QbjBgxguLi4m7Z1oEDBxg9enS3bCsQ5s+fz+TJk5k1\naxYzZ87kkksu4dlnn+3ydrZs2cL3vve9Lq83evRoDhw40OX1RHoDS6ALEJG+5+c//zmXX345AGVl\nZVx77bWkpaUxderUTm8jKyuLf/zjH74qUaRXUk9bxIeam5v5v//7P2bOnMns2bP5wx/+gNvtBmD1\n6tVMmzaN2bNn8/LLLzNhwoST9hCrq6u57bbb2nqwTz75ZNtrf/rTn5g5cyYzZ87k+uuvp6Sk5ITL\nj1i1ahWXXXZZu2WXX345n3zyCZ999hlXXnkll1xyCbNnz2bp0qVdboPExERmzZrF2rVrAdi1axfX\nXXcdM2fO5LLLLmPr1q0ArF+/nrlz53Lbbbdxxx13sH79embMmHHSdly1ahUzZsxg9uzZPP300237\nbWho4JZbbmH27NlceOGF3HXXXTidzi7XL9KTKLRFfOjZZ5+luLiYd999l9dff50NGzbwzjvv4Ha7\nufPOO7n33ntZunQpe/bsobGx8aTbe/jhh4mOjmb58uW8+OKLvPTSS2zYsIGdO3eybNky3nnnHZYv\nX86MGTNYt25dh8uPlp2dTXFxMfv37wdg//79FBcXc+655/LAAw+wcOFC3nvvPZ544glWrFhxSu3g\ncrmw2Wx4PB5uueUWLr/8cpYvX84999zDzTffjMvlAiA3N5e5c+fy0EMPdbodf/3rX/Ob3/yGpUuX\nYjKZ2sL8jTfeICoqiqVLl7J8+XLMZjO7du06pfpFegqFtogPffzxx8yZMweLxUJoaCiXXXYZa9eu\nZc+ePbS0tDBt2jSg9Tqwx+M56fZWrVrFvHnzAIiJiWHGjBmsXbuWqKgoKisrefvtt6mpqWH+/Plc\nccUVHS4/ms1m4/zzz2flypUArFixgosuugiLxUJ8fDxvvPEGBQUFDBky5Jgw7Yz9+/ezbNkyZsyY\nwe7du6moqOCaa64BYOLEicTFxfHll18CEBoaSnZ2dpfbcfLkyQBceeWVbesc2e6aNWvweDz89re/\nZdSoUV2uX6QnUWiL+FBlZSXR0dFtP0dHR1NRUUFNTQ1RUVFty5OSkjq9vaPXi4qKoqKign79+vHY\nY4+xbNkypk+fzk033cShQ4c6XP51M2fObBfal1xyCQD33XcfYWFh3HjjjVx88cUsW7asU3U++OCD\nbQPRbr/9du68806ysrKora2lqamJ2bNnM2vWLGbNmkVFRQXV1dVt7dPRcXfUjhEREe2WHzF79mwW\nLFjAI488QnZ2Nr/97W9paWnpVP0iPZVCW8SHEhIS2gIJWq9JJyQkEBERgcPhaFteXl5+WtsDmDRp\nEk8++SRr164lJSWFP/7xjydcfrQpU6aQl5fHnj172LNnD5MmTWrb3913380nn3zC//3f/7Fw4UIa\nGhpOWufPf/5zli1bxvLly3n11VfbPgQkJSURHh7OsmXL2r7WrFnTdu26q8cdHR1NfX192/LKysp2\n682dO5dXX32V9957j23btvHGG2+ctHaRnkyhLeJD06dPZ8mSJbjdbhwOB2+++SbTpk1jyJAhuFwu\n1q9fD8BLL72EYRid2t7LL78MtAbUBx98wPTp01mzZg2//e1v8Xg82O12Ro4ciWEYHS7/OpvNxuTJ\nk3nwwQe58MILMZvNOJ1O5s+fT2lpKQBjxozBYrFgMp36n43U1FSSk5PbeuyVlZXcfvvt7T7AdHTc\nx2vHQYMGYTab29rxtddeazu+v/71ryxZsgSAfv36MWDAgE61sUhPplu+RLrJ/PnzMZvNbT//7ne/\nY/78+ezfv59LL70UwzCYNWsWs2fPxjAM7rnnHhYuXEhkZCQ33ngjJpMJwzDwer243W5mzZrVbvtP\nPfUUP/3pT7nnnnuYNWsWJpOJm266iaysLJqbm3n33XeZOXMmNpuNuLg47rvvPpKSko67/HhmzpzJ\nj3/8Y/71r38BYLVaueaaa1iwYAEAJpOJu+66i7CwMD744ANWrlzJ/fff36U2MgyDhx9+mHvuuYc/\n//nPmEwmbrzxRux2+0nbtqN2XLRoEb/61a+w2WxcddVVbdu6/PLLWbhwIU899RSGYTBu3Li229BE\neitDz9MWCTyHw8EZZ5zBhg0biIyMDHQ5ItJD6fS4SIBcffXVvPfeewC89957pKenK7BF5ITU0xYJ\nkA0bNnDvvffS3NxMeHg499xzD1lZWYEuS0R6MIW2iIhIL6HT4yIiIr2EQltERKSX6NG3fJWV1XX7\nNmNj7VRVnfieUDl9amf/UDv7h9rZP9TOrRITOx6QGnQ9bYvFfPI3yWlTO/uH2tk/1M7+oXY+uaAL\nbRERkd5KoS0iItJLKLRFRER6CYW2iIhIL6HQFhER6SUU2iIiIr2EQltERKSXUGiLiEif8PHHH3bq\nfY888hAHDxZ1+Pqdd97eXSV1O4W2iIj0eocOHWTFiuWdeu9tt91B//6pHb7+hz883F1ldbsePY2p\niIhIZzz88ANs376NKVPO4uKLZ3Po0EH+/OfHuf/+eykrK6WxsZHvfvcmzjtvCrfeehO33/4LPvro\nQxoa6tm3by9FRQf4yU/uIDv7PC699ELeffdDbr31Js466xy++GID1dXVPPDAn0hISODee++muPgQ\nY8dmsXLlCl5//T2/HWfQhLbX62VD8RbODBuFgS3Q5YiI9FmvrNzF53mlXV7PbDZwu4//tOizRiYx\n54KMDtf99rfn89prr5CWls6+fXt4/PGnqaqq5OyzJzF79jcoKjrA3XffyXnnTWm3XmlpCX/846P8\n97+f8uab/yE7+7x2r4eHh/PII0/wxBOP8cknK+nffwAtLc08+eS/WLt2Na+88lKXj/N0BE1o1zQ2\n8K/tL7B8ZwZ3Tb0p0OWIiIiPjBo1BoDIyCi2b9/GW2+9hmGYqK2tOea9WVnjAUhKSqK+vv6Y18eN\nO6Pt9ZqaGvbuLWTs2HEAZGefh9ns3/nSgya0w21heJvDKHbvxe1xYzZpYnoREV+Yc0HGCXvFHUlM\njOyWpztarVYAPvhgGbW1tfz1r09TW1vL978//5j3Hh26Xu+xvfyvv+71ejEdzg/DMDAM47Tr7Yqg\nGYhmtZiJZQBes5NNB3cFuhwREelGJpMJt9vdbll1dTUpKf0xmUysWrUSp9N52vtJTR3Ajh25AHz2\n2X+P2aevBU1oA4yKGw7Aun1bA1yJiIh0p8GD09ixI4+Ghq9OcU+ffgGffrqa2277EWFhYSQlJfHM\nM0+d1n7OPXcKDQ0N/OhH32Pz5i+Jioo+3dK7xPAe73xAD9Edp0mOtq+8kj9seoAwTxwPXfzLbt22\ntNddp7nkxNTO/qF29o/e0M61tTV88cUGpk+/kLKyUm677Ue8+OJ/unUfiYmRHb4WNNe0AQbGx2Jp\njqcptJza5jqiQjpuGBERka+z28NZuXIFL764GK/Xw49/7N+JWIIqtA3DYJB9KIXeclbv3sqlo84N\ndEkiItKLWCwW7r33/oDtP6iuaQNkD84CYFPJ9gBXIiIi0jVBF9oXjM3E67RR7Nx73OH9IiIiPVXQ\nhXaUPQS7MxmPuYmCygOBLkdERKTTgi60AdIjW2/6X1O4JcCViIiIdF5QhvZ5h69r76jeGeBKRETE\nn6655jIcDgeLF/+LnJz2HTeHw8E111x2wvWPPP7zvffeZtWqj3xWZ0eCavT4EWMGJUNOFLWhxTS7\nWwgx6wEiIiLBZP78BV1e58jjP6dPv5BLLjlxuPtKUIa22WQi3jSIClMOn+/PZfKQ8YEuSURETsN3\nv/sd7rvvIZKTkykuPsTChXeQmJhEY2MjTU1N/OxnP2f06My29//+9/cwffqFjB9/Br/+9S9oaWlp\ne3gIwPvvL2XJkpcxm00MGZLOL3/567bHfz7zzFN4PB5iYmK4+uprefzxR9i6dTMul5urr57DrFmX\nHvexnsnJyad9nEEZ2gCZCSNYVZ/D5we2KbRFRLrRa7ve4cvSrk8XbTYZuD3Hv6vnjKSxXJXxjQ7X\nnTr1fNau/YSrr57D6tWrmDr1fNLThzF16nQ2bvycF154lt///sFj1lu+fClDh6bzk5/cwYcfvs+K\nFcsBaGxs5KGHHiMyMpJbbvkBBQW72h7/eeONP+Af//g7AJs2fcHu3QU88cQ/aWxs5IYb5jJ16nTg\n2Md6zpkzr8tt8nVBeU0bYErGaLxuM/sadwe6FBEROU2tob0agDVrVjF58jRWrfqQH/3oezzxxGPU\n1Bz7WE6APXt2k5nZ+qjNM86Y2LY8KiqKhQvv4NZbb2Lv3kJqaqqPu35eXi7jx08AICwsjCFDhrJ/\n/36g/WM9j/fYz1MRtD3tlLhIrI2JtEQUU1JfTr+IhECXJCLSJ1yV8Y0T9oo7cjpzjw8dmk5FRRkl\nJcXU1dWxevXHJCQkcffdi8jLy+Uvf/nzcdfzesFkan28pudwL9/pdPLww/+Pf/3rReLjE/jFL37a\n4X4Nw+DoKT9cLmfb9k722M9TEbQ9bYABYUMBWLNHt36JiPR22dmTefLJx5kyZRo1NdWkpg4AYNWq\nj3C5XMddZ9CgweTltc6Q+cUXGwBwOBowm83ExydQUlJMXt52XC7XcR//OXLkGL78cuPh9RwUFR1g\nwIBBvjrE4A7ts1LHALC1LC/AlYiIyOmaNu38ttHds2Zdyssvv8DPfnYLY8ZkUlFRwbvvvnXMOrNm\nXcq2bVu57bYfsX//XgzDIDo6hrPOOofvf/96nnnmKebNm8+jjz7c9vjPRx99qG39cePGM2LESG65\n5Qf87Ge38D//cythYWE+O0afPpozPz+fm2++mQULFnDdddfhdDq588472bt3L+Hh4Tz66KNER3f8\nLFJfPKLt6NMvjiYXd6z8HWZbC49csAizyXyStaWzesMj9voCtbN/qJ39Q+3c6kSP5vRZT9vhcLBo\n0SKys7Pblr3yyivExsayZMkSLrnkEjZs2OCr3XeKPdRCpLs/XpOL3LKCgNYiIiJyMj4LbZvNxlNP\nPUVSUlLbso8++ohvfvObAFx77bVceOGFvtp9pw2PHgbAp3u7fnuCiIiIP/kstC0WC6Ghoe2WFRUV\n8cknnzB//nx+9rOfUV19/CH0/nTe0Ey8HoNdtbsCXYqIiMgJ+fWWL6/XS1paGrfeeiuPP/44f//7\n3/nlL3/Z4ftjY+1YLN1/nfno6wVx8RH85Ys4HBEVWCO8xIRFdfv+gtWJrstI91E7+4fa2T/Uzifm\n19BOSEjgrLPOAmDy5Mk89thjJ3x/VZWj22s43kCHfubBlFDB0k3ruShjUrfvMxhpQIl/qJ39Q+3s\nH2rnVgEZiHY8U6dOZfXq1hlrtm3bRlpamj9336Fx/UYCsPFQboArERER6ZjPeto5OTk88MADFBUV\nYbFYWL58OX/84x/5/e9/z5IlS7Db7TzwwAO+2n2XnJs+nOXrQyjy7MHj9WAygvr2dRER6aF8FtqZ\nmZksXrz4mOWPPvqor3Z5yhJj7dia+uGM2se+miKGxAwMdEkiIiLHUJfysCHh6QCs1a1fIiLSQym0\nD5s0cAxeL+RW5ge6FBERkeNSaB82Lq0/Xkc01Z5imlxNgS5HRETkGArtw8JCLMR4UsHwsKVEvW0R\nEel5FNpHGRU/AoD1+3MCXImIiMixFNpHOXfoSLwuC4UNeniIiIj0PArtowxNjsFoSKDZqKO0oSzQ\n5YiIiLSj0D6KyWTQ3zYEgPUHdIpcRER6FoX210xIGQ3AppK8AFciIiLSnkL7a85OH4KnMZwS535c\nHlegyxEREWmj0P6a+OhQQpuT8RoudlYWBrocERGRNgrt48iIzABg3T5NaSoiIj2HQvs4Jg0ejddj\nYkf1zkCXIiIi0kahfRxjhiTirY+lngpqmvVAdhER6RkU2scRarMQT+vjOb8szg1wNSIiIq0U2h3I\nTGyd0nRD0bYAVyIiItJKod2Bc4Zm4G0JYX9jIR6vJ9DliIiIKLQ7Mjg5ClN9Ei6jmX21RYEuR0RE\nRKHdEZNhMCAsDYDPNKWpiIj0AArtEzgzdTReL+SU7wh0KSIiIgrtE5kwtD/ehmgqXIdodDUGuhwR\nEQlyCu0TiIsKxe7sD4aX3HJNtCIiIoGl0D6J4dHDAFi/X9e1RUQksBTaJ3HOkBF4XRYK6grwer2B\nLkdERIKYQvskRg2Kw1ubQBN1lDrKAl2OiIgEMYX2SYTYzCSaBwHwRfH2AFcjIiLBTKHdCeP6jQLg\ny0Oah1xERAJHod0JZw4dhMcRwcHmfTjdzkCXIyIiQUqh3QkD+0VgdiThNdzsqi4MdDkiIhKkFNqd\nYDIM0sKHAvC5nvolIiIBotDupDMHjsLrMZFbmR/oUkREJEgptDspKy0JT20cdZ4KqptrAl2OiIgE\nIYV2J8VGhhDp7g9ATllegKsREZFgpNDuglFxwwH4vEi3fomIiP8ptLvgrCFD8TSHsqdhNx6vJ9Dl\niIhIkFFod8HwQbFQm4iLZvbWHgh0OSIiEmQU2l0QYjWTbBsMwJfFOkUuIiL+pdDuojNSRuL1Gmwp\n1WA0ERHxL4V2F41PS8FTH01ZyyEcTkegyxERkSCi0O6iAUkRWBv7geElr3JnoMsREZEg4tPQzs/P\n56KLLuL5559vt3z16tWMGDHCl7v2GZNhkB6ZDsCGg7quLSIi/uOz0HY4HCxatIjs7Ox2y5ubm3ny\nySdJTEz01a597sxBw/C6rOyo3onX6w10OSIiEiR8Fto2m42nnnqKpKSkdsv/9re/MW/ePGw2m692\n7XOZaQm4a+Jp8tZT7CgNdDkiIhIkfBbaFouF0NDQdssKCwvJy8tj9uzZvtqtX8REhBDtGQDAVk1p\nKiIifmLx587uv/9+7rrrrk6/PzbWjsVi7vY6EhMjT3sbZw3M5OOmDWwp28F3zvpGN1TV93RHO8vJ\nqZ39Q+3sH2rnE/NbaJeUlLB7927+93//F4DS0lKuu+66YwapHa2qqvtvqUpMjKSsrO60tzO6fzIr\ncyLYSyFFxZXYzNZuqK7v6K52lhNTO/uH2tk/1M6tTvTBxW+h3a9fP1asWNH28wUXXHDCwO7phg+I\nhnVJeOy72VW9m9HxvXM0vIiI9B4+u6adk5PD/Pnzef3113nuueeYP38+1dXVvtqd31ktZlJDhgCw\nqXh7YIsREZGg4LOedmZmJosXL+7w9ZUrV/pq134zIXUE79SuYmu5BqOJiIjvaUa005A1NBFPXRy1\n7kqqmvrOWQQREemZFNqnITUhHFtjPwC2VewIcDUiItLXKbRPg2EYjIgZBsAXhzSlqYiI+JZC+zRN\nGDwET3MYBbUFuD3uQJcjIiJ9mEL7NI1Ji8dTnYCLFvbW7Q90OSIi0ocptE9TVLiNOENTmoqIiO8p\ntLtBVr8ReD2G7tcWERGfUmh3g/FpyXjqYyhtPkS9syHQ5YiISB+l0O4GGQNiMOoSwYAdlTsDXY6I\niPRRCu1uYLWYGGQfCsCmEl3XFhER31Bod5MJAzPwOm1sr9yB1+sNdDkiItIHKbS7SebQeNw18TR6\nGjjYUBzockREpA9SaHeT/vF2wppTAMjVlKYiIuIDCu1uYhgGo+KGA/BFsaY0FRGR7qfQ7kbj01Lx\nNERxoGEfze6WQJcjIiJ9jEK7G40eEounJh4PHnZWFQS6HBER6WMU2t0o0m4jwTwIgBxNaSoiIt1M\nod3NxqcMw+s2s0WhLSIi3Uyh3c3GpiXiqY2nxlVFRWNloMsREZE+RKHdzdJTozHqEwHIrcwPcDUi\nItKXKLS7mdViIi0iHYDNJXrql4iIdB+Ftg+cMXgwniY7O2sKcHvcgS5HRET6CIW2D2SmxeGpScDl\nbaGwdl+gyxERkT5Coe0DyXF27M7DU5qWa0pTERHpHgptHzAMgzEJw/B6DDaV6rq2iIh0D4W2j2Sl\n9cNTH0tJ0yHqWuoDXY6IiPQBCm0fGT2k9bo2QF7lzgBXIyIifYFC20ciwqwkWwcDsFWzo4mISDdQ\naPvQuNQ0vC02civy8Xg9gS5HRER6OYW2D2WmxeOuTaDR00BRfXGgyxERkV5Ooe1D6anRmOqTANhe\nqVu/RETk9Ci0fchiNjEsOgOvV1OaiojI6VNo+9i4If3xNkSxr34fTa7mQJcjIiK9mELbx8akxeGu\nScCDh53VBYEuR0REejGFto/1iw0jwtUfgG2a0lRERE6DQtvHDMMgMzkDr9vMFt2vLSIip0Gh7QdZ\naQl4ahKocVZR5qgIdDkiItJLKbT9YOTgWDy18YBu/RIRkVOn0PaDiDAr/UPSAE1pKiIip06h7Sfj\nBg7E0xjOzuoCXB5XoMsREZFeyKehnZ+fz0UXXcTzzz8PwKFDh1iwYAHXXXcdCxYsoKyszJe771HG\npLU+9cvpdbK7Zm+gyxERkV6o06FdX9/6TOjy8nI2bNiAx3PiB2A4HA4WLVpEdnZ227I///nPzJkz\nh+eff54ZM2bwzDPPnGLZvc/Q/lGYG1qnNM2t0HVtERHpuk6F9qJFi1i6dCnV1dXMnTuXxYsXc889\n95xwHZvNxlNPPUVSUlLbst/85jfMnDkTgNjYWKqrq0+98l7GYjYxIi4dr8fQdW0RETklls68KTc3\nl7vvvpuXXnqJK6+8kltuuYUbbrjhxBu2WLBY2m/ebrcD4Ha7efHFF7nllltOuI3YWDsWi7kzJXZJ\nYmJkt2+zM7LHDmL7tjiKTcVYI73EhEYFpA5/CVQ7Bxu1s3+onf1D7XxinQptr9cLwMcff8xPf/pT\nAFpaWk5ph263m1/84hdMmjSp3anz46mqcpzSPk4kMTGSsrK6bt9uZwxOtOOpScAcXcGa/C84J2Vi\nQOrwh0C2czBRO/uH2tk/1M6tTvTBpVOnx9PS0rjkkktoaGhg1KhRvPHGG0RHR59SMQsXLmTw4MHc\neuutp7R+b5YUE0aU+/CUprquLSIiXdSpnvbvfvc78vPzSU9PB2DYsGFccMEFXd7ZW2+9hdVq5Sc/\n+UmX1+0LDMNgbOoQ1reEkFuRj8frwWTorjsREemcToX29u3bKSsrY9SoUfzpT39i06ZN/PjHP+bM\nM8/scJ2cnBweeOABioqKsFgsLF++nIqKCkJCQpg/fz4A6enpJx3Q1tdkpsXz6aYEGm1FHKg7yKCo\nAYEuSUREeolO97T/8Ic/sGHDBrZu3crdd9/Nvffey3PPPdfhOpmZmSxevLjbCu0rRg2OxftJIiQW\nkVu5Q6EtIiKd1qlzsyEhIQwZMoQPP/yQOXPmkJGRgcmk07qnwh5qZaB9CF4v5OhRnSIi0gWdSt7G\nxkaWLl3KihUrmDx5MtXV1dTW1vq6tj4ra3AK3oZo9tTuo9HVFOhyRESkl+hUaN9+++28/fbb3H77\n7URERLB48WIWLFjg49L6rjFpcbhrEvDiIb9qV6DLERGRXqJT17QnTZpEVlYWhYWF5Obm8v3vf5+w\nsDBf19ZnpaVEYnX0AwrIrdjBuMTMQJckIiK9QKdCe8WKFdxzzz0kJyfj8XgoLy9n0aJFTJs2zdf1\n9Ulmk4lRiWnkuj4jp3wHXq8XwzACXZaIiPRwnQrtp59+mrfeeou4uDgASkpKuO222xTapyEzLYGc\ngniqLSWUNpbTz54Y6JJERKSH69Q1bavV2hbYAP369cNqtfqsqGBw5Lo2wPaK/ABXIyIivUGnQjs8\nPJx//vOf5OXlkZeXx9NPP014eLiva+vTEmPCiKX1Hu1tFXrql4iInFynTo///ve/55FHHuGtt97C\nMAzGjx/Pfffd5+va+ryxAwfwqSOCfGM3To8Lq6lT/zlERCRIdSol4uPjuffee9stKygoaHfKXLou\nc0gcazbE47LvpaC6kJFxwwJdkoiI9GCnPK3Zb3/72+6sIyiNHByLp6Z1AFpupWZHExGREzvl0D7y\njG05dWEhFtIiB+P1mNimKU1FROQkTjm0dV9x98hMS8JTG0exo4Tq5ppAlyMiIj3YCa9pL1mypMPX\nysrKur2YYDQmLY638xMwx5SzvXIn2SkdP+5URESC2wlDe+PGjR2+Nn78+G4vJhilJUdha+wH5JFb\nkafQFhGRDp0wtO+//35/1RG0TCaD0SkDyWkOZXvFTjxeDyZDjz0VEZFjdeqWr3nz5h1zDdtsNpOW\nlsbNN99Mv379fFJcsMhMi2dLXgKNIQfYV3eAIVGDAl2SiIj0QJ3q0p177rkkJydzww03cOONNzJw\n4EAmTpxIWloaCxcu9HWNfd6YIV9NaZpboVHkIiJyfJ3qaW/cuJFnnnmm7eeLLrqIm266iSeffJIP\nP/zQZ8UFi4SYMBLMA6j1biK3Ip9L0mYEuiQREemBOtXTrqiooLKysu3nuro6Dh48SG1tLXV1dT4r\nLpiMHZSMpz6GPbX7cDgbA12OiIj0QJ3qaV9//fXMnj2b1NRUDMPgwIED/PCHP+Sjjz7i2muv9XWN\nQWFMWhyr1iXgjaxmR9UuzkgaG+iSRESkh+lUaF9zzTXMmjWLPXv24PF4GDRoEDExMb6uLaiMGBQD\n7ycCu8it2KHQFhGRY3QqtBsaGnj22WfZunVr21O+brjhBkJDQ31dX9AIC7GQFjOQ/a4NbKvYgdfr\n1axzIiLSTqeuad99993U19czd+5c5syZQ3l5OXfddZevaws6mWkJuGviqWmpocRRGuhyRESkh+lU\nT7u8vJyHH3647efzzz+f+fPn+6yoYJWZFsdbuQkQX0xuxQ6Sw3X/u4iIfKVTPe3GxkYaG78a0exw\nOGhubvZZUcFqcL9IQppagzr+lM25AAAgAElEQVS3Mj/A1XRdfaOTdTnFPPn2Nt5dWxjockRE+pxO\n9bSvvfZaZs+eTWZmJgDbtm3jtttu82lhwchkMhgzIJUtjgh2GrtpcTuxma2BLqtDXq+XgxUONu8q\nZ/OucnYV1XDkia2f5ZaQcuPZDEyKCGyRIiJ9SKdHj5933nls27YNwzC4++67Wbx4sa9rC0pj0uL4\nMicBl30PBdWFjIofHuiS2nG6POTvr2bT4aAur2kCwADSU6MZlxFPeKiV55bv4Pn3d3DndyZoQJ2I\nSDfpVGgDpKSkkJKS0vbzli1bfFJQsBszJA7P2gRI2UNu5Y4eEdq1DS1sKahgc0E5OYWVNLe4AQi1\nmTlzZBLj0uMZmx5PlN3Wts6OAzWs31bMf3NLyB6THKjSRUT6lE6H9td5j5wHlW4VHx1Kki2VaveX\n5Fbs4Ophl/m9Bq/Xy4GyhrbT3rsP1nLkv3ZiTCjjslIYn5HA8IExWMzHHxbx/csz+WJHKa+s3MX4\njATCQk75V01ERA475b+kOuXpO5mDE/mkLo5icylVTdXEhvp+Ihuny03evtbT3lt2lVNR2zrQ0DBg\n2MAYxmXEMy49gZR4e6f+2yfHh3PJpMG8uaaQN9cUMvfCYb4+BBGRPu+EoT1t2rTj/oH2er1UVVX5\nrKhgNyYtjo9Wx2OOKSO3cgfn9T/HJ/upqW9mc0EFm3eVk7unimZn62nvsBALZ49KYnxGAplD44kI\nO7XBcLPPGcTarYdYseEAU7JSSE3UoDQRkdNxwtB+8cUX/VWHHGXEoBioTQTy2F6R322h7fV62VdS\n33rau6CcwkNfPeylX5yd8Yd70xkDojs87d0VNquZeRcN59H/bOGFD/L5+bfP0BkaEZHTcMLQTk1N\n9VcdcpRQm4WMxP7saQ5je+VO3B43ZpP5lLbV4nSTu7eKLbvK2VxQQVVd62lvs8lg5KAYxmckkJWR\nQHKcvTsPoc34YQlkpcezpaCCz7aXcs5oTRgjInKqNDqoh8pMi2f33gSaQvazt+4AQ6MHd3rdqrpm\nNheUs3lnOdv3VtHi8gAQHmohe0w/xmUkkJkWhz3UP/eAz7toGLl7qnh55U7GZcQTatOvnYjIqdBf\nzx5qTFocr29JwJK0n+V7PmRU/AjsljDCrXbslrDWr8PfG4aJvcV1h0d7V7C35KvT3v0TwhmXHs+4\njATSU6Mwm07/tHdXJcXamX3OIN7+dA9vr93Dt87P8HsNIiJ9gUK7hxrUL5Kwln543GZyKvLIqcjr\n+M1uMx6XFdxWiLMSn2wnISKK1NgYEiK82C1uai117KiyY7ceDnyLnTBL6Cmfdu+qS7IH82lOMe9/\nvp/JWSmkxIf7Zb8iIn2JQruHMhkGYwYl8fnWydx45SDC7B7K6mopLK3gQGU1lQ11eM0tYHZitrkI\nDfFAaAst3jocVLLPCftKgZM8LCzUHHpUkIcd/v6ocLe279UfeS3MEorJ6HyvPcRqZu6Fw/jr61t5\n4YN87rh2vAaliYh0kUK7BxuTFsdn20v573oXtQ1ODpQ5gSggigGJEYzLiGd8RgJpKVGYTK0B6PF6\ncLgacTgbaTz8r8PloMHZ2Lrc5aDx8PcNTkfbe8sbK2hyd/4hMAYGoZbQ9sF+VLhfYJ5EFHHt1pkw\nvPVaek5hJRt3lHHmyKRubC0Rkb5Pod2DjRkShwHk7qnCYjbIHBrXOto7PZ6E6LDjrmMyTERYw4mw\ndv30s9vjPhzsR8K+kUang4ajwr91WSMNLkfbe0ocZbS4W9pta/XBdSw862ckhH0V3IZhMG/GcO5+\nej3/XrmTsUPjCbH55/S8iEhf4NPQzs/P5+abb2bBggVcd911HDp0iF/84he43W4SExN58MEHsdls\nJ99QkIqLCuW2b2XhcnsZPSTW56OuzSYzkbYIIm1dnwTF5XHR6Gqiwekgt3IH/9n5Ns/lvsxPJ/yw\n3Wn05Dg7s84ZxLvr9vLOuj1cPS29G49ARKRv89lQYofDwaJFi8jOzm5b9uijjzJv3jxefPFFBg8e\nzJIlS3y1+z4jKz2BCcMTe/xtUhaThUhbBMnhSZw/YDKTBkygoKaQD/d9csx7v5E9hLioEJZ/to+S\nSkcAqhUR6Z18Fto2m42nnnqKpKSvrluuX7+eCy+8EIDzzz+fdevW+Wr3EkCGYfCDM79NtC2St3cv\n50DdwXavh9jMzL1gGC63lxdW5OvhMyIineSz7pvFYsFiab/5xsbGttPh8fHxlJWVnXAbsbF2LJbu\nv+aZmBjZ7duUY9086Xru/+SvvJD/KvfN+CU281eTucxKiGDttmI27yynoKSB7LEpJ9iSnIh+n/1D\n7ewfaucTC9g51870rqqquv/UaWJiJGVldSd/o5yWxMRIBlgGMyU1m9VF63jmsyVclfGNdu/51rR0\ncgoq+PtrWxgYH0aIVYPSukq/z/6hdvYPtXOrE31w8ev0WHa7naamJgBKSkranTqXvunKjEtJCktg\n5b7V7KwqaPda/4RwZpw1kIraJt5btzdAFYqI9B5+De1zzz2X5cuXA/D+++8zZcoUf+5eAiDEbOP6\n0XMxDINnc1+m0dXY7vXLzh1CTISNpev3UeqDMysiIn2Jz0I7JyeH+fPn8/rrr/Pcc88xf/58br31\nVt544w3mzZtHdXU1V1xxha92Lz1IWvQgZg6+gKrmal7Nf6vda2EhFq69YBgut4eXVuwMUIUiIr2D\nz65pZ2Zmsnjx4mOWP/PMM77apfRgs4dcyLaKPNYXbyQrYTTjk8a2vXb2qCRWbSpic0EFm3aVMz4j\nIYCVioj0XP5/5JMEJbPJzA2j52I1WXhxx3+oaf5qsMmRmdJMhsFLK/JxutwBrFREpOdSaIvfJIcn\ncUXGpTQ4HbyQ92q7OwgGJEZw0ZkDKKtuYul/9wWwShGRnkuhLX41NTWbkbHD2FaRx5qD69u9dvnk\nNKLDbbz7372UVTd2sAURkeCl0Ba/Mhkm5o+eg90Sxms736bUUd72WliIhTnnZ+B0efj3hxqUJiLy\ndQpt8buYkGjmjriSFo+T53L/jdvz1TXsSWP6MXxANF/uLGdLQUUAqxQR6XkU2hIQE/uN58x+4yms\n3cf7ez9uW24YBt+5eAQmw+DFFfk4XZ7AFSki0sMotCVgrh1+BTEh0by35wP21R5oWz4wKYILJqRS\nWtXI8s80KE1E5AiFtgSM3Wpn/qg5eLwe/pX7b1rczrbXrpiSRpTdyjuf7qGipimAVYqI9BwKbQmo\nkXHDmD7gPEocpbxZ8F7bcnuolWumZ9Di8vDvlRqUJiICCm3pAS5Pv4R+9iQ+PrCWvMqvAvrcscmk\np0axcUcZ2worA1ihiEjPoNCWgLOZrSwYPReTYWLx9ldwOFsfHGIyDK6bMQLDgBc+yMfl1qA0EQlu\nCm3pEQZFDeCSITOobq7h5fw32pYPTo5k+hmpFFc6+ODz/QGsUEQk8BTa0mNcPHg6aVGD2FCyiQ0l\nm9qWXzllKBFhVt5au4fKWg1KE5HgpdCWHsNsMnP96LnYTFb+veN1qptrAIgIs3LN9HSanW5e+WhX\ngKsUEQkchbb0KEn2BK4adhmNrkYW576Cx9t6HXtyVgppKVF8tr2U7XurAlyliEhgKLSlx5nc/xzG\nxI8kr2onnxStAw4PSrt4OAYalCYiwUuhLT2OYRh8Z+Q1hFvtvLHrXYobSgFIS4li6vj+HCxv4MON\nB06yFRGRvkehLT1SdEgU80ZcjdPj4tncl9oeKnL1tHTCQy28uaaQ6vrmAFcpIuJfCm3pscYnjeWc\n5Insqyti6Z4PgdZBaVdPS6epRYPSRCT4KLSlR/vW8G8SGxLD8r0rKaxpfXjI1HH9GZwcyX+3lbBj\nnwaliUjwUGhLjxZmCeOG0dfi9Xp5LvffNLtbMJkMrpsxHGgdlOb2aFCaiAQHhbb0eMNi07lg4BRK\nG8t5fde7AKSnRjM5K4UDZQ2s3FgU4ApFRPxDoS29wmVDZ9I/PJnVRevYVpEHwDXT07GHWHhjzW5q\nGloCXKGIiO8ptKVXsJqt3DB6LmbDzPPbX6Xe2UCU3caVU4fS2OxmiQaliUgQUGhLrzEgsj/fGHox\ntS11vJT3Gl6vl/PPSGVQUgRrc4rZdaAm0CWKiPiUQlt6lYsGTSM9egibyrbyWfEXrYPSLh4BwPPv\n78Dj8Qa4QhER31FoS69iMkxcP3ouIWYbr+S/SWVTFRkDojkvM5l9pfV89KUGpYlI36XQll4nISyO\na4ZdTpO7iedyX8bj9XDN+RmEhZh5/ZPd1Do0KE1E+iaFtvRK2SlnkpUwhp3Vu/lo/xqiw21cMXko\njmYX//m4INDliYj4hEJbeiXDMJg38moirRG8tXsZB+uLuWBiKgMSw1m95RAFBzUoTUT6HoW29FqR\ntgjmjbwal8fFv3JfwoOH7xyeKe359/M1KE1E+hyFtvRqWYljODflbIrqD/Fe4QeMGBTLpDH92Ftc\nxyebDwa6PBGRbqXQll7v6mHfID40jg/2fsyu6kLmnJ9BiM3Mf1YVUN/oDHR5IiLdRqEtvV6oJZQb\nRs8F4LnclwkN9XL5eWk0NLn4zyoNShORvkOhLX1CeswQZgyeTkVTJf/Z+TYXnTmA/gnhfLLpIIWH\nagNdnohIt1BoS59xadoMBkT059NDn5NbuZ3vzBiOl8OD0rx9Z1Cay+1h065ynngjhwef30CL0x3o\nkkTETxTa0mdYTBZuGD0Xi8nCC3lLGJBi5exRSRQeqmXNlkOBLu+0eL1e9hbX8eKKfG7/20c8vuZN\nttiWsN79En95a4OeKS4SJCyBLkCkO/WPSOabQ2fx2q53eCFvCd+afi2bd1Ww5OMCJgxPJCLMGugS\nu6Sqrpn/5hazNucQxY1FmJP2YxlRjNXkwYQJDx52ulbwzFI737skE8MwAl2yiPiQQlv6nPMHTian\nfDtby3PJSsjhm+cN4dWPC3h99W7mH364SE/W7HTzZX4Zn+YUs21fKaa4g1j67SfEXgdAUlgCUwZk\nc07yRF4vfId1BzbwecUKoj4KZc4FwwJcvYj4kl9Du6GhgV/+8pfU1NTgdDq55ZZbmDJlij9LkCBg\nMkzMHz2H36//E0t2vskvJt7G6i12Pv6yiKlZ/RmcHBnoEo/h8XrZub+atTnFbMgrpdlcjSVpP2Fn\nHMRrcmHCRFbiWKamZjM8Nr2tR33rpOs5uKyUvexjxYGPiFofwqxzBgX4aETEVwyv138jdJ5//nlK\nSkq44447KCkp4YYbbmDZsmUdvr+srK7ba0hMjPTJdqW9ntDO6w9t5LntLzM0eggXx87hT69sIT01\nioXXTcTUQ04jl1Q6+DSnmHXbiimvdWCOLSa0fxEeewUAMSHRnNf/bM7tfzYxIdHHrJ+YGMnuokP8\n4bNHqW6ppmXXOBZkX8B5Y1P8fSh9Wk/4fQ4GaudWiYkddyz82tOOjY1lx44dANTW1hIbG+vP3UuQ\nOTt5AlvLc/mybCuHErYycUQiG3eUsS6nOKCh1tDk5PPtpXyaU8yuohoMm4OQ5CIihxfhMprwAKPi\nhjMldRKZ8aMwm8wn3F6kLYJbxn+XBzf8BYZu5V+r7ISHTWF8RoJ/DkhE/MavoX3ppZfy2muvMWPG\nDGpra/n73//uz91LkDEMg7kjr2J3zR7e2f0+N026ia27K3j1o12cMSwBe6j/BqW53B5yCiv5NKeY\nTTvLcbndmGPKiBtXTGNI63SrIRY701KmMjn1HJLsiV3afv+IZL4/9jqe2PwM1mEbeeLdUO64Kpvh\nA2N8cTgiEiB+PT3+5ptvsmHDBhYtWkReXh6/+tWveO211zp8v8vlxmI5cS9D5GS+PJTD/Z/8lYFR\nKZxpuYYXl+3ksilDuemKsT7dr9frZXdRDSs37GfVlweoqW8BSzPxaaUQvx+Hp3XSl2HxaVycPpXs\ngROwWWyntc+l+R/xzJev4HFEYt59Hn/40XTS+h97Wl1Eeie/9rS/+OILJk+eDMDIkSMpLS3F7XZj\nNh8/mKuqHN1eg66Z+EdPaucBlsFMSc1mddE6MgZsol9sAu+s2c2ZwxIYmBTR7fs7cpvWpznFFJU1\nAF7C4+sYOLKYStMeHHiwGTbO638OU1KzGRjZH4CaqmaguUv7+no7T4yZyK7U/awuWocrdSN3/d3K\nr687k8SYsG48wuDTk36f+zK1c6sec0178ODBbN68mZkzZ1JUVER4eHiHgS3Sna7MuJQdlTv5+MAa\nvjH5Wl55u5Hn39/Bnd+Z0C33Nre7TWtPJV4vmK0u0jJraI4qpMpVTjmQHN6PKamTOCd5AmGW7g9S\nwzD41rBvUuYoJ4+dOJq28tDLFhZeN5Ho8NPrxYtI4Pn19HhDQwO/+tWvqKiowOVycdttt5Gdnd3h\n+zV6vPfqie1cWLOPh794nGhbFAnFF7NlZy0/+MZosjOTT2l7X79Nq6mldTrRgYPdRA48SJFrJy2e\nFsyGmfGJmUxJzSYjJq1bJ0DpqJ0dzkb+uPGvlDhKaSkcQ6ppFL+cN4GwEE3NcCp64u9zX6R2bnWi\nnrZfQ7urFNq9V09t53d2v8/SPSsYFzeOjStSsYdYuO+mSV0Ks3a3adU0ARAXbSFtVD01oTspchS1\nLguNZXL/c8jufxZRNt/cG36idi5zVPDgxsdwtDTSlHcmw2PT+dmccVg1TqTLeurvc1+jdm7VY06P\niwTa7CEXsq0ij82Vm5l4dj/++6mHN9cUMvfCE88kduQ2rbU5hygoah1AFmIzMzHLjq3fAfIbcsh1\nOTAcBmPiRzI1NZvR8SMwGYGb3j/RHs8PMq/nsU1PETZiMztyQnnyLSs/uiITk6ln3KcuIl2j0Jag\nYjaZuWH0XP7w+Z/ZyWri46exYsMBpmSlkJrYflBa221aWw+xaVc5LrcXAxg9JJqBwxwUG9vJrd4F\nNRBhDefiwedzXv9zSAiLC8zBHcew2KF8e+TVPL/9FSJGb2LjZivPLbdyw6wRmqdcpBdSaEvQSQ5P\n4oqMS3k1/00Gjsmn4pNhvPBBPj//9hkA7CupZ23OIdbnllDncAKQEm9n4pgoPHF7+bJiGYU1NQCk\nR6cxNXUS45LGYjX1zP+dslPOpKShlA/2fUzUmK18ssVCVLiVq6amB7o0EeminvlXRsTHpqZms7Us\nl7yqnQweHU9ersEzS/MoPFR7+DYtiAizcsHEVAamNZHfuJmPynPxHPQQag5hauq5TEmdRP+IUxvE\n5m/fTJ9FqaOMzeXbiBq+g3c+NYgMszHjrIGBLk1EukChLUHpq4eKPExV1CYs9nNZs+UQFrPBxBGJ\nTBwdQ13obj499Cbr9pUDkBqRwpTUbM7qdwahlpAAH0HXmAwTN4z5Nn/a+Dj72UvEoAhe+tAgwm4l\ne0zv+OAhIgptCWIxIdHMHXEl/9z2IqkT85lqv4bkVCcbyjfw70ObcHpcWEwWzk6ewJTUbNKiBvXq\n68AhZhs/zFrAgxseoyZ5G2GNdv757nbCQ61kpccHujwR6QSFtgS1if3Gs6U8lw0lm1jBc1TntF6r\nTgiLZ0rqJCYln0mELTzAVXaf2NAYfpi1gD998TcYuhlX09k8/vpW/vfbZ5CRqulORXq6wN2PItJD\nXDv8CmJDYqhpriUrYQy3jPsev5n0cy4aNK1PBfYRg6MGcv3oa3F6W4jJ3ILLaOKRVzdTVFYf6NJE\n5CTU05agZ7faWXj2T3F73T6bBKWnmZCURenQWby9exn9z8rlwLqxPPzKZhZeN4GEaM1TLtJTqact\nAoRb7UET2EfMHHw+ZydPoMJVTPqkPVTVNfHQy5updbQEujQR6YBCWyRIGYbBvJHXMDR6CAfdOxl1\ndjkllQ7+/MpmGptdgS5PRI5DoS0SxKwmCzeNvZ740Dj2sJHR4xvZU1zHX1/fitPlCXR5IvI1Cm2R\nIBdpi+B/shYQag5lf8haRozwkruniqfeycXj6bHPExIJSgptEaF/RDLfzfwObq+byoS1DB1sYUNe\nKS+syKcHPwhQJOgotEUEgDHxI7hm+Depd9bjTfuc1KQQPvqiiLfW7gl0aSJymEJbRNpMH3AeU1Oz\nKXaUkDg+j4SYEN5cU8jKLw4EujQRQaEtIl9zzbBvMipuODuqdzD2vFKiwm288H4+n20vCXRpIkFP\noS0i7ZhNZr475jsk25P4b9k6LrjITWiImafezmVbYWWgyxMJagptETmG3RrG/2TdSLjVzgfFS7ly\ndhSGYfCX17ay+2BtoMsTCVoKbRE5rkR7PDeNvQEDg2Wlb/DtS1Jocbn586ubOVTREOjyRIKSQltE\nOpQRk8a8kVfT6Grkk9o3mXvxEOobnTz08iYqa5sCXZ5I0FFoi8gJTUo5k4sHn09pYzm53g+4cupg\nKmubeejlTdQ3OgNdnkhQUWiLyEldNnQm4xIzya8uoCb2C2acNYBDFQ4eeXUzzS3uQJcnEjQU2iJy\nUibDxA2j5zIwMpV1hz4nIeMQ2WOSKThYy19f34rLrXnKRfxBoS0inRJitvE/WQuItkXxZsF7nHW2\nh6z0eHIKK/nnu9vxaLpTEZ9TaItIp8WERPM/WQuwmCw8m/dvvnlRPBmp0fw3t4R/r9ipecpFfEyh\nLSJdMihqAAtGz6XF3cI/c5/ju5enkZoYzoqNB3hn3d5AlyfSpym0RaTLxieN5ZtDZ1HVXM1z+S/w\n42vGEB8Vyuuf7ObjTUWBLk+kz1Joi8gpuXjw+ZyTPJG9tft5Z/+b3H7tOCLtVhYv38GGvNJAlyfS\nJym0ReSUGIbBt0deTXr0EDaWbuaLmrX8bM44bFYzT769je17NE+5SHdTaIvIKbOaLPxg7PXEh8bx\n3p4VlFHAT64aC8Cjr21lT7HmKRfpTgptETktkbYIfjTuRkLNoTyf9yohsXXcdNkYWlrc/OmVzZRU\nOgJdokifodAWkdOWEt6P72V+B7fHzZNbniVtsJX5M0dQ52idp7yqrjnQJZ6Ux+OlpqGF/aX1bCus\nZF1OMcvW7+OVj3bxj7dy2LSrnKYWV6DLlCBnCXQBItI3jI4fwbeGX84r+W/wty3PcPvEm6lzpPH6\n6kIefmUTd35nAuGhVr/W5HJ7qHM4qW1ooaahhTpHS9v3tYe/P/JV1+jkZLeZW8wGwwbEkJkWR+bQ\neAYkhmMYhn8ORgQwvD14NoSysrpu32ZiYqRPtivtqZ39oye28yv5b7DqwKdkxo/kprE38O8PC/hw\n4wEyBkRzx7XjCbGaT2v7TpenNWgdh8P36K+jQ7mhhYamk/eMw0LMRNltRIV/9RX9tZ8jIkJZu+kA\nOYWV7C3+qr2jI2xkDmkN8DFpcUSE+fdDSW/l9XppdDVS3VxLdXMN1c211DTXgtVFpBHNwMhU+ocn\nYzUHZ3smJkZ2+Jp62iLSra7OuIxSRzk5FXm8UfAe377oG9Q3OlmfW8ITb+Rw61VjsZjbX5lrbnFT\n4zg2fI/+qjncY25sPnkQh4daiAq3MTApojV4vxbCrT9biQ63YbWc/ENEYmIkydEhXD0tndqGFrbt\nqSRndwXbCitZm1PM2pxiDGBISiSZafFkDo1jaP8ozKbguwLp9LioORzC1c011BwJ5Zb2Ae30nPgJ\ncSbDREp4PwZGpDIwMpUBkf0ZEJFCqCXUT0fSM6mnLT6hdvaPntrOja5G/rjxcYobSvj2iKuYlHw2\njy7ZQk5hJSMGxmAPtRwVzE6anSd+UpgBRNqtRB4O3OhjAvirZZF26zEfCk5XR+3s8XrZX1JPTmEF\nObsr2VVUg9vT+ic1LMTC6CGxrafS0+KJj+7dYeP1eql3NhwO3Zq2UK5urqW6paYtqOudDR1uw8Ag\n0hZBTEgU0SFRRIdEE2OLbvs5JSGO7UWF7K8rYn/dQQ7UH2wX7gYGSfYEBkT0Z2BkattXuNXujybw\nmxP1tBXa4hNqZ//oye1c3ljBgxv+gsPVyC3jvkdaxFD++PKXFBS13gZmMgwiw63HnIo+JpTDbUSG\nWTGZ/Hvt2OP14HA1Ut/SQFikmbqaZqwmCxaTFYvJgvXwl8Vkabuu3djsIm9vFTmFlWzdXUF5TVPb\n9lLi7WSmxTN2aBzDB8ZgO83LBN2pxd3SFsbH9opb/61trsXl7fjDVYjZRkxINNEh0UTboogJiSIm\n5Eggt/4bZYvEbOr4uL/+++zxeihxlB0O8davA/UHaXQ1tVsvLjS2NcAjUhkY2Rro0SFRp98wAaLQ\nPkpP/iPXl6id/aOnt/Ou6kIe+/JJrGYbP594C4lhiZRWNxIeaiE8zIrJj4O43B43DS4H9S0N1Dvr\nqWtpoN7ZQH1LPfXOBuqO+r6+pYEGlwOPt3OPHLUY5sNhbsZqsmI1WTCbLBgeE80t4Gj04Gh043Gb\n8HpMmDATEx5GYpSdfjGRxIaHYTFbsB7+QPD1DwVffVj4avtfvc+KxTAfNww9Xg91LfXtesU1zTVU\nt9S2W9boauzw2EyGiShbJNFHh7At6nBAf/VvWDectu7M77PX66WiqZJ9R0K87iD76g4c08OPskUy\nILI/g9pOr6cSHxrbKwYOKrSP0tP/yPUVamf/6A3tvP7QRp7b/jKJYfH875m3EmEN75btujyutoA9\nEr51zq8F8ZHXnPU4nI14OfmfuzBLGJHWcCJs4URYI4iwhhMXGUmdoxGXx4Xz8Jfr8JfT48TlcR/+\n19X2nqP/7cx+T5fJMLWGuNEa5gB1zvoTfvAIs4S1C+EjveLWMG5dFmmLwGT459r8qf4+e71ealpq\nj+qRH2R/XRFVzdXt3hdmCTvcI//q9HqSPcFvx9dZPSq033rrLZ5++mksFgs/+clPmD59eofvVWj3\nXmpn/+gt7fxmwVLe3/sRw2KGcuv477eFytFa3E7qnfXUt3yt13t0IB/uJdc7G445RXo8BgbhVjsR\nR4ewLbw1lA9/H2ENJ9LWGs4R1vDj9lhPp529Xi8erwenx9kuzCvrHOQXVbLzYCWFh6ppcjnB5MYw\neUiKCyElIZR+8aFEhhgfVToAAAygSURBVJtxe124vO4OPyB89SHiq314vV6iQiKP6RUffT05xGw7\npWM6HU6Xh+r6Zqrrm6mqa6a6rpmq+maq61twerzE2m0MSApnQFIEqQnhhNpOfbx0fUsD++tbe+NH\nAr20sbzde2z/v727j2nq3OMA/i1tobSnQNtLq1hwikYibL4nV4dziW4mM5mZbsLQutzcmC1mJlvc\nMsJ0uLgswWSJmRidmUscZpFN9po595LJQjKc28XrJlfUITqgQHkptKW89eX+0VJEh1MnPT2n309C\nyjmcwq9PGr59nuec5ySoYQ0PqVvDvfKpOvOfvkejJWZC2+l0orCwEFVVVfB6vdi3bx9279494fEM\nbeliO0eHVNo5EAzg8Pmj+G/neeQYZiMtKRXucEB7RkKBPOwf/svfk6BIgE6thT7cAx4fxNcFcjiE\ndWrtPelFTXY7BwJBXG134/yVbpxv6kGjvS9yzbhOo0Ju+GS23BlGGPRJk1bH3xEMBuEeGAmFsPu6\nUPYMwekejmx7Bm591viNzGnJsJoFWNN1yDQLsJoFpKcl3/XUyoBvEK2etnHz5O1ex7gRCZVCianC\nlMiZ65n6DEwTpiIxSh9yYia0T5w4gTNnzmDXrl23dTxDW7rYztEhpXYe8g9jb91B/OFuiexTKZSR\ngB0NYf11PeDRn40GcbJKI8pQZrTbuX9wBBeuOkNnpTf1oMc1tqKcNV2HvJkm5M0wYrY1DWrV5LfH\n0Ig/1DsOB7LTM4Re93D4MbSvr38IPv/EcaJJVMKgT0KaEPoy6JPC24lI0yfBICQhc1oa6i870Ozw\noMXRj5ZOD5odnpuCPlGdAGt6KMit6QIyzQKmpQt3fZ38sH8E9v62yLB6s7sV9v52+AJjlxcqoMAU\nnRlWYRqyRnvm+gwkq5Lv6m/eSsyE9qFDh3DlyhX09vbC5XJh27ZtWLp06YTHM7Sli+0cHVJrZ3/A\njxaPHVqVFkKiDhplkmRODBKrnYPBIOzdXtSHe+EXm3sx4gv1ChPVCcjJMkRWaLMYku+oPQOBIFze\n4ZuGqkM95OFIIHtvcW18gkKBVCExEsgGIQlp+tB26PvQ/uSkvx5u/rN2DgZDy8u2ODxo7hwLc3tX\nf+TyulEGfVI4wHXITA/1yqcYtXd1CaA/4Ee714E/3K1oGe2Ve+w3jQhZtGb8O28jpglT7/hvTCSm\nQruurg7l5eWw2+3YvHkzTp06NeGbzOfzQ3UbCx8QEcWLoRE/6hu78Z+LHTh70YHmDk/kZxajFgvn\nmLFgjhk59xng8Y6gp28Q3a5BdPcNRL7v6Qtvu4cQCEwcAbpkNUypGphSNDCmamBKTY5sm1KTYUzV\nIFVIgjLKl+MBoSVqWx0eNLW5cNXeh6ttLlxtc6G7b/y5DiqlApkWPe6bmoL7pqaGHjNSYNDf+QfG\nQDCAdk8nmpx/oMnZjCZnMzr7u7Htn//CbNOMe/nyJhTV0K6qqkJXVxeeffZZAMCaNWvw/vvvw2Qy\n/enx7GlLF9s5OtjO0RHL7dzdNxgZRv/fVedtrRinTFBEhqjT9Nf1jq/blyYk/e0lZ+/UvWhnz8AI\nWsPD6qHh9X60dnkwPDL+LHohWR2aI08XYDWH5sszTLqYuH4+ZpYxzc/PR3FxMbZs2YK+vj54vV4Y\nDIZolkBEJCumVA1WzJ+GFfOnwR8I4IrdhfNXetDs8CBFpw7NIYeDeTSQhShfIx9NQrIac7IMmJM1\nli2BQBCdvQORIG/p7EeLw4ML15y4cM0ZOU6hACwGLaxmAZnpuvCjAFOqJmamcaIa2haLBatXr8aG\nDRsAADt27EBCHK7NS0Q0GZQJCZhtTcNsa5rYpcSUhAQFLEYtLEYtFueYI/sHhnywd/WH58rDX539\n+KXBgV8axp6vSVSGe+RjYW5NF25rnv5e4+IqNCnYztHBdo4OtnN0xEI7B4NBON1D1w2vh4K8vduL\nwA1x+Y9UDaZb9ChcOfueri0fM8PjREREsUyhUMCYooExRYN5s/4R2T/i86Ot2zs2xO7woLmzH3WX\nOrFifkbUbgjD0CYiIvoLapUSWRY9sizje8EjvkBUrpUfxQllIiKiuxTNwAYY2kRERJLB0CYiIpII\nhjYREZFEMLSJiIgkgqFNREQkEQxtIiIiiWBoExERSQRDm4iISCIY2kRERBLB0CYiIpIIhjYREZFE\nxPStOYmIiGgMe9pEREQSwdAmIiKSCIY2ERGRRDC0iYiIJIKhTUREJBEMbSIiIomIm9B+8803UVBQ\ngMLCQvz6669ilyNre/bsQUFBAdavX49vvvlG7HJkbXBwEKtWrcLHH38sdimy9fnnn+Pxxx/HunXr\nUF1dLXY5stTf34/nn38eNpsNhYWFqKmpEbukmKUSu4BoOHPmDK5du4bKyko0NjaipKQElZWVYpcl\nS6dPn8bly5dRWVkJp9OJJ554Ao8++qjYZcnWgQMHkJqaKnYZsuV0OrF//35UVVXB6/Vi3759ePjh\nh8UuS3Y++eQTzJgxA9u3b0dHRweeeeYZnDx5UuyyYlJchHZtbS1WrVoFAMjOzkZfXx88Hg8EQRC5\nMvlZsmQJHnjgAQBASkoKBgYG4Pf7oVQqRa5MfhobG/H7778zRCZRbW0tli5dCkEQIAgCdu/eLXZJ\nsmQwGHDx4kUAgMvlgsFgELmi2BUXw+NdXV3j3gRGoxGdnZ0iViRfSqUSWq0WAHD8+HE89NBDDOxJ\nUlZWhuLiYrHLkLWWlhYMDg7iueeeQ1FREWpra8UuSZbWrFkDu92ORx55BJs2bcIrr7widkkxKy56\n2jfiyq2T77vvvsPx48fx3nvviV2KLH366aeYP38+MjMzxS5F9np7e1FeXg673Y7Nmzfj1KlTUCgU\nYpclK5999hkyMjJw+PBhNDQ0oKSkhOdpTCAuQttsNqOrqyuy7XA4kJ6eLmJF8lZTU4ODBw/i3Xff\nhV6vF7scWaqurkZzczOqq6vR3t6OxMRETJkyBcuWLRO7NFkxmUxYsGABVCoVsrKyoNPp0NPTA5PJ\nJHZpslJXV4f8/HwAQE5ODhwOB6fVJhAXw+MPPvggvv76awBAfX09zGYz57Mnidvtxp49e/DOO+8g\nLS1N7HJka+/evaiqqsKHH36Ip556Clu3bmVgT4L8/HycPn0agUAATqcTXq+X862TYPr06Th37hwA\noLW1FTqdjoE9gbjoaS9cuBC5ubkoLCyEQqFAaWmp2CXJ1okTJ+B0OvHCCy9E9pWVlSEjI0PEqoju\njsViwerVq7FhwwYAwI4dO5CQEBd9nagqKChASUkJNm3aBJ/Ph127doldUszirTmJiIgkgh8ZiYiI\nJIKhTUREJBEMbSIiIolgaBMREUkEQ5uIiEgiGNpEMtPS0oK8vDzYbLbIXZO2b98Ol8t127/DZrPB\n7/ff9vFPP/00fvrpp7spl4juAEObSIaMRiMqKipQUVGBY8eOwWw248CBA7f9/IqKCi5uQRSD4mJx\nFaJ4t2TJElRWVqKhoQFlZWXw+XwYGRnBa6+9hrlz58JmsyEnJwcXLlzAkSNHMHfuXNTX12N4eBg7\nd+5Ee3s7fD4f1q5di6KiIgwMDODFF1+E0+nE9OnTMTQ0BADo6OjASy+9BCB0r++CggI8+eSTYr50\nIllhaBPJnN/vx7fffotFixbh5Zdfxv79+5GVlXXTjRm0Wi2OHj067rkVFRVISUnBW2+9hcHBQTz2\n2GNYvnw5fvzxR2g0GlRWVsLhcGDlypUAgK+++gozZ87E66+/jqGhIXz00UdRf71EcsbQJpKhnp4e\n2Gw2AEAgEMDixYuxfv16vP3223j11Vcjx3k8HgQCAQCh5X5vdO7cOaxbtw4AoNFokJeXh/r6ely6\ndAmLFi0CELohz8yZMwEAy5cvxwcffIDi4mKsWLECBQUFk/o6ieINQ5tIhkbntK/ndruhVqtv2j9K\nrVbftO/GW1AGg0EoFAoEg8Fxa3CPBn92dja+/PJL/Pzzzzh58iSOHDmCY8eO/d2XQ0RhPBGNKE7o\n9XpYrVb88MMPAICmpiaUl5ff8jnz5s1DTU0NAMDr9aK+vh65ubnIzs7G2bNnAQBtbW1oamoCAHzx\nxRf47bffsGzZMpSWlqKtrQ0+n28SXxVRfGFPmyiOlJWV4Y033sChQ4fg8/lQXFx8y+NtNht27tyJ\njRs3Ynh4GFu3boXVasXatWvx/fffo6ioCFarFffffz8AYNasWSgtLUViYiKCwSC2bNkClYr/Zoju\nFd7li4iISCI4PE5ERCQRDG0iIiKJYGgTERFJBEObiIhIIhjaREREEsHQJiIikgiGNhERkUQwtImI\niCTi/xM/fZqvW7D4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0e38746a90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAFnCAYAAACM3c9QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBGRJAwSIiKShEFCRESSMEiIiEiS/wfgQPcMq6V3OgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0e3837d210>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "EBgMYkG5bNP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "266KQvZoMxMv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below for one possible solution."
      ]
    },
    {
      "metadata": {
        "id": "lRWcn24DM3qa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here is a set of parameters that should attain roughly 0.9 accuracy."
      ]
    },
    {
      "metadata": {
        "id": "TGlBMrUoM1K_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_ = train_linear_classification_model(\n",
        "    learning_rate=0.03,\n",
        "    steps=1000,\n",
        "    batch_size=30,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mk095OfpPdOx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2: Replace the Linear Classifier with a Neural Network\n",
        "\n",
        "**Replace the LinearClassifier above with a [`DNNClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) and find a parameter combination that gives 0.95 or better accuracy.**\n",
        "\n",
        "You may wish to experiment with additional regularization methods, such as dropout. These additional regularization methods are documented in the comments for the `DNNClassifier` class."
      ]
    },
    {
      "metadata": {
        "id": "rm8P_Ttwu8U4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE: Replace the linear classifier with a neural network.\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TOfmiSvqu8U9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once you have a good model, double check that you didn't overfit the validation set by evaluating on the test data that we'll load below.\n"
      ]
    },
    {
      "metadata": {
        "id": "evlB5ubzu8VJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_test_dataframe = pd.read_csv(\n",
        "  \"https://download.mlcc.google.com/mledu-datasets/mnist_test.csv\",\n",
        "  sep=\",\",\n",
        "  header=None)\n",
        "\n",
        "test_targets, test_examples = parse_labels_and_features(mnist_test_dataframe)\n",
        "test_examples.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDuLd2Hcu8VL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE: Calculate accuracy on the test set.\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6sfw3LH0Oycm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below for a possible solution."
      ]
    },
    {
      "metadata": {
        "id": "XatDGFKEO374",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The code below is almost identical to the original `LinearClassifer` training code, with the exception of the NN-specific configuration, such as the hyperparameter for hidden units."
      ]
    },
    {
      "metadata": {
        "id": "kdNTx8jkPQUx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_nn_classification_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    hidden_units,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a neural network classification model for the MNIST digits dataset.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  a plot of the training and validation loss over time, as well as a confusion\n",
        "  matrix.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: An `int`, the learning rate to use.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    hidden_units: A `list` of int values, specifying the number of neurons in each layer.\n",
        "    training_examples: A `DataFrame` containing the training features.\n",
        "    training_targets: A `DataFrame` containing the training labels.\n",
        "    validation_examples: A `DataFrame` containing the validation features.\n",
        "    validation_targets: A `DataFrame` containing the validation labels.\n",
        "      \n",
        "  Returns:\n",
        "    The trained `DNNClassifier` object.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  # Caution: input pipelines are reset with each call to train. \n",
        "  # If the number of steps is small, your model may never see most of the data.  \n",
        "  # So with multiple `.train` calls like this you may want to control the length \n",
        "  # of training with num_epochs passed to the input_fn. Or, you can do a really-big shuffle, \n",
        "  # or since it's in-memory data, shuffle all the data in the `input_fn`.\n",
        "  steps_per_period = steps / periods  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create feature columns.\n",
        "  feature_columns = [tf.feature_column.numeric_column('pixels', shape=784)]\n",
        "\n",
        "  # Create a DNNClassifier object.\n",
        "  my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  classifier = tf.estimator.DNNClassifier(\n",
        "      feature_columns=feature_columns,\n",
        "      n_classes=10,\n",
        "      hidden_units=hidden_units,\n",
        "      optimizer=my_optimizer,\n",
        "      config=tf.contrib.learn.RunConfig(keep_checkpoint_max=1)\n",
        "  )\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"LogLoss error (on validation data):\")\n",
        "  training_errors = []\n",
        "  validation_errors = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "  \n",
        "    # Take a break and compute probabilities.\n",
        "    training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
        "    training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
        "    training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10)\n",
        "        \n",
        "    validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
        "    validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
        "    validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10)    \n",
        "    \n",
        "    # Compute training and validation errors.\n",
        "    training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_errors.append(training_log_loss)\n",
        "    validation_errors.append(validation_log_loss)\n",
        "  print(\"Model training finished.\")\n",
        "  # Remove event files to save disk space.\n",
        "  _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
        "  \n",
        "  # Calculate final predictions (not probabilities, as above).\n",
        "  final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
        "  final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
        "  \n",
        "  \n",
        "  accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
        "  print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.plot(training_errors, label=\"training\")\n",
        "  plt.plot(validation_errors, label=\"validation\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "  # Output a plot of the confusion matrix.\n",
        "  cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
        "  # Normalize the confusion matrix by row (i.e by the number of samples\n",
        "  # in each class).\n",
        "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
        "  ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
        "  ax.set_aspect(1)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.ylabel(\"True label\")\n",
        "  plt.xlabel(\"Predicted label\")\n",
        "  plt.show()\n",
        "\n",
        "  return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZfzsTYGPPU8I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier = train_nn_classification_model(\n",
        "    learning_rate=0.05,\n",
        "    steps=1000,\n",
        "    batch_size=30,\n",
        "    hidden_units=[100, 100],\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qXvrOgtUR-zD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we verify the accuracy on the test set."
      ]
    },
    {
      "metadata": {
        "id": "scQNpDePSFjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_test_dataframe = pd.read_csv(\n",
        "  \"https://download.mlcc.google.com/mledu-datasets/mnist_test.csv\",\n",
        "  sep=\",\",\n",
        "  header=None)\n",
        "\n",
        "test_targets, test_examples = parse_labels_and_features(mnist_test_dataframe)\n",
        "test_examples.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EVaWpWKvSHmu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_test_input_fn = create_predict_input_fn(\n",
        "    test_examples, test_targets, batch_size=100)\n",
        "\n",
        "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
        "test_predictions = np.array([item['class_ids'][0] for item in test_predictions])\n",
        "  \n",
        "accuracy = metrics.accuracy_score(test_targets, test_predictions)\n",
        "print(\"Accuracy on test data: %0.2f\" % accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WX2mQBAEcisO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 3: Visualize the weights of the first hidden layer.\n",
        "\n",
        "Let's take a few minutes to dig into our neural network and see what it has learned by accessing the `weights_` attribute of our model.\n",
        "\n",
        "The input layer of our model has `784` weights corresponding to the `28×28` pixel input images. The first hidden layer will have `784×N` weights where `N` is the number of nodes in that layer. We can turn those weights back into `28×28` images by *reshaping* each of the `N` `1×784` arrays of weights into `N` arrays of size `28×28`.\n",
        "\n",
        "Run the following cell to plot the weights. Note that this cell requires that a `DNNClassifier` called \"classifier\" has already been trained."
      ]
    },
    {
      "metadata": {
        "id": "eUC0Z8nbafgG",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classifier.get_variable_names())\n",
        "\n",
        "weights0 = classifier.get_variable_value(\"dnn/hiddenlayer_0/kernel\")\n",
        "\n",
        "print(\"weights0 shape:\", weights0.shape)\n",
        "\n",
        "num_nodes = weights0.shape[1]\n",
        "num_rows = int(math.ceil(num_nodes / 10.0))\n",
        "fig, axes = plt.subplots(num_rows, 10, figsize=(20, 2 * num_rows))\n",
        "for coef, ax in zip(weights0.T, axes.ravel()):\n",
        "    # Weights in coef is reshaped from 1x784 to 28x28.\n",
        "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.pink)\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kL8MEhNgrx9N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first hidden layer of the neural network should be modeling some pretty low level features, so visualizing the weights will probably just show some fuzzy blobs or possibly a few parts of digits.  You may also see some neurons that are essentially noise -- these are either unconverged or they are being ignored by higher layers.\n",
        "\n",
        "It can be interesting to stop training at different numbers of iterations and see the effect.\n",
        "\n",
        "**Train the classifier for 10, 100 and respectively 1000 steps. Then run this visualization again.**\n",
        "\n",
        "What differences do you see visually for the different levels of convergence?"
      ]
    }
  ]
}